[
  {
    "objectID": "starter-analysis-exercise/data/readme.html",
    "href": "starter-analysis-exercise/data/readme.html",
    "title": "Andrew's Data Analysis Portfolio",
    "section": "",
    "text": "The folders inside this folder should contain all data at various stages.\nThis data is being loaded/manipulated/changed/saved with code from the code folders.\nYou should place the raw data in the raw_data folder and not edit it. Ever!\nIdeally, load the raw data into R and do all changes there with code, so everything is automatically reproducible and documented.\nSometimes, you need to edit the files in the format you got. For instance, Excel files are sometimes so poorly formatted that it’s close to impossible to read them into R, or the persons you got the data from used color to code some information, which of course won’t import into R. In those cases, you might have to make modifications in a software other than R. If you need to make edits in whatever format you got the data (e.g. Excel), make a copy and place those copies in a separate folder, AND ONLY EDIT THOSE COPIES. Also, write down somewhere the edits you made.\nAdd as many sub-folders as suitable. If you only have a single processing step, one sub-folder for processed data is enough. If you have multiple stages of cleaning and processing, additional sub-folders might be useful. Adjust based on the complexity of your project.\nI suggest you save your processed and cleaned data as RDS or RDA/Rdata files. This preserves coding like factors, characters, numeric, etc. If you save as CSV, that information would get lost. However, CSV is better for sharing with others since it’s plain text. If you do CSV, you might want to write down somewhere what each variable is.\nSee here for some suggestions on how to store your processed data:\nhttp://www.sthda.com/english/wiki/saving-data-into-r-data-format-rds-and-rdata"
  },
  {
    "objectID": "starter-analysis-exercise/results/figures/readme.html",
    "href": "starter-analysis-exercise/results/figures/readme.html",
    "title": "Andrew's Data Analysis Portfolio",
    "section": "",
    "text": "Folder for all figures.\nYou can create further sub-folders if that makes sense."
  },
  {
    "objectID": "starter-analysis-exercise/results/tables-files/readme.html",
    "href": "starter-analysis-exercise/results/tables-files/readme.html",
    "title": "Andrew's Data Analysis Portfolio",
    "section": "",
    "text": "Folder for all tables (generally stored as Rds files) and other files.\nYou can create further sub-folders if that makes sense."
  },
  {
    "objectID": "starter-analysis-exercise/code/processing-code/readme.html",
    "href": "starter-analysis-exercise/code/processing-code/readme.html",
    "title": "Andrew's Data Analysis Portfolio",
    "section": "",
    "text": "This folder contains code for processing data.\nCurrently, there is just a single Quarto file to illustrate how the processing can look like.\nInstead of a Quarto file that contains code, it is also possible to use R scripts or a combination of R scripts and Quarto code. Those approaches are illustrated in the full dataanalysis-template repository."
  },
  {
    "objectID": "starter-analysis-exercise/code/eda-code/readme.html",
    "href": "starter-analysis-exercise/code/eda-code/readme.html",
    "title": "Andrew's Data Analysis Portfolio",
    "section": "",
    "text": "This folder contains code to do some simple exploratory data analysis (EDA) on the processed/cleaned data. The code produces a few tables and figures, which are saved in the appropriate results sub-folder."
  },
  {
    "objectID": "starter-analysis-exercise/code/eda-code/eda2.html",
    "href": "starter-analysis-exercise/code/eda-code/eda2.html",
    "title": "An example exploratory analysis script",
    "section": "",
    "text": "This Quarto file loads the cleaned data and does some exploring.\nI’m only showing it the way where the code is included in the file. As described in the processing_code materials, I currently prefer the approach of having R code in a separate file and pulling it in.\nBut I already had this written and haven’t yet re-done it that way. Feel free to redo and send a pull request on GitHub :)\nAgain, it is largely a matter of preference and what makes the most sense to decide if one wants to have code inside Quarto files, or as separate R files. And sometimes, an R script with enough comments is good enough and one doesn’t need a Quarto file.\nAlso note that while here I split cleaning and exploring, this is iterative. You saw that as part of the processing, we already had to explore the data somewhat to understand how to clean it. In general, as you explore, you’ll find things that need cleaning. As you clean, you can explore more. Therefore, at times it might make more sense to combine the cleaning and exploring code parts into a single R or Quarto file. Or split things in any other logical way.\nAs part of the exploratory analysis, you should produce plots or tables or other summary quantities for the most interesting/important quantities in your data. Depending on the total number of variables in your dataset, explore all or some of the others. Figures produced here might be histograms or density plots, correlation plots, etc. Tables might summarize your data.\nStart by exploring one variable at a time. Then continue by creating plots or tables of the outcome(s) of interest and the predictor/exposure/input variables you are most interested in. If your dataset is small, you can do that for all variables.\nPlots produced here can be scatterplots, boxplots, violinplots, etc. Tables can be simple 2x2 tables or larger ones.\n\nSetup\n\n#load needed packages. make sure they are installed.\nlibrary(here) #for data loading/saving\n\nhere() starts at /Users/andrewruiz/MADA_course/andrew_ruiz-MADA-portfolio\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(skimr)\nlibrary(ggplot2)\n\nLoad the data.\n\n#Path to data. Note the use of the here() package and not absolute paths\ndata_location &lt;- here::here(\"starter-analysis-exercise\",\"data\",\"processed-data\",\"processeddata2.rds\")\n#load data\nmydata &lt;- readRDS(data_location)\n\n\n\nData exploration through tables\nShowing a bit of code to produce and save a summary table.\n\nsummary_df = skimr::skim(mydata)\nprint(summary_df)\n\n── Data Summary ────────────────────────\n                           Values\nName                       mydata\nNumber of rows             9     \nNumber of columns          5     \n_______________________          \nColumn type frequency:           \n  character                1     \n  factor                   1     \n  numeric                  3     \n________________________         \nGroup variables            None  \n\n── Variable type: character ────────────────────────────────────────────────────\n  skim_variable n_missing complete_rate min max empty n_unique whitespace\n1 SR_health             0             1   4   7     0        4          0\n\n── Variable type: factor ───────────────────────────────────────────────────────\n  skim_variable n_missing complete_rate ordered n_unique top_counts      \n1 Gender                0             1 FALSE          3 M: 4, F: 3, O: 2\n\n── Variable type: numeric ──────────────────────────────────────────────────────\n  skim_variable n_missing complete_rate  mean   sd  p0 p25 p50 p75 p100 hist \n1 Height                0             1 166.  16.0 133 156 166 178  183 ▂▁▃▃▇\n2 Weight                0             1  70.1 21.2  45  55  70  80  110 ▇▂▃▂▂\n3 HC_time               0             1  33.3 19.7  10  20  25  50   65 ▇▂▂▂▃\n\n# save to file\nsummarytable_file = here(\"starter-analysis-exercise\",\"results\", \"tables-files\", \"summarytable2.rds\")\nsaveRDS(summary_df, file = summarytable_file)\n\nWe are saving the results to the results/tables folder. Structure the folders inside results such that they make sense for your specific analysis. Provide enough documentation that someone can understand what you are doing and what goes where. readme.md files inside each folder are a good idea.\n\n\nData exploration through figures\nHistogram plots for the continuous outcomes.\nHeight first.\n\np1 &lt;- mydata %&gt;% ggplot(aes(x=Height)) + geom_histogram() \nplot(p1)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nfigure_file = here(\"starter-analysis-exercise\",\"results\",\"figures\",\"height-distribution.png\")\nggsave(filename = figure_file, plot=p1) \n\nSaving 7 x 5 in image\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nNow weights.\n\np2 &lt;- mydata %&gt;% ggplot(aes(x=Weight)) + geom_histogram() \nplot(p2)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nfigure_file = here(\"starter-analysis-exercise\",\"results\",\"figures\",\"weight-distribution.png\")\nggsave(filename = figure_file, plot=p2) \n\nSaving 7 x 5 in image\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nNow height as function of weight.\n\np3 &lt;- mydata %&gt;% ggplot(aes(x=Height, y=Weight)) + geom_point() + geom_smooth(method='lm')\nplot(p3)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nfigure_file = here(\"starter-analysis-exercise\",\"results\",\"figures\",\"height-weight.png\")\nggsave(filename = figure_file, plot=p3) \n\nSaving 7 x 5 in image\n`geom_smooth()` using formula = 'y ~ x'\n\n\nOnce more height as function of weight, stratified by gender. Note that there is so little data, it’s a bit silly. But we’ll plot it anyway.\n\np4 &lt;- mydata %&gt;% ggplot(aes(x=Height, y=Weight, color = Gender)) + geom_point() + geom_smooth(method='lm')\nplot(p4)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning in qt((1 - level)/2, df): NaNs produced\n\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\n\n\n\n\n\n\n\nfigure_file = here(\"starter-analysis-exercise\",\"results\",\"figures\",\"height-weight-stratified.png\")\nggsave(filename = figure_file, plot=p4) \n\nSaving 7 x 5 in image\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning in qt((1 - level)/2, df): NaNs produced\n\nWarning in qt((1 - level)/2, df): no non-missing arguments to max; returning\n-Inf\n\n\n\n# Boxplot of Weight by Travel time to nearest health facility\np5 &lt;- mydata %&gt;%\n    ggplot(aes(x=SR_health, y=Weight)) + \n    geom_boxplot() +\n    theme(legend.position = \"none\")\n\nplot(p5)\n\n\n\n\n\n\n\nfigure_file = here(\"starter-analysis-exercise\",\"results\",\"figures\",\"Weight_by_SR_health.png\")\nggsave(filename = figure_file, plot=p5)\n\nSaving 7 x 5 in image\n\n\n\n# Scatter plot of Travel time to nearest health facility vs Weight stratified by Gender\np6 &lt;- mydata %&gt;%\n    ggplot(aes(x=Weight, y=HC_time, color=Gender)) +\n    geom_point()  # Adds scatter plot points\n\nplot(p6)\n\n\n\n\n\n\n\nfigure_file = here(\"starter-analysis-exercise\",\"results\",\"figures\",\"SR-Health_by_Weight_stratified.png\")\nggsave(filename = figure_file, plot=p6)\n\nSaving 7 x 5 in image\n\n\n\n\nNotes\nFor your own explorations, tables and figures can be “quick and dirty”. As long as you can see what’s going on, there is no need to polish them. That’s in contrast to figures you’ll produce for your final products (paper, report, presentation, website, etc.). Those should look as nice, polished and easy to understand as possible."
  },
  {
    "objectID": "starter-analysis-exercise/code/analysis-code/readme.html",
    "href": "starter-analysis-exercise/code/analysis-code/readme.html",
    "title": "Andrew's Data Analysis Portfolio",
    "section": "",
    "text": "This folder contains code to do some simple exploratory analysis and statistical analysis on the processed/cleaned data. The code produces a few tables and figures, which are saved in the results folder.\nIt’s the same code done 3 times:\n\nFirst, there is an R script that you can run which does all the computations.\nSecond, there is a Quarto file which contains exactly the same code as the R script.\nThird, my current favorite, is a Quarto file with an approach where the code is pulled in from the R script and run.\n\nThe last version has the advantage of having code in one place for easy writing/debugging, and then being able to pull the code into the Quarto file for a nice combination of text/commentary and code.\nEach way of doing this is a reasonable approach, pick whichever one you prefer or makes the most sense for your setup. Whichever approach you choose, add ample documentation/commentary so you and others can easily understand what’s going on and what is done."
  },
  {
    "objectID": "starter-analysis-exercise/products/readme.html",
    "href": "starter-analysis-exercise/products/readme.html",
    "title": "Andrew's Data Analysis Portfolio",
    "section": "",
    "text": "The folders inside this folder should contain all the products of your project.\nFor a classical academic project, this will be a peer-reviewed manuscript, and should be placed into a manuscript folder.\nFor our case, since we’ll want to put it on the website, we call it a report.\nOften you need a library of references in bibtex format, as well as a CSL style file that determines reference formatting. Since those files might be used by several of the products, I’m placing them in the main products folder. Feel free to re-organize."
  },
  {
    "objectID": "fitting-exercise/fitting-exercise.html",
    "href": "fitting-exercise/fitting-exercise.html",
    "title": "fitting-exercise",
    "section": "",
    "text": "`\nsuppressMessages({\n  library(ggplot2)\n  library(dplyr)\n  library(skimr)\n  library(shiny)\n  library(DT)\n  library(here)\n  library(rsconnect)\n  library(tidymodels)\n  library(tidyverse)\n  library(yardstick)\n  library(MASS)\n  library(broom)\n  library(purrr)\n})"
  },
  {
    "objectID": "fitting-exercise/fitting-exercise.html#load-dataset",
    "href": "fitting-exercise/fitting-exercise.html#load-dataset",
    "title": "fitting-exercise",
    "section": "Load dataset",
    "text": "Load dataset\n\ndataset found at https://github.com/metrumresearchgroup/BayesPBPK-tutorial.git\n\nfile_path_mav = here(\"fitting-exercise\", \"data\", \"Mavoglurant_A2121_nmpk.csv\")\nmav = read.csv(file_path_mav)"
  },
  {
    "objectID": "fitting-exercise/fitting-exercise.html#dv-is-the-outcome-variable",
    "href": "fitting-exercise/fitting-exercise.html#dv-is-the-outcome-variable",
    "title": "fitting-exercise",
    "section": "DV is the outcome variable",
    "text": "DV is the outcome variable"
  },
  {
    "objectID": "fitting-exercise/fitting-exercise.html#plot-graph-dv-as-a-function-of-time-by-dose-and-id",
    "href": "fitting-exercise/fitting-exercise.html#plot-graph-dv-as-a-function-of-time-by-dose-and-id",
    "title": "fitting-exercise",
    "section": "Plot graph DV as a function of Time by DOSE and ID",
    "text": "Plot graph DV as a function of Time by DOSE and ID\n\n# Create a ggplot object using the 'mav' data\nggplot(mav, aes(x = TIME, y = DV, group = ID, color = as.factor(DOSE))) + \n  geom_line() + \n  geom_point() +\n  theme_minimal() + \n  labs(title = \"DV as a function of Time by DOSE and ID\", \n       x = \"Time\", \n       y = \"DV\", \n       color = \"Dose\")"
  },
  {
    "objectID": "fitting-exercise/fitting-exercise.html#showing-all-doses-on-one-graph-make-it-difficult-to-read",
    "href": "fitting-exercise/fitting-exercise.html#showing-all-doses-on-one-graph-make-it-difficult-to-read",
    "title": "fitting-exercise",
    "section": "Showing all doses on one graph make it difficult to read",
    "text": "Showing all doses on one graph make it difficult to read"
  },
  {
    "objectID": "fitting-exercise/fitting-exercise.html#try-creating-1-plot-for-each-dose",
    "href": "fitting-exercise/fitting-exercise.html#try-creating-1-plot-for-each-dose",
    "title": "fitting-exercise",
    "section": "Try creating 1 plot for each dose",
    "text": "Try creating 1 plot for each dose\n\nggplot(mav, aes(x = TIME, y = DV, group = ID, color = as.factor(DOSE))) + \n  geom_line() + \n  geom_point() +\n  theme_minimal() + \n  labs(title = \"DV as a function of Time by DOSE and ID\", \n       x = \"Time\", \n       y = \"DV\", \n       color = \"Dose\") + \n  facet_grid(~DOSE, scales = \"fixed\")  # Adjusted scales to \"fixed\" so that they share the same y axis scale."
  },
  {
    "objectID": "fitting-exercise/fitting-exercise.html#keep-only-records-where-occ1",
    "href": "fitting-exercise/fitting-exercise.html#keep-only-records-where-occ1",
    "title": "fitting-exercise",
    "section": "Keep only records where OCC=1",
    "text": "Keep only records where OCC=1\n\nmav_occ_1 = mav %&gt;%\n    filter(OCC == 1)\n\n#check to make sure filter worked as expected\nunique(mav_occ_1$OCC)\n\n[1] 1\n\n\n\nFilter and join the dataset\n\nOne data frame where observations where TIME = 0 are excluded, then sum DV for each ID to create a new variable, Y\n\n\nOne data frame that keeps only records where TIME == 0\n\nRationale: Initial measurements (TIME == 0) often represent baseline or pre-treatment values. Excluding these when summing DV allows for the calculation of total change or exposure post-baseline, which can be critical for assessing the effect or impact of an intervention.\n\n# exclude observations where TIME = 0\n# then sum DV for each ID to create new variable, Y\nmav_dv_sum = mav_occ_1 %&gt;%\n  filter(TIME != 0) %&gt;%\n  group_by(ID) %&gt;%\n  summarize(Y = sum(DV, na.rm = TRUE))\n\n#check dimension\ndim(mav_dv_sum)\n\n[1] 120   2\n\n# Keep only records where TIME == 0\nmav_time0 = mav_occ_1 %&gt;%\n    filter(TIME == 0) %&gt;%\n    distinct(ID, .keep_all = TRUE)\n\n#join the two data frames\nmav_joined = left_join(mav_dv_sum, mav_time0, by = \"ID\")\n\n#Check the dimension to ensure it is 120x18\ndim(mav_joined)\n\n[1] 120  18"
  },
  {
    "objectID": "fitting-exercise/fitting-exercise.html#convert-sex-race-and-dose-to-factor-variables-and-keep-the-variables-y-dose-age-sex-race-wt-ht",
    "href": "fitting-exercise/fitting-exercise.html#convert-sex-race-and-dose-to-factor-variables-and-keep-the-variables-y-dose-age-sex-race-wt-ht",
    "title": "fitting-exercise",
    "section": "Convert SEX, RACE, and DOSE to factor variables and keep the variables Y, DOSE, AGE, SEX, RACE, WT, HT",
    "text": "Convert SEX, RACE, and DOSE to factor variables and keep the variables Y, DOSE, AGE, SEX, RACE, WT, HT\n\n#This code transforms SEX, RACE, and DOSE into categorical variables for analysis and selects a specific set of variables, streamlining the dataset for focused statistical modeling or data exploration involving these key demographic and treatment attributes.\nlibrary(dplyr)\nmav_clean &lt;- mav_joined %&gt;%\n  mutate(SEX = as.factor(SEX), RACE = as.factor(RACE), DOSE = as.factor(DOSE)) %&gt;%\n  dplyr::select(Y, DOSE, AGE, SEX, RACE, WT, HT)\n\n# Checking the dimensions\ndim(mav_clean)\n\n[1] 120   7"
  },
  {
    "objectID": "fitting-exercise/fitting-exercise.html#create-bmi-variable-and-a-categorical-variable-for-age",
    "href": "fitting-exercise/fitting-exercise.html#create-bmi-variable-and-a-categorical-variable-for-age",
    "title": "fitting-exercise",
    "section": "Create BMI variable and a categorical variable for age",
    "text": "Create BMI variable and a categorical variable for age\n\nConvert them to factors\n\nBMI = weight in kilograms / (height in meters)^2\n\n#Calculate BMI and assign categories based on value\nmav_clean &lt;- mav_clean %&gt;%\n  mutate(\n    bmi = WT / (HT^2),\n    BMI_Category = case_when(\n      bmi &lt; 18.5 ~ \"Underweight\",\n      bmi &gt;= 18.5 & bmi &lt; 25 ~ \"Normal\",\n      bmi &gt;= 25 & bmi &lt; 30 ~ \"Overweight\",\n      bmi &gt;= 30 ~ \"Obese\",\n      TRUE ~ \"Unknown\"  # Handles any missing or NA values\n    )\n  ) %&gt;%\n  mutate(BMI_Category = factor(BMI_Category)) #convert to factor\n\n#Create categorical age variable\nmav_clean &lt;- mav_clean %&gt;%\n  mutate(Age_Group = cut(AGE,\n                         breaks = c(-Inf, 18, 30, 40, 50, 60, Inf),\n                         labels = c(\"&lt;=18\", \"19-30\", \"31-40\", \"41-50\", \"51-60\", \"&gt;60\"),\n                         right = FALSE)) %&gt;%\n    mutate(Age_Group = factor(Age_Group)) #convert to factor\n#examine structure\nstr(mav_clean)\n\ntibble [120 × 10] (S3: tbl_df/tbl/data.frame)\n $ Y           : num [1:120] 2691 2639 2150 1789 3126 ...\n $ DOSE        : Factor w/ 3 levels \"25\",\"37.5\",\"50\": 1 1 1 1 1 1 1 1 1 1 ...\n $ AGE         : int [1:120] 42 24 31 46 41 27 23 20 23 28 ...\n $ SEX         : Factor w/ 2 levels \"1\",\"2\": 1 1 1 2 2 1 1 1 1 1 ...\n $ RACE        : Factor w/ 4 levels \"1\",\"2\",\"7\",\"88\": 2 2 1 1 2 2 1 4 2 1 ...\n $ WT          : num [1:120] 94.3 80.4 71.8 77.4 64.3 ...\n $ HT          : num [1:120] 1.77 1.76 1.81 1.65 1.56 ...\n $ bmi         : num [1:120] 30.1 26 21.9 28.4 26.4 ...\n $ BMI_Category: Factor w/ 3 levels \"Normal\",\"Obese\",..: 2 3 1 3 3 1 3 1 1 2 ...\n $ Age_Group   : Factor w/ 4 levels \"19-30\",\"31-40\",..: 3 1 2 3 3 1 1 1 1 1 ..."
  },
  {
    "objectID": "fitting-exercise/fitting-exercise.html#create-tables",
    "href": "fitting-exercise/fitting-exercise.html#create-tables",
    "title": "fitting-exercise",
    "section": "Create tables",
    "text": "Create tables\n\nCalculatec summary statistics (number of observations, mean, median, minimum, and maximum of variable Y) for different groups in the dataset mav_clean, based on SEX, BMI_Category, and Age_Group\n\n\nDisplay these values in sortable tables\n\n# Compute summary statistics for each factor variable\nsummary_sex &lt;- mav_clean %&gt;%\n  group_by(SEX) %&gt;%\n    summarize(\n    N = n(),\n    Mean_Y = mean(Y, na.rm = TRUE),\n    Median_Y = median(Y, na.rm = TRUE),\n    Min_Y = min(Y, na.rm = TRUE),\n    Max_Y = max(Y, na.rm = TRUE),\n    .groups = 'drop'\n  ) %&gt;%\n  mutate(across(c(Mean_Y, Median_Y, Min_Y, Max_Y), round, 2))\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `across(c(Mean_Y, Median_Y, Min_Y, Max_Y), round, 2)`.\nCaused by warning:\n! The `...` argument of `across()` is deprecated as of dplyr 1.1.0.\nSupply arguments directly to `.fns` through an anonymous function instead.\n\n  # Previously\n  across(a:b, mean, na.rm = TRUE)\n\n  # Now\n  across(a:b, \\(x) mean(x, na.rm = TRUE))\n\nsummary_BMI &lt;- mav_clean %&gt;%\n  group_by(BMI_Category) %&gt;%\n    summarize(\n    N = n(),\n    Mean_Y = mean(Y, na.rm = TRUE),\n    Median_Y = median(Y, na.rm = TRUE),\n    Min_Y = min(Y, na.rm = TRUE),\n    Max_Y = max(Y, na.rm = TRUE),\n    .groups = 'drop'\n  ) %&gt;%\n  mutate(across(c(Mean_Y, Median_Y, Min_Y, Max_Y), round, 2))\n\nsummary_age &lt;- mav_clean %&gt;%\n  group_by(Age_Group) %&gt;%\n  summarize(\n    N = n(),\n    Mean_Y = mean(Y, na.rm = TRUE),\n    Median_Y = median(Y, na.rm = TRUE),\n    Min_Y = min(Y, na.rm = TRUE),\n    Max_Y = max(Y, na.rm = TRUE),\n    .groups = 'drop'\n  ) %&gt;%\n  mutate(across(c(Mean_Y, Median_Y, Min_Y, Max_Y), round, 2))\n\n# Display the tables\ndatatable(summary_sex, options = list(pageLength = 5), caption = 'Summary Statistics of Y by SEX')\n\n\n\n\ndatatable(summary_BMI, options = list(pageLength = 5), caption = 'Summary Statistics of Y by BMI')\n\n\n\n\ndatatable(summary_age, options = list(pageLength = 5), caption = 'Summary Statistics of Y by Age')\n\n\n\n\n\n\n\nComputes summary statistics (count, mean, median, minimum, and maximum) for variable Y, grouped by Age_Group and BMI_Category from the mav_clean dataset, and then displays the results in an sortable table\n\n# Compute summary statistics for Y, stratified by both SEX and RACE\nsummary_stats_group &lt;- mav_clean %&gt;%\n  group_by(Age_Group, BMI_Category) %&gt;%\n  summarize(\n    N = n(),\n    Mean_Y = mean(Y, na.rm = TRUE),\n    Median_Y = median(Y, na.rm = TRUE),\n    Min_Y = min(Y, na.rm = TRUE),\n    Max_Y = max(Y, na.rm = TRUE),\n    .groups = 'drop'\n  ) %&gt;%\n  mutate(across(c(Mean_Y, Median_Y, Min_Y, Max_Y), round, 2))\n\n# Display the table with DT::datatable for interactivity\ndatatable(summary_stats_group, options = list(pageLength = 10), \n          caption = 'Summary Statistics of Y by Age and BMI Status')\n\n\n\n\n\n\n\nThis R code reorders the levels of the factor variable BMI_Category in the dataset mav_clean and then creates four different plots: a raincloud plot of Y by BMI_Category, a combines scatter and contour plot of Y by Weight, a raincloud plot of Y by DOSE, and a raincloud plot of Y by age category using the ggplot2 package in R\n\n# Reorder the levels of BMI_Category\nmav_clean$BMI_Category &lt;- factor(mav_clean$BMI_Category, \n                                  levels = c(\"Normal\", \"Overweight\", \"Obese\"))\n\nggplot(mav_clean, aes(x = BMI_Category, y = Y)) +\n  geom_violin(fill = \"skyblue\", alpha = 0.5) +  # Add violin plot with semi-transparent fill\n  geom_boxplot(width = 0.1, fill = \"white\", color = \"black\", outlier.shape = NA) +  # Add transparent boxplot without outliers\n  geom_point(position = position_jitter(width = 0.2), alpha = 0.5, size = 2) +  # Add jittered points for individual data\n  labs(x = \"BMI\", y = \"Y\", title = \"Raincloud Plot of Y by BMI\")  # Add labels and title\n\n\n\n\n\n\n\nggplot(mav_clean, aes(x = WT, y = Y)) +\n  geom_point() +\n  labs(x = \"Weight (kg)\", y = \"Y\", title = \"Scatter Plot of Y by Weight\")\n\n\n\n\n\n\n\n#Combined scatter and contour plot\n#a contour plot displays the density of points\n#in the form of contour lines, providing a two-dimensional representation of the data density.\nggplot(mav_clean, aes(x = WT, y = Y)) +\n  stat_density_2d(aes(fill = after_stat(level)), geom = \"polygon\") +  # Create contour polygons\n  geom_point() +  # Add scatter plot\n  scale_fill_viridis_c() +  # Choose a color scale\n  labs(x = \"Weight (kg)\", y = \"Y\", title = \"Combined Scatter and Contour Plot of Y by Weight\")  # Add labels and title\n\n\n\n\n\n\n\nggplot(mav_clean, aes(x = DOSE, y = Y)) +\n  geom_violin(fill = \"skyblue\", alpha = 0.5) +  # Add violin plot with semi-transparent fill\n  geom_boxplot(width = 0.1, fill = \"white\", color = \"black\", outlier.shape = NA) +  # Add transparent boxplot without outliers\n  geom_point(position = position_jitter(width = 0.2), alpha = 0.5, size = 2) +  # Add jittered points for individual data\n  labs(x = \"DOSE\", y = \"Y\", title = \"Raincloud Plot of Y by Dose\")  # Add labels and title\n\n\n\n\n\n\n\nggplot(mav_clean, aes(x = Age_Group, y = Y)) +\n  geom_violin(fill = \"skyblue\", alpha = 0.5) +  # Add violin plot with semi-transparent fill\n  geom_boxplot(width = 0.1, fill = \"white\", color = \"black\", outlier.shape = NA) +  # Add transparent boxplot without outliers\n  geom_point(position = position_jitter(width = 0.2), alpha = 0.5, size = 2) +  # Add jittered points for individual data\n  labs(x = \"Age_Group\", y = \"Y\", title = \"Raincloud Plot of Y by Age\")  # Add labels and title\n\nWarning: Groups with fewer than two data points have been dropped.\n\n\n\n\n\n\n\n\n\n\n\nCreate a grid of scatterplots for each pair of variables in subset_data (Y, bmi) and (HT, bmi), along with histograms for each variable on the diagonal and correlation coefficients in the upper triangle.\n\n\nWeight and BMI are directly related. Using this as an example to show highly correlated pair\n\n# Load the GGally library for pair plot visualization\nlibrary(GGally)\n\nRegistered S3 method overwritten by 'GGally':\n  method from   \n  +.gg   ggplot2\n\n# Subset the dataset to include only the variables Y and BMI\nsubset_Ybmi&lt;- mav_clean[, c(\"Y\", \"bmi\")]\n\n# Using the pairs() function to create a matrix of scatterplots for Y and BMI\npairs(subset_Ybmi)\n\n\n\n\n\n\n\n# Using the ggpairs() function to create a grid of scatterplots, histograms, and correlation coefficients for Y and BMI\nggpairs(subset_Ybmi)\n\n\n\n\n\n\n\n# Subset the dataset to include only the variables weight and BMI\nsubset_dataWTbmi &lt;- mav_clean[, c(\"WT\", \"bmi\")]\n\n# Using the pairs() function to create a matrix of scatterplots for weight and BMI\npairs(subset_dataWTbmi)\n\n\n\n\n\n\n\n# Using the ggpairs() function to create a grid of scatterplots, histograms, and correlation coefficients for weight and BMI\nggpairs(subset_dataWTbmi)\n\n\n\n\n\n\n\n\n\n\nThe BMI to Y shows a Corr. of -.0153. This suggests that there is weak inverse relationship between the two variables.\n\n\nThe weight to BMI shows a Corr. of 0.762. This suggests that there is a stronger postitive relationship and the two are closely related."
  },
  {
    "objectID": "fitting-exercise/fitting-exercise.html#model-fitting",
    "href": "fitting-exercise/fitting-exercise.html#model-fitting",
    "title": "fitting-exercise",
    "section": "Model fitting",
    "text": "Model fitting\n\nFit a linear model to the continuous outcome (Y) using the main predictor of interest, DOSE\n\n\nFit a linear model to the continuous outcome (Y) using all predictors\n\nPreprocess data\n\n# Preprocess your data: convert 'DOSE' and 'BMI_Category' to factors\nmav_clean &lt;- mav_clean %&gt;%\n  mutate(\n    DOSE = as.factor(DOSE),  # Convert DOSE to a factor\n    BMI_Category = factor(BMI_Category, levels = c(\"Normal\", \"Overweight\", \"Obese\"))  # Ensure BMI_Category has ordered levels\n  )\n\n\n\nThe code defines a linear model specification using the ‘lm’ engine for regression analysis and prepares a 5-fold cross-validation with stratification by ‘Y’ to ensure balanced splits\n\n\nUtilizing a 5-fold cross-validation with stratification by ‘Y’ helps ensure balanced splits within each fold, which is crucial for maintaining the representativeness of each subset during model evaluation, especially in the presence of class imbalance or uneven distribution of the target variable ‘Y’.\n\n# Define the linear model specification using the 'lm' engine\nlinear_spec &lt;- linear_reg() %&gt;% \n  set_engine(\"lm\") %&gt;% \n  set_mode(\"regression\")\n\n# Prepare a 5-fold cross-validation, stratifying by 'Y' to ensure balanced splits\ncv_folds &lt;- vfold_cv(mav_clean, v = 5, strata = Y)\n\n\n\nThe code creates a workflow for a linear regression model using ‘DOSE’ as the predictor variable, fits the model across cross-validation folds, and collects evaluation metrics including Root Mean Squared Error (RMSE) and R-squared\n\n# Create a workflow for the model using only DOSE as the predictor\nworkflow_dose &lt;- workflow() %&gt;%\n  add_formula(Y ~ DOSE) %&gt;%  # Define the model formula with DOSE\n  add_model(linear_spec)  # Add the linear model specification\n\n# Fit the model across the cross-validation folds and collect evaluation metrics (RMSE and R-squared)\nresults_dose &lt;- fit_resamples(\n  workflow_dose,\n  cv_folds,\n  metrics = metric_set(rmse, rsq)\n)\n\n\n\nThis code creates a workflow for a linear regression model including all predictors (DOSE, AGE, and BMI_Category), fits the model across cross-validation folds, and collects evaluation metrics such as Root Mean Squared Error (RMSE) and R-squared.\n\n# Workflow for the model including all predictors (DOSE, AGE, BMI_Category)\nworkflow_all &lt;- workflow() %&gt;%\n  add_formula(Y ~ DOSE + AGE + BMI_Category) %&gt;%  # Include all predictors in the formula\n  add_model(linear_spec)  # Add the same linear model specification\n\n# Fit this comprehensive model across the cross-validation folds and collect metrics\nresults_all &lt;- fit_resamples(\n  workflow_all,\n  cv_folds,\n  metrics = metric_set(rmse, rsq)\n)\n\n\n\nThis series of steps allows for the comparison of evaluation metrics between the model with only ‘DOSE’ as the predictor and the model with all predictors (‘DOSE’, ‘AGE’, and ‘BMI_Category’). Additionally, it provides the range of values for the ‘Y’ variable in the dataset.\n\n# Step 1: Collect metrics for the model with DOSE as the predictor\nmetrics_dose &lt;- collect_metrics(results_dose)\n\n# Step 2: Collect metrics for the model with all predictors\nmetrics_all &lt;- collect_metrics(results_all)\n\n# Step 3: Add a model identifier column to the metrics data frames AFTER collecting metrics\nmetrics_dose$model &lt;- \"DOSE Predictor\"\nmetrics_all$model &lt;- \"All Predictors\"\n\n# Step 4: Combine metrics into a single data frame for comparison\ncombined_metrics &lt;- bind_rows(metrics_dose, metrics_all)\n\n# Step 5: Reorder the columns so that 'model' is the first column\nreordered_metrics &lt;- combined_metrics %&gt;%\n  dplyr::select(model, .metric, .estimator, mean, n, std_err, .config)\n\n# Step 6: Print the reordered metrics\nprint(reordered_metrics)\n\n# A tibble: 4 × 7\n  model          .metric .estimator    mean     n std_err .config             \n  &lt;chr&gt;          &lt;chr&gt;   &lt;chr&gt;        &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 DOSE Predictor rmse    standard   669.        5 47.1    Preprocessor1_Model1\n2 DOSE Predictor rsq     standard     0.540     5  0.0435 Preprocessor1_Model1\n3 All Predictors rmse    standard   663.        5 46.0    Preprocessor1_Model1\n4 All Predictors rsq     standard     0.570     5  0.0467 Preprocessor1_Model1\n\n# Step 7: Print the range of 'Y' from the 'mav_clean' dataset\n# Assuming 'mav_clean' is your dataset and it contains the variable 'Y'\ny_range &lt;- range(mav_clean$Y, na.rm = TRUE)\n\n# Step 8: Print the range\nprint(y_range)\n\n[1]  826.43 5606.58\n\n\n\n\n\nComparative Proportion: The error is a moderate proportion of the range (5606.58 - 826.43 = 4780.15). Specifically, it’s about 14% of the total range (666.90 / 4780.15 ≈ 0.14), suggesting that, on average, the model’s predictions might deviate from the actual values by around 14% of the total variability in Y."
  },
  {
    "objectID": "fitting-exercise/fitting-exercise.html#fit-a-logistic-model-to-the-categoricalbinary-outcome-sex-using-the-main-predictor-of-interest-which-well-again-assume-here-to-be-dose",
    "href": "fitting-exercise/fitting-exercise.html#fit-a-logistic-model-to-the-categoricalbinary-outcome-sex-using-the-main-predictor-of-interest-which-well-again-assume-here-to-be-dose",
    "title": "fitting-exercise",
    "section": "Fit a logistic model to the categorical/binary outcome (SEX) using the main predictor of interest, which we’ll again assume here to be DOSE",
    "text": "Fit a logistic model to the categorical/binary outcome (SEX) using the main predictor of interest, which we’ll again assume here to be DOSE"
  },
  {
    "objectID": "fitting-exercise/fitting-exercise.html#fit-a-logistic-model-to-sex-using-all-predictors.",
    "href": "fitting-exercise/fitting-exercise.html#fit-a-logistic-model-to-sex-using-all-predictors.",
    "title": "fitting-exercise",
    "section": "Fit a logistic model to SEX using all predictors.",
    "text": "Fit a logistic model to SEX using all predictors."
  },
  {
    "objectID": "fitting-exercise/fitting-exercise.html#for-both-models-compute-accuracy-and-roc-auc-and-print-them",
    "href": "fitting-exercise/fitting-exercise.html#for-both-models-compute-accuracy-and-roc-auc-and-print-them",
    "title": "fitting-exercise",
    "section": "For both models, compute accuracy and ROC-AUC and print them",
    "text": "For both models, compute accuracy and ROC-AUC and print them\n\nP(SEX = 1 | DOSE) = 1 / (1 + exp(-(intercept + coefficient * DOSE))\n\n# Ensure SEX is a factor and DOSE is treated as a factor for logistic regression analysis\nmav_clean_prepared &lt;- mav_clean %&gt;%\n  mutate(\n    SEX = as.factor(SEX),  # Convert SEX to a factor if it isn't already\n    DOSE = as.factor(DOSE)  # Ensure DOSE is treated as a factor\n  )\n\n# Specify a logistic regression model using glm (Generalized Linear Model) as the engine\nlogistic_spec_dose &lt;- logistic_reg() %&gt;% \n  set_engine(\"glm\") %&gt;% \n  set_mode(\"classification\")  # Set mode to classification for the binary outcome\n\n# Prepare a 5-fold cross-validation object, stratifying by SEX to ensure balanced folds\ncv_folds_sex &lt;- vfold_cv(mav_clean_prepared, v = 5, strata = SEX)\n\n# Create a workflow combining the logistic model specification with the SEX ~ DOSE formula\nworkflow_sex_dose &lt;- workflow() %&gt;%\n  add_formula(SEX ~ DOSE) %&gt;%  # Predicting SEX based on DOSE\n  add_model(logistic_spec_dose)  # Add the logistic regression specification\n\n# Fit the model across the cross-validation folds and calculate metrics\nresults_sex_dose_cv &lt;- fit_resamples(\n  workflow_sex_dose,\n  cv_folds_sex,\n  metrics = metric_set(roc_auc, accuracy)  # Focus on ROC AUC and accuracy for evaluation\n)\n\n# Collect and summarize the metrics from cross-validation\nmetrics_sex_dose &lt;- collect_metrics(results_sex_dose_cv)\n\n# Print the summarized metrics to assess model performance\nprint(metrics_sex_dose)\n\n# A tibble: 2 × 6\n  .metric  .estimator  mean     n std_err .config             \n  &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy binary     0.867     5 0.00681 Preprocessor1_Model1\n2 roc_auc  binary     0.469     5 0.113   Preprocessor1_Model1\n\n\n\n\nAccuracy\n\nMetric: Accuracy measures the proportion of true results (both true positives and true negatives) among the total number of cases examined. It’s a straightforward indicator of how often the model predicts the correct category.\n\n\nValue: The mean accuracy across the 5 cross-validation folds is approximately 86.69%.\n\n\nInterpretation: This suggests that, on average, the model correctly predicts the SEX category about 86.69% of the time across the different subsets of your data. A high accuracy indicates the model is generally effective at classifying the instances according to SEX.\n\n\n\nROC AUC (Area Under the Receiver Operating Characteristic Curve)\n\nMetric: ROC AUC evaluates the model’s ability to discriminate between the classes at various threshold settings. The AUC (Area Under the Curve) ranges from 0 to 1, where 1 indicates perfect discrimination and 0.5 indicates no discrimination (equivalent to random guessing). Value: The mean ROC AUC across the 5 folds is approximately 0.553. Interpretation: This value is slightly above 0.5, indicating the model has a very limited ability to distinguish between the SEX categories beyond random chance. The ROC AUC being close to 0.5 suggests that, while the model is accurate in many of its predictions, this might be attributed to the distribution of classes in the dataset rather than the model’s discriminative power.\n\n\n\nP(SEX = 1 | DOSE, AGE, BMI_Category) = 1 / (1 + exp(-(intercept + coefficient_DOSE * DOSE + coefficient_AGE * AGE + coefficient_BMI_Category * BMI_Category)))\n\n# Preprocess the dataset: converting predictors to their appropriate formats\nmav_clean_logistic_all &lt;- mav_clean %&gt;%\n  mutate(\n    BMI_Category = as.factor(BMI_Category),  # Ensure BMI_Category is a factor\n    DOSE = as.factor(DOSE),  # Ensure DOSE is a factor\n    AGE = as.numeric(AGE)  # Ensure AGE is numeric\n  )\n\n# Specify a logistic regression model using glm as the computational engine\nlogistic_spec_all &lt;- logistic_reg() %&gt;% \n  set_engine(\"glm\") %&gt;% \n  set_mode(\"classification\")\n\n# Prepare a 5-fold cross-validation, ensuring a balanced representation of SEX across folds\ncv_folds_sex_all &lt;- vfold_cv(mav_clean_logistic_all, v = 5, strata = SEX)\n\n# Create a workflow that encapsulates the model specification and formula\nworkflow_sex_all &lt;- workflow() %&gt;%\n  add_formula(SEX ~ BMI_Category + AGE + DOSE) %&gt;%  # Use all predictors in the model formula\n  add_model(logistic_spec_all)  # Add the logistic regression model specification\n\n# Fit the model across the cross-validation folds and evaluate\nresults_sex_all_cv &lt;- fit_resamples(\n  workflow_sex_all,\n  cv_folds_sex_all,\n  metrics = metric_set(roc_auc, accuracy)  # Focus on ROC AUC and accuracy for evaluation\n)\n# Collect metrics from the cross-validation results\nmetrics_sex_all &lt;- collect_metrics(results_sex_all_cv)\n\n# Print the summarized metrics to understand model performance\nprint(metrics_sex_all)\n\n# A tibble: 2 × 6\n  .metric  .estimator  mean     n std_err .config             \n  &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy binary     0.834     5  0.0124 Preprocessor1_Model1\n2 roc_auc  binary     0.769     5  0.0461 Preprocessor1_Model1\n\n\n\n\nFirst Model (DOSE as the Predictor)\n\nAccuracy: The mean accuracy is approximately 86.69%, indicating a high overall rate of correctly predicting SEX.\n\n\nROC AUC: The mean ROC AUC is approximately 0.553, suggesting the model’s ability to discriminate between the classes is only slightly better than random guessing.\n\n\n\nSecond Model (All Predictors: BMI_Category, AGE, DOSE)\n\nAccuracy: The mean accuracy slightly decreases to approximately 84.26%. This indicates a slight reduction in the overall rate of correct predictions compared to the first model.\n\n\nROC AUC: The mean ROC AUC improves to approximately 0.627, indicating enhanced discriminative ability between the classes compared to the first model.\n\n\n\nInterpretation\n\nAccuracy vs. ROC AUC: While the first model achieves higher accuracy, its ROC AUC value is lower, suggesting it’s not as effective at distinguishing between the classes across different thresholds. The second model, despite a slight drop in accuracy, shows a notable improvement in ROC AUC, indicating better performance in class discrimination.\n\n\nModel Comparison: The increase in ROC AUC for the second model suggests that including additional predictors (BMI_Category and AGE alongside DOSE) contributes to a more nuanced understanding and prediction of SEX, beyond what is achievable with DOSE alone. This indicates the importance of considering multiple factors in predictive modeling, especially for complex outcomes."
  },
  {
    "objectID": "fitting-exercise/fitting-exercise.html#k-nearest-neighbors-knn-regression-model",
    "href": "fitting-exercise/fitting-exercise.html#k-nearest-neighbors-knn-regression-model",
    "title": "fitting-exercise",
    "section": "k-nearest neighbors (KNN) regression model",
    "text": "k-nearest neighbors (KNN) regression model\n\nThe model is trained and evaluated to predict the outcome variable ‘Y’ based on the predictor variable ‘DOSE’.\n\n\nThis process involves splitting the dataset into training and testing sets, converting the ‘DOSE’ variable to a factor, specifying the KNN model, fitting the model on the training data, making predictions on the testing set, calculating evaluation metrics (Root Mean Squared Error and R-squared), and printing the evaluation metrics for model assessment and comparison.\n\nlibrary(kknn)\n\n# Splitting the data\nset.seed(123)  # Ensure reproducibility\nmav_data_split &lt;- initial_split(mav_clean, prop = 0.75)  # 75% training, 25% testing\nmav_train &lt;- training(mav_data_split)  # Training data\nmav_test &lt;- testing(mav_data_split)  # Testing data\n\nmav_train &lt;- mav_train %&gt;%\n  mutate(DOSE = as.factor(DOSE))\n\nmav_test &lt;- mav_test %&gt;%\n  mutate(DOSE = as.factor(DOSE))\n\n# KNN model specification\nknn_spec &lt;- nearest_neighbor(neighbors = 5) %&gt;%\n  set_engine(\"kknn\") %&gt;%\n  set_mode(\"regression\")\n\n# Creating the workflow\nknn_workflow &lt;- workflow() %&gt;%\n  add_formula(Y ~ DOSE) %&gt;%\n  add_model(knn_spec)\n\n# Fitting the model on training data\nknn_fit &lt;- knn_workflow %&gt;%\n  fit(data = mav_train)\n\n# Making predictions on the testing set\nknn_predictions &lt;- predict(knn_fit, new_data = mav_test) %&gt;%\n  bind_cols(mav_test)\n\n# Calculate RMSE and R-squared\nknn_metrics &lt;- knn_predictions %&gt;%\n  metrics(truth = Y, estimate = .pred) %&gt;%\n  filter(.metric %in% c(\"rmse\", \"rsq\"))\n\n# Print the evaluation metrics\nprint(knn_metrics)\n\n# A tibble: 2 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard     566.   \n2 rsq     standard       0.648"
  },
  {
    "objectID": "fitting-exercise/fitting-exercise.html#model-comparison",
    "href": "fitting-exercise/fitting-exercise.html#model-comparison",
    "title": "fitting-exercise",
    "section": "Model comparison",
    "text": "Model comparison\n\nRMSE (Root Mean Squared Error):\n\n\nKNN model: 565.72\n\n\n“DOSE Predictor” model: 673.09\n\nThe RMSE of the KNN model (565.72) is lower than that of the “DOSE Predictor” model (673.09), indicating that, on average, the KNN model’s predictions are closer to the true values compared to the “DOSE Predictor” model.\n\n\n\nR-squared (rsq):\n\nKNN model: 0.648\n\n\n“DOSE Predictor” model: 0.522\n\nThe R-squared value of the KNN model (0.648) is higher than that of the “DOSE Predictor” model (0.522), suggesting that the KNN model explains a higher proportion of the variance in the outcome variable compared to the “DOSE Predictor” model.\n\n\nOverall, based on these metrics, the KNN model appears to perform better in terms of both accuracy (lower RMSE) and explanatory power (higher R-squared) compared to the “DOSE Predictor” model."
  },
  {
    "objectID": "fitting-exercise/fitting-exercise.html#improving-models",
    "href": "fitting-exercise/fitting-exercise.html#improving-models",
    "title": "fitting-exercise",
    "section": "Improving Models",
    "text": "Improving Models"
  },
  {
    "objectID": "fitting-exercise/fitting-exercise.html#data-prep",
    "href": "fitting-exercise/fitting-exercise.html#data-prep",
    "title": "fitting-exercise",
    "section": "Data prep",
    "text": "Data prep\n\nFirst we will set a random seed.\n\nWe will specify a value for a seed at the start, and then re-set the seed to this value before every operation that involves random numbers.\n\nrngseed2 = 1234\n\n\n\nTo pick up where we left off, let’s re-examine the dataset.\n\nstr(mav_clean)\n\ntibble [120 × 10] (S3: tbl_df/tbl/data.frame)\n $ Y           : num [1:120] 2691 2639 2150 1789 3126 ...\n $ DOSE        : Factor w/ 3 levels \"25\",\"37.5\",\"50\": 1 1 1 1 1 1 1 1 1 1 ...\n $ AGE         : int [1:120] 42 24 31 46 41 27 23 20 23 28 ...\n $ SEX         : Factor w/ 2 levels \"1\",\"2\": 1 1 1 2 2 1 1 1 1 1 ...\n $ RACE        : Factor w/ 4 levels \"1\",\"2\",\"7\",\"88\": 2 2 1 1 2 2 1 4 2 1 ...\n $ WT          : num [1:120] 94.3 80.4 71.8 77.4 64.3 ...\n $ HT          : num [1:120] 1.77 1.76 1.81 1.65 1.56 ...\n $ bmi         : num [1:120] 30.1 26 21.9 28.4 26.4 ...\n $ BMI_Category: Factor w/ 3 levels \"Normal\",\"Overweight\",..: 3 2 1 2 2 1 2 1 1 3 ...\n $ Age_Group   : Factor w/ 4 levels \"19-30\",\"31-40\",..: 3 1 2 3 3 1 1 1 1 1 ...\n\n\n\n\n\nIn the previous exercise, I added 3 new variable. For this exercise, I will remove them along with RACE so that only Y, DOSE, AGE, SEX, WT, HT remain.\n\n\nThe dataframe dimension should be 120X6\n\n# Rename dataframe and remove 'RACE', 'bmi', 'BMI_Category', 'Age_Group' columns using dplyr\nmav_ex10 &lt;- mav_clean %&gt;%\n  dplyr::select(-RACE, -bmi, -BMI_Category, -Age_Group)\nhead(mav_ex10)\n\n# A tibble: 6 × 6\n      Y DOSE    AGE SEX      WT    HT\n  &lt;dbl&gt; &lt;fct&gt; &lt;int&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 2691. 25       42 1      94.3  1.77\n2 2639. 25       24 1      80.4  1.76\n3 2150. 25       31 1      71.8  1.81\n4 1789. 25       46 2      77.4  1.65\n5 3126. 25       41 2      64.3  1.56\n6 2337. 25       27 1      74.1  1.83\n\ndim(mav_ex10)\n\n[1] 120   6\n\n\n\n\nRandomly split dataset into training (75%) and test (25%) frames using the seed defined above.\n\nset.seed(rngseed2)\n\n# Split the data into a 75% training set and a 25% test set\ndata_split_mav &lt;- initial_split(mav_ex10, prop = 0.75)\n\n# Extract the training and test sets\nmav10_train_75pct &lt;- training(data_split_mav)\nmav10_test_25pct&lt;- testing(data_split_mav)"
  },
  {
    "objectID": "fitting-exercise/fitting-exercise.html#model-fitting-1",
    "href": "fitting-exercise/fitting-exercise.html#model-fitting-1",
    "title": "fitting-exercise",
    "section": "Model Fitting",
    "text": "Model Fitting\n\nUse the tidymodels framework to fit two linear models to our continuous outcome of interest, (here, Y). The first model should only use DOSE as predictor, the second model should use all predictors. For both models, the metric to optimize should be RMSE\n\n\nModel specification\n\n# Define linear regression models for fitting: one with DOSE only, another with all predictors\n# dose\nmodel_spec_dose &lt;- linear_reg() %&gt;% \n  set_engine(\"lm\") %&gt;%\n  set_mode(\"regression\")\n\n# all predictors\nmodel_spec_all &lt;- linear_reg() %&gt;%\n  set_engine(\"lm\") %&gt;%\n  set_mode(\"regression\")"
  },
  {
    "objectID": "fitting-exercise/fitting-exercise.html#creating-and-preparing-a-recipe",
    "href": "fitting-exercise/fitting-exercise.html#creating-and-preparing-a-recipe",
    "title": "fitting-exercise",
    "section": "Creating and Preparing a Recipe",
    "text": "Creating and Preparing a Recipe\n\nThe process involves defining a data preprocessing recipe tailored to the training dataset and incorporating this unprepared recipe into model-specific workflows. Once the workflows are fitted to the training data, the recipe is automatically prepared and applied, seamlessly integrating data preprocessing with model training.\n\n# Define two recipes: one for the DOSE-only model and another for the All-predictors model\n\n# Define the recipe for the DOSE-only model without immediately preparing it\nmav_recipe_dose &lt;- recipe(Y ~ DOSE, data = mav10_train_75pct) %&gt;%\n  step_dummy(all_nominal(), -all_outcomes())\n\n# Define the recipe for the All-predictors model without immediately preparing it\nmav_recipe_all &lt;- recipe(Y ~ ., data = mav10_train_75pct) %&gt;%\n  step_dummy(all_nominal(), -all_outcomes())\n\n# Now, you can add these unprepared recipes to the workflows\nworkflow_dose &lt;- workflow() %&gt;%\n  add_model(model_spec_dose) %&gt;%\n  add_recipe(mav_recipe_dose)\n\nworkflow_all &lt;- workflow() %&gt;%\n  add_model(model_spec_all) %&gt;%\n  add_recipe(mav_recipe_all)\n\n# Fit the workflows to the training data\nfit_dose &lt;- fit(workflow_dose, data = mav10_train_75pct)\nfit_all &lt;- fit(workflow_all, data = mav10_train_75pct)\n\nMaking Predictions and Calculating RMSE #### This code segment generates predictions using two different models (fit_dose and fit_all) on a testing dataset (mav10_train_75pct), then computes the Root Mean Squared Error (RMSE) for each model’s predictions compared to the true values (Y).\n\n# Make predictions on the testing set and calculate RMSE for each model\npreds_dose &lt;- predict(fit_dose, new_data = mav10_train_75pct) %&gt;%\n  bind_cols(mav10_train_75pct)\npreds_all &lt;- predict(fit_all, new_data = mav10_train_75pct) %&gt;%\n  bind_cols(mav10_train_75pct)\nrmse_dose &lt;- rmse(preds_dose, truth = Y, estimate = .pred)\nrmse_all &lt;- rmse(preds_all, truth = Y, estimate = .pred)"
  },
  {
    "objectID": "fitting-exercise/fitting-exercise.html#calculating-rmse-and-model-comparison",
    "href": "fitting-exercise/fitting-exercise.html#calculating-rmse-and-model-comparison",
    "title": "fitting-exercise",
    "section": "Calculating RMSE and Model Comparison",
    "text": "Calculating RMSE and Model Comparison\n\nThis code block manually computes the Root Mean Squared Error (RMSE) for three different models: the ‘DOSE’ model, the ‘All Predictors’ model, and a Null model. It then prints the RMSE values to compare the performance of each model.\n\n# Manually calculate the mean of 'Y' from the training set for the null model\nmean_y &lt;- mean(mav10_train_75pct$Y, na.rm = TRUE)\nnull_predictions &lt;- rep(mean_y, nrow(mav10_train_75pct))\nnull_rmse &lt;- sqrt(mean((mav10_train_75pct$Y - null_predictions)^2))\n\n# Print RMSE values to compare model performances\ncat(\"RMSE for DOSE model:\", rmse_dose$.estimate, \"\\n\")\n\nRMSE for DOSE model: 702.7909 \n\ncat(\"RMSE for All Predictors model:\", rmse_all$.estimate, \"\\n\")\n\nRMSE for All Predictors model: 627.2724 \n\ncat(\"RMSE for Null model (manual):\", null_rmse, \"\\n\")\n\nRMSE for Null model (manual): 948.3526 \n\n\n#Model performance assessment 2 ## Cross validation (CV) ### Set seed\n\n#use the same seed as the previous section 1234\nset.seed(rngseed2)  # Ensuring reproducibility\n\n\n# Set the seed for reproducibility\nset.seed(rngseed2)\n\n# Define the 10-fold cross-validation folds\ncv_folds10 &lt;- vfold_cv(mav10_train_75pct, v = 10)\n\n# Define the model specifications \nmodel_spec_dose &lt;- linear_reg() %&gt;%\n  set_engine(\"lm\") %&gt;%\n  set_mode(\"regression\")\n\nmodel_spec_all &lt;- linear_reg() %&gt;%\n  set_engine(\"lm\") %&gt;%\n  set_mode(\"regression\")\n\n# Define workflows\nworkflow_dose &lt;- workflow() %&gt;%\n  add_model(model_spec_dose) %&gt;%\n  add_formula(Y ~ DOSE)\n\nworkflow_all &lt;- workflow() %&gt;%\n  add_model(model_spec_all) %&gt;%\n  add_formula(Y ~ .)\n\n# Perform cross-validation for the DOSE-only model\ncv_results_dose &lt;- fit_resamples(\n  workflow_dose,\n  cv_folds10,\n  metrics = metric_set(rmse)\n)\n\n# Perform cross-validation for the All-predictor model\ncv_results_all &lt;- fit_resamples(\n  workflow_all,\n  cv_folds10,\n  metrics = metric_set(rmse)\n)\n\n# cv_results_dose and cv_results_all contain the cross-validation results\n\n# Extract and average RMSE for the DOSE-only model\ncv_summary_dose &lt;- cv_results_dose %&gt;% \n  collect_metrics() %&gt;% \n  filter(.metric == \"rmse\") %&gt;% \n  summarize(mean_rmse_cv = mean(mean, na.rm = TRUE)) %&gt;%\n  pull(mean_rmse_cv)\n\n# Extract and average RMSE for the All-predictors model\ncv_summary_all &lt;- cv_results_all %&gt;% \n  collect_metrics() %&gt;% \n  filter(.metric == \"rmse\") %&gt;% \n  summarize(mean_rmse_cv = mean(mean, na.rm = TRUE)) %&gt;%\n  pull(mean_rmse_cv)\n\n# Assuming cv_results_dose and cv_results_all contain the cross-validation results\n\n# Extract and average RMSE for the DOSE-only model\ncv_summary_dose &lt;- cv_results_dose %&gt;% \n  collect_metrics() %&gt;% \n  filter(.metric == \"rmse\") %&gt;% \n  summarize(mean_rmse_cv = mean(mean, na.rm = TRUE)) %&gt;%\n  pull(mean_rmse_cv)\n\n# Extract and average RMSE for the All-predictors model\ncv_summary_all &lt;- cv_results_all %&gt;% \n  collect_metrics() %&gt;% \n  filter(.metric == \"rmse\") %&gt;% \n  summarize(mean_rmse_cv = mean(mean, na.rm = TRUE)) %&gt;%\n  pull(mean_rmse_cv)\n\nlibrary(dplyr)\n\n# Summarize RMSE for DOSE-only model\nsummary_dose &lt;- cv_results_dose %&gt;% collect_metrics()\n\n# Summarize RMSE for All-predictor model\nsummary_all &lt;- cv_results_all %&gt;% collect_metrics()\n\n# Combine summaries into a single table\ncombined_summary &lt;- bind_rows(\n  data.frame(Model = \"DOSE-only\", summary_dose),\n  data.frame(Model = \"All-predictor\", summary_all)\n)\n\n# Print the combined summary\nprint(combined_summary)\n\n          Model .metric .estimator     mean  n  std_err              .config\n1     DOSE-only    rmse   standard 696.7098 10 68.09511 Preprocessor1_Model1\n2 All-predictor    rmse   standard 652.7739 10 63.59876 Preprocessor1_Model1"
  },
  {
    "objectID": "fitting-exercise/fitting-exercise.html#interpreting-the-results",
    "href": "fitting-exercise/fitting-exercise.html#interpreting-the-results",
    "title": "fitting-exercise",
    "section": "Interpreting the results",
    "text": "Interpreting the results\n\nDose only model\n\nFor the DOSE-only model, the RMSE obtained through cross-validation is slightly lower than the initial RMSE. This indicates that the model is quite stable and generalizes well to unseen data. The slight improvement in RMSE suggests that the initial evaluation might have slightly overestimated the model’s error, and the model actually performs a bit better on average across different subsets of the data."
  },
  {
    "objectID": "fitting-exercise/fitting-exercise.html#all-predictor-model",
    "href": "fitting-exercise/fitting-exercise.html#all-predictor-model",
    "title": "fitting-exercise",
    "section": "All predictor model",
    "text": "All predictor model\n\nIn contrast, for the All-predictors model, the CV RMSE is higher than the initial RMSE. This could indicate that the model, when evaluated on the training set, might have been slightly overfitting to that specific data. When the model is assessed through cross-validation, which involves training and evaluating the model on multiple subsets of the data, the average error increases. This suggests that the model’s predictions are not as consistent across different subsets of data, highlighting a potential overfitting issue where the model learns specific patterns in the training set that don’t generalize as well to unseen data."
  },
  {
    "objectID": "fitting-exercise/fitting-exercise.html#null-model",
    "href": "fitting-exercise/fitting-exercise.html#null-model",
    "title": "fitting-exercise",
    "section": "Null model",
    "text": "Null model\n\nThe Null Model, serving as a baseline, simply predicts the mean outcome for all observations without using any predictors. There’s no variation in its predictions, so cross-validation does not apply. The RMSE here serves to underscore the baseline level of error when no predictive modeling is attempted.\n\n# Set new seed for reproducibility\nset.seed(4444)  \n\n\n# Split the data into a 75% training set and a 25% test set\ndata_split_mav_new &lt;- initial_split(mav_ex10, prop = 0.75)\n\n# Extract the training and test sets\nmav10_train_75pct_new &lt;- training(data_split_mav)\nmav10_test_25pct_new &lt;- testing(data_split_mav)\n\n# Define the 10-fold cross-validation folds\ncv_folds10_new &lt;- vfold_cv(mav10_train_75pct_new, v = 10)  # Assuming mav10_train_75pct_new is the new dataframe\n\n# Define the model specifications \nmodel_spec_dose_new &lt;- linear_reg() %&gt;%\n  set_engine(\"lm\") %&gt;%\n  set_mode(\"regression\")\n\nmodel_spec_all_new &lt;- linear_reg() %&gt;%\n  set_engine(\"lm\") %&gt;%\n  set_mode(\"regression\")\n\n# Define workflows\nworkflow_dose_new &lt;- workflow() %&gt;%\n  add_model(model_spec_dose_new) %&gt;%\n  add_formula(Y ~ DOSE)\n\nworkflow_all_new &lt;- workflow() %&gt;%\n  add_model(model_spec_all_new) %&gt;%\n  add_formula(Y ~ .)\n\n# Perform cross-validation for the DOSE-only model\ncv_results_dose_new &lt;- fit_resamples(\n  workflow_dose_new,\n  cv_folds10_new,\n  metrics = metric_set(rmse)\n)\n\n# Perform cross-validation for the All-predictor model\ncv_results_all_new &lt;- fit_resamples(\n  workflow_all_new,\n  cv_folds10_new,\n  metrics = metric_set(rmse)\n)\n\n# Extract and average RMSE for the DOSE-only model\ncv_summary_dose_new &lt;- cv_results_dose_new %&gt;% \n  collect_metrics() %&gt;% \n  filter(.metric == \"rmse\") %&gt;% \n  summarize(mean_rmse_cv = mean(mean, na.rm = TRUE)) %&gt;%\n  pull(mean_rmse_cv)\n\n# Extract and average RMSE for the All-predictors model\ncv_summary_all_new &lt;- cv_results_all_new %&gt;% \n  collect_metrics() %&gt;% \n  filter(.metric == \"rmse\") %&gt;% \n  summarize(mean_rmse_cv = mean(mean, na.rm = TRUE)) %&gt;%\n  pull(mean_rmse_cv)\n\n# Summarize RMSE for DOSE-only model\nsummary_dose_new &lt;- cv_results_dose_new %&gt;% collect_metrics()\n\n# Summarize RMSE for All-predictor model\nsummary_all_new &lt;- cv_results_all_new %&gt;% collect_metrics()\n\n# Combine summaries into a single table\ncombined_summary_new &lt;- bind_rows(\n  data.frame(Model = \"DOSE-only\", summary_dose_new),\n  data.frame(Model = \"All-predictor\", summary_all_new)\n)\n\n# Print the combined summary\nprint(combined_summary_new)\n\n          Model .metric .estimator     mean  n  std_err              .config\n1     DOSE-only    rmse   standard 712.7537 10 64.50994 Preprocessor1_Model1\n2 All-predictor    rmse   standard 646.3119 10 69.04694 Preprocessor1_Model1\n\n# Print RMSE values to compare model performances\ncat(\"RMSE for DOSE model:\", rmse_dose$.estimate, \"\\n\")\n\nRMSE for DOSE model: 702.7909 \n\ncat(\"RMSE for All Predictors model:\", rmse_all$.estimate, \"\\n\")\n\nRMSE for All Predictors model: 627.2724 \n\ncat(\"RMSE for Null model (manual):\", null_rmse, \"\\n\")\n\nRMSE for Null model (manual): 948.3526 \n\n\n\n\nWhen a different random seed was used, the RMSE directions changed. For Dose-Only the mean RMSE went up to 712. This suggests that using the randomizationm from this seed, subsets are not as consistent than in the seed1234.\n\n\nOn the other hand, the RMSE for the all predictors CV model improved slightly. This suggests that model based on this randomization is stabler and generalizes well to unseen data."
  },
  {
    "objectID": "fitting-exercise/fitting-exercise.html#using-the-bootstrap-method-to-test-for-model-uncertainty",
    "href": "fitting-exercise/fitting-exercise.html#using-the-bootstrap-method-to-test-for-model-uncertainty",
    "title": "fitting-exercise",
    "section": "Using the Bootstrap Method to test for Model Uncertainty",
    "text": "Using the Bootstrap Method to test for Model Uncertainty\n\nlibrary(tidymodels)\nlibrary(purrr) # For the map function\n\n# Set the random seed for reproducibility\nset.seed(rngseed2) # Make sure rngseed2 is defined\n\n# Create 100 bootstrap samples of the training data\nboot_samples &lt;- bootstraps(mav10_train_75pct, times = 100)\n\n# Use the 'workflow_all' to fit the model to each of the bootstrap samples \n# and make predictions on the original training data\npredictions_list &lt;- boot_samples$splits %&gt;%\n  map(.f = ~{\n    # Extract the analysis (training) set from the current bootstrap sample\n    boot_data &lt;- analysis(.x)\n    \n    # Fit the workflow to the bootstrap sample. Assuming 'workflow_all' includes your model and preprocessing steps\n    fitted_workflow &lt;- fit(workflow_all, data = boot_data)\n    \n    # Make predictions on the original training data using the fitted workflow\n    predict(fitted_workflow, new_data = mav10_train_75pct)$.pred\n  })\n# Check the length of the predictions list\n# it should be 100\nlength(predictions_list)\n\n[1] 100\n\n\n\n# Step 1: Convert the list of prediction vectors into a matrix with bootstrap samples as columns\nbootstrap_predictions_matrix &lt;- do.call(cbind, predictions_list)\n\n# Ensure that the matrix is correctly oriented (observations as rows, bootstrap samples as columns)\n# This should already be the case based on the description\n\n# Step 2: Compute the median and 89% confidence intervals for each observation across bootstrap samples\nmodel2_median_and_CI89 &lt;- apply(bootstrap_predictions_matrix, 1, quantile, probs = c(0.055, 0.5, 0.945)) %&gt;% t()\n\n# model2_median_and_CI89 now contains the median and confidence intervals for each observation\n\n# Convert the results into a dataframe for easier handling and potentially merging with your original data\nCI_df &lt;- as.data.frame(model2_median_and_CI89)\nnames(CI_df) &lt;- c(\"Lower CI (5.5%)\", \"Median\", \"Upper CI (94.5%)\")\n\n# View the first few rows to verify\nhead(CI_df)\n\n  Lower CI (5.5%)   Median Upper CI (94.5%)\n1        3095.536 3345.767         3553.229\n2        1688.124 1962.397         2185.772\n3        2420.566 2717.821         2937.470\n4        1798.039 2094.438         2386.281\n5        2660.761 2936.070         3141.177\n6        1066.095 1301.015         1490.740\n\n# At this point, CI_df  will contain the median prediction and confidence intervals for each observation in your original dataset.\n\n\noriginal_predictions &lt;- preds_all_df$Predicted\nobserved_values &lt;- preds_all_df$Observed\n\n# Adjust column names if they differ in your preds_all_df dataset\n# Create the bootstrap_stats_df from the quantiles obtained previously\nbootstrap_stats_df &lt;- data.frame(\n  Lower_Bound = model2_median_and_CI89[, \"5.5%\"],\n  Median = model2_median_and_CI89[, \"50%\"],\n  Upper_Bound = model2_median_and_CI89[, \"94.5%\"]\n)\n\n# Ensure all data frames have the same number of rows\nstopifnot(nrow(bootstrap_stats_df) == length(original_predictions))\nstopifnot(length(original_predictions) == length(observed_values))\n\n# Create plot_data with all predictions\nplot_data &lt;- data.frame(\n  Observed = observed_values,\n  Original_Predictions = original_predictions\n)\n\n# Combine the original predictions with the bootstrap statistics\nplot_data &lt;- cbind(plot_data, bootstrap_stats_df)\n\n# Now pivot the plot_data to long format for ggplot2\nplot_data_long &lt;- pivot_longer(\n  plot_data,\n  cols = c(\"Original_Predictions\", \"Lower_Bound\", \"Median\", \"Upper_Bound\"),\n  names_to = \"Prediction_Type\",\n  values_to = \"Predicted_Values\"\n)\n\n# Define the order for the predictions explicitly\nprediction_levels &lt;- c(\"Lower_Bound\", \"Median\", \"Upper_Bound\", \"Original_Predictions\")\n\n# Set the levels for the 'Prediction_Type' factor based on the desired order\nplot_data_long$Prediction_Type &lt;- factor(plot_data_long$Prediction_Type, levels = prediction_levels)\n\n# Define intuitive colors for predictions\ncolors &lt;- c(\"Lower_Bound\" = \"darkolivegreen3\", \"Median\" = \"lightblue\", \"Upper_Bound\" = \"coral3\", \"Original_Predictions\" = \"black\")\n\n# Plot with ggplot2\nggplot(plot_data_long, aes(x = Observed, y = Predicted_Values, color = Prediction_Type)) +\n  geom_point(size = 1.2) +\n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\", color = \"black\") +\n  scale_color_manual(values = colors) +\n  labs(x = \"Observed Values\", y = \"Predicted Values\", color = \"Prediction Type\") +\n  theme_minimal() +\n  scale_x_continuous(limits = c(0, 5000), expand = expansion(mult = c(0, 0.05))) +\n  scale_y_continuous(limits = c(0, 5000), expand = expansion(mult = c(0, 0.05))) +\n  coord_fixed(ratio = 1)\n\nWarning: Removed 4 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n# Ensure plot_data contains 'Observed', 'Original_Predictions', 'Median', 'Lower_Bound', and 'Upper_Bound'\n\n# Calculate summary statistics for observed values\nobserved_summary &lt;- summary(plot_data$Observed)\n\n# Calculate summary statistics for original model predictions\noriginal_pred_summary &lt;- summary(plot_data$Original_Predictions)\n\n# Calculate summary statistics for bootstrap median predictions\nbootstrap_median_summary &lt;- summary(plot_data$Median)\n\n# Create a data frame with summary statistics directly from summary objects\nsummary_table &lt;- tibble(\n  Statistic = c(\"Min.\", \"1st Qu.\", \"Median\", \"Mean\", \"3rd Qu.\", \"Max.\"),\n  Observed = as.numeric(observed_summary),\n  Original_Predictions = as.numeric(original_pred_summary),\n  Bootstrap_Median = as.numeric(bootstrap_median_summary)\n)\n\n# Display the summary table\nprint(summary_table)\n\n# A tibble: 6 × 4\n  Statistic Observed Original_Predictions Bootstrap_Median\n  &lt;chr&gt;        &lt;dbl&gt;                &lt;dbl&gt;            &lt;dbl&gt;\n1 Min.          826.                1267.            1288.\n2 1st Qu.      1803.                1961.            1947.\n3 Median       2398.                2413.            2431.\n4 Mean         2509.                2509.            2523.\n5 3rd Qu.      3104.                3206.            3217.\n6 Max.         5607.                3961.            3987."
  },
  {
    "objectID": "fitting-exercise/fitting-exercise.html#back-to-andrew-ruiz",
    "href": "fitting-exercise/fitting-exercise.html#back-to-andrew-ruiz",
    "title": "fitting-exercise",
    "section": "Back to Andrew Ruiz",
    "text": "Back to Andrew Ruiz\n\nUse the fit of model 2 using the training data you computed previously, and now use this fitted model to make predictions for the test data. This gives us an indication how our model generalizes to data that wasn’t used to construct/fit/train the model.\n\n# Make predictions on the test dataset\ntest_predictions &lt;- predict(fit_all, new_data = mav10_test_25pct)\n\n# Assuming a regression task, extract the predicted values\n# If your task is classification, adjust to use `.pred_class` or appropriate column\ntest_predicted_values &lt;- test_predictions$.pred\n\n# Optionally, compare these predicted values with the actual outcomes in your test dataset\n# This step requires your test dataset to include the actual outcome variable, let's say it's named 'Y'\n\n# Assuming the actual outcomes are in mav10_test_25pct under 'Y'\nactual_outcomes &lt;- mav10_test_25pct$Y\n\n# Calculate performance metrics, e.g., RMSE for regression tasks\nrmse_value &lt;- sqrt(mean((actual_outcomes - test_predicted_values)^2))\n\n# Assuming calculation of RMSE for training data is similar to test data\ntrain_rmse &lt;- sqrt(mean((mav10_train_75pct$Y - predict(fit_all, mav10_train_75pct)$.pred)^2))\n\n# Create a summary table of performance metrics\nperformance_summary &lt;- tibble(\n  Dataset = c(\"Training\", \"Test\"),\n  RMSE = c(train_rmse, rmse_value)\n)\n\n# Display the table\nprint(performance_summary)\n\n# A tibble: 2 × 2\n  Dataset   RMSE\n  &lt;chr&gt;    &lt;dbl&gt;\n1 Training  627.\n2 Test      518.\n\n\n\n\nMake a plot that shows predicted versus observed for both the training data (which you did above) and in the same plot, also show predicted versus observed for the test data (using, e.g. different symbols or colors).\n\n# Step 1: Prepare the data\n\n# For training data predictions \ntrain_predicted_values &lt;- predict(fit_all, new_data = mav10_train_75pct)$.pred\ntrain_data_plot &lt;- mav10_train_75pct %&gt;%\n  mutate(Predicted = train_predicted_values, DataSet = \"Training\")\n\n# For test data predictions\ntest_data_plot &lt;- mav10_test_25pct %&gt;%\n  mutate(Predicted = test_predicted_values, DataSet = \"Test\")\n\n# Combine training and test data for plotting\nplot_data &lt;- bind_rows(train_data_plot, test_data_plot)\n\n# Ensure your outcome variable name is correctly specified instead of 'Y'\nplot_data$Observed &lt;- plot_data$Y\n\n# Step 2: Plot using ggplot2\nggplot(plot_data, aes(x = Observed, y = Predicted, color = DataSet)) +\n  geom_point(aes(shape = DataSet), size = 2) +\n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\", color = \"grey\") +\n  scale_color_manual(values = c(\"Training\" = \"blue\", \"Test\" = \"red\")) +\n  labs(x = \"Observed Values\", y = \"Predicted Values\", title = \"Predicted vs Observed Values\") +\n  theme_minimal() +\n  scale_shape_manual(values = c(\"Training\" = 16, \"Test\" = 17)) + # Different shapes for training and test\n  xlim(0, 5000) + # Setting x-axis limits\n  ylim(0, 5000) +   # Setting y-axis limits\n  theme(aspect.ratio = 1, legend.position = \"bottom\", legend.direction = \"horizontal\") # Square aspect ratio and horizontal legend at the bottom\n\nWarning: Removed 1 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\nDoes model 1 with only dose in the model improve results over the null model? Do the results make sense? Would you consider this model “usable” for any real purpose?\n\nThe dose model seems to improve over the Null Model in that it at least captures some variability in the data that the Null Model, which simply predicts a constant value, does not.\n\n\nThe results show that the model predictions cluster into three distinct horizontal bands, which makes sense if the dose is a categorical variable with three levels. This implies that the model predicts different average values for each dose level but does not account for any other variation within those levels.\n\n\nThe Dose Model has a significantly lower RMSE compared to the Null Model, indicating it provides a better fit to the data. This suggests that the dose variable alone has a substantial effect on the outcome and the model is able to capture a meaningful portion of the variance in the data.\n\n\nThe Dose Model is more accurate than just guessing the average (Null Model), so it might be usable in scenarios where the predictions do not need to be highly precise, or if dose is the only available information.\n\n\nThe Dose Model can be considered usable with the understanding that there is a trade-off between simplicity and accuracy. It may be sufficient for certain applications, especially when other predictors are not available or if the decision-making process can tolerate a higher level of error. However, where accuracy is more critical, the Full Model is the superior choice.\n\n\n\nDoes model 2 with all predictors further improve results? Do the results make sense? Would you consider this model “usable” for any real purpose?\n\nThe RMSE on the test set is 518.22 and improvement over the CV RSME. This suggests that the model is not overfitting to the training data.\n\n\nThe results make sense. The predictors are logical and likely carry meaningful information about the target variable.\n\n\nConsidering the model’s performance and the fact that it uses standard biometric predictors, the model appears usable for real-world applications.\n\n\nBefore using the model in practice, it would be essential to validate its performance on a larger and more diverse external dataset and to ensure its decisions are interpretable and actionable in a clinical context.\n\n\nIn summary, the information suggests that Model 2 with all predictors does improve results over the simpler Dose-only model and over the null model. The lower RMSE in both cross-validation and testing indicates the model has learned to generalize well. Yes, provided the model passes further validation and ethical review, it could be considered usable for real-world applications where the outcome variable is of interest."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My website and data analysis portfolio",
    "section": "",
    "text": "This is my website and data analysis portfolio. It currently under development. More content will be added throughout the semester, so make sure to visit again.\n\nPlease use the Menu Bar above to look around.\n\nThe “About Me” section is complete\n\n\n\n\nEmail: andrew.ruiz@uga.edu\nLinkedIn: Connect with me here"
  },
  {
    "objectID": "index.html#thanks-for-dropping-by",
    "href": "index.html#thanks-for-dropping-by",
    "title": "My website and data analysis portfolio",
    "section": "",
    "text": "This is my website and data analysis portfolio. It currently under development. More content will be added throughout the semester, so make sure to visit again.\n\nPlease use the Menu Bar above to look around.\n\nThe “About Me” section is complete\n\n\n\n\nEmail: andrew.ruiz@uga.edu\nLinkedIn: Connect with me here"
  },
  {
    "objectID": "tidytuesday-exercise/tidytuesday-exercise.html",
    "href": "tidytuesday-exercise/tidytuesday-exercise.html",
    "title": "Tidy Tuesday Exercise",
    "section": "",
    "text": "Placeholder file for the future Tidy Tuesday exercise."
  },
  {
    "objectID": "data-exercise/data-exercise.html",
    "href": "data-exercise/data-exercise.html",
    "title": "Data Exercise",
    "section": "",
    "text": "The source of the text for this exercise come from public comments in response to Public Citizens second petition for rulemaking to the Federal Election Commission (FEC) in July, 2023. Public Citizen asked the FEC to clarify the subject of “fraudulent misrepresentation” regarding the use of AI, including deep fake technology, and open a Notice of Availability that would allow public comment.\nFifty pdfs were downloaded from the FEC site. Each pdf contained comments in response to Public Citizens petition.\nThese fifty documents made up the corpus for the text analysis. The process is described below.\n\nif (!require(syuzhet)) {\n  install.packages(\"syuzhet\")\n}\n\nLoading required package: syuzhet\n\n#load packages\nlibrary(pdftools)\n\nUsing poppler version 23.04.0\n\nlibrary(tm)\n\nLoading required package: NLP\n\nlibrary(topicmodels)\nlibrary(syuzhet)\nlibrary(tokenizers)\nlibrary(here)\n\nhere() starts at /Users/andrewruiz/MADA_course/andrew_ruiz-MADA-portfolio"
  },
  {
    "objectID": "data-exercise/data-exercise.html#locate-and-read-the-pdfs",
    "href": "data-exercise/data-exercise.html#locate-and-read-the-pdfs",
    "title": "Data Exercise",
    "section": "Locate and read the PDFs",
    "text": "Locate and read the PDFs\n\n# Specify the folder containing the PDFs\npdf_folder &lt;- here(\"data-exercise\", \"data\", \"raw-data\")\n\n# Read all PDF files from the folder\nfile_list &lt;- list.files(path = pdf_folder, pattern = \"*.pdf\", full.names = TRUE)"
  },
  {
    "objectID": "data-exercise/data-exercise.html#process-files",
    "href": "data-exercise/data-exercise.html#process-files",
    "title": "Data Exercise",
    "section": "Process files",
    "text": "Process files\nNow that the files are located and read, we will begin processing them for analysis\n\n# Extract text from each PDF\ntext_data &lt;- lapply(file_list, pdf_text)\n\n# Combine the text into one character vector, one element per PDF\ntext_data_combined &lt;- sapply(text_data, paste, collapse = \" \")\n\n# Create a corpus from the combined text\ndocs &lt;- Corpus(VectorSource(text_data_combined))"
  },
  {
    "objectID": "data-exercise/data-exercise.html#cleaning-the-text",
    "href": "data-exercise/data-exercise.html#cleaning-the-text",
    "title": "Data Exercise",
    "section": "Cleaning the text",
    "text": "Cleaning the text\nTo analyze the text we will need to clean in and prepare it for use.\n\nclean_corpus_initial &lt;- function(corpus) {\n  original_length &lt;- length(corpus)\n  # convert text to lowercase\n  corpus &lt;- tm_map(corpus, content_transformer(tolower))\n  # remove punctuation\n  corpus &lt;- tm_map(corpus, removePunctuation)\n  # remove numbers\n  corpus &lt;- tm_map(corpus, removeNumbers)\n  # remove stop words (common words like 'the', 'and', 'is)\n  corpus &lt;- tm_map(corpus, removeWords, stopwords(\"english\"))\n  # remove extra whitespaces\n  corpus &lt;- tm_map(corpus, stripWhitespace)\n  \n  # Return the cleaned corpus along with the indices of dropped documents\n  return(list(corpus = corpus, original_length = original_length))\n}\n\n# Apply initial cleaning\nresult &lt;- clean_corpus_initial(docs)\n\nWarning in tm_map.SimpleCorpus(corpus, content_transformer(tolower)):\ntransformation drops documents\n\n\nWarning in tm_map.SimpleCorpus(corpus, removePunctuation): transformation drops\ndocuments\n\n\nWarning in tm_map.SimpleCorpus(corpus, removeNumbers): transformation drops\ndocuments\n\n\nWarning in tm_map.SimpleCorpus(corpus, removeWords, stopwords(\"english\")):\ntransformation drops documents\n\n\nWarning in tm_map.SimpleCorpus(corpus, stripWhitespace): transformation drops\ndocuments\n\n# There was a warning that documents had been dropped. This code will check to see which ones and how many.\ncorpus_cleaned &lt;- result$corpus\noriginal_length &lt;- result$original_length\n\ncat(\"Original number of documents:\", original_length, \"\\n\")\n\nOriginal number of documents: 50 \n\ncat(\"Number of documents after cleaning:\", length(corpus_cleaned), \"\\n\")\n\nNumber of documents after cleaning: 50 \n\ncat(\"Number of documents dropped:\", original_length - length(corpus_cleaned), \"\\n\")\n\nNumber of documents dropped: 0 \n\n# Identify the indices of dropped documents\ndropped_indices &lt;- setdiff(1:original_length, 1:length(corpus_cleaned))\ncat(\"Indices of dropped documents:\", paste(dropped_indices, collapse = \", \"), \"\\n\")\n\nIndices of dropped documents:  \n\n# The output indicates that zero documents were dropped\n\nNow that the text is clean we can proceed to the next step.\n\n# Create a Document-Term Matrix (DTM) from the cleaned text documents (docs_cleaned_initial).\n# Remove rows (documents) from the DTM where the sum of term frequencies is zero,\n# effectively filtering out empty documents.\ndtm_initial &lt;- DocumentTermMatrix(corpus_cleaned)\ndtm_initial &lt;- dtm_initial[rowSums(as.matrix(dtm_initial)) &gt; 0, ]\n\nWe will now create a Latent Dirichlet Allocation (LDA) model. An LDA is statistical model used in natural language processing and machine learning.\n\n# Set the number of topics to 8\n# this can be modified depending on the need and results\nk_initial &lt;- 8\n\n# Create an LDA model using the Document-Term Matrix (dtm_initial) with the specified number of topics.\n# Control parameters may include the random seed for reproducibility (seed = 4321).\nlda_model_initial &lt;- LDA(dtm_initial, k = k_initial, control = list(seed = 4321))\n\n# Retrieve the terms associated with each topic, specifying a maximum of 8 terms per topic.\ntopics_initial &lt;- terms(lda_model_initial, 8)\n\n# Print the initial topics along with potential terms that describe each topic.\nprint(\"Initial topics with potential names included:\")\n\n[1] \"Initial topics with potential names included:\"\n\nprint(topics_initial)\n\n     Topic 1        Topic 2   Topic 3      Topic 4    Topic 5     Topic 6     \n[1,] \"campaign\"     \"mary\"    \"campaign\"   \"john\"     \"ads\"       \"content\"   \n[2,] \"comments\"     \"michael\" \"deepfakes\"  \"patricia\" \"provided\"  \"can\"       \n[3,] \"ads\"          \"robert\"  \"election\"   \"donna\"    \"campaigns\" \"campaign\"  \n[4,] \"deceptive\"    \"david\"   \"candidate\"  \"susan\"    \"never\"     \"generative\"\n[5,] \"content\"      \"barbara\" \"political\"  \"linda\"    \"depicting\" \"election\"  \n[6,] \"misleading\"   \"richard\" \"commission\" \"margaret\" \"law\"       \"federal\"   \n[7,] \"saying\"       \"linda\"   \"public\"     \"thomas\"   \"comments\"  \"use\"       \n[8,] \"ai‐generated\" \"susan\"   \"fraudulent\" \"david\"    \"use\"       \"commission\"\n     Topic 7      Topic 8    \n[1,] \"campaign\"   \"campaign\" \n[2,] \"comments\"   \"ads\"      \n[3,] \"saying\"     \"deceptive\"\n[4,] \"deceptive\"  \"law\"      \n[5,] \"misleading\" \"campaigns\"\n[6,] \"content\"    \"never\"    \n[7,] \"understand\" \"comments\" \n[8,] \"release\"    \"depicting\"\n\n\nWe now have 8 topics with the most common words associated with each topic. Notice that topic 2 is a list of first names. This is not especially helpful in this case. However, let’s proceed with these topics and see if we can fix them later. Next we will see the theme associated with each document.\n\n# Extract the topic for each document for the initial model\ntopic_probabilities_initial &lt;- posterior(lda_model_initial)$topics\ndoc_topics_initial &lt;- apply(topic_probabilities_initial, 1, which.max)\n\n# Create a data frame for the document-topic associations for the initial model\ndoc_topics_df_initial &lt;- data.frame(Document = names(doc_topics_initial), MostLikelyTopic = doc_topics_initial)\n\n# View the first few rows of the document-topic association for the initial model\nhead(doc_topics_df_initial)\n\n  Document MostLikelyTopic\n1        1               3\n2        2               3\n3        3               6\n4        4               6\n5        5               3\n6        6               6\n\n\nLet’s include those names in the stopword list to see if the results are better.\n\n# Extend the stopwords list with common names for refined cleaning\ncustom_stopwords &lt;- c(stopwords(\"en\"), \"john\", \"patricia\", \"donna\", \"susan\", \"linda\", \"margaret\", \"thomas\", \"david\")\n\n# Refined cleaning function that includes removal of first names\nclean_corpus_refined &lt;- function(corpus) {\n  corpus &lt;- tm_map(corpus, content_transformer(tolower))\n  corpus &lt;- tm_map(corpus, removePunctuation)\n  corpus &lt;- tm_map(corpus, removeNumbers)\n  corpus &lt;- tm_map(corpus, removeWords, custom_stopwords)\n  corpus &lt;- tm_map(corpus, stripWhitespace)\n  return(corpus)\n}\n# Apply refined cleaning\ndocs_cleaned_refined &lt;- clean_corpus_refined(docs)\n\nWarning in tm_map.SimpleCorpus(corpus, content_transformer(tolower)):\ntransformation drops documents\n\n\nWarning in tm_map.SimpleCorpus(corpus, removePunctuation): transformation drops\ndocuments\n\n\nWarning in tm_map.SimpleCorpus(corpus, removeNumbers): transformation drops\ndocuments\n\n\nWarning in tm_map.SimpleCorpus(corpus, removeWords, custom_stopwords):\ntransformation drops documents\n\n\nWarning in tm_map.SimpleCorpus(corpus, stripWhitespace): transformation drops\ndocuments\n\n\nNow let’s rerun the code with the refined text.\n\n# DTM for refined analysis\ndtm_refined &lt;- DocumentTermMatrix(docs_cleaned_refined)\ndtm_refined &lt;- dtm_refined[rowSums(as.matrix(dtm_refined)) &gt; 0, ]\n\n\n# Refined topic modeling\nk_refined &lt;- 8\nlda_model_refined &lt;- LDA(dtm_refined, k = k_refined, control = list(seed = 4321))\ntopics_refined &lt;- terms(lda_model_refined, 8)\nprint(\"Refined topics without first names:\")\n\n[1] \"Refined topics without first names:\"\n\nprint(topics_refined)\n\n     Topic 1      Topic 2      Topic 3      Topic 4   Topic 5     Topic 6    \n[1,] \"never\"      \"content\"    \"never\"      \"mary\"    \"ads\"       \"ads\"      \n[2,] \"ads\"        \"election\"   \"ads\"        \"michael\" \"campaign\"  \"campaign\" \n[3,] \"law\"        \"campaign\"   \"comments\"   \"barbara\" \"campaigns\" \"never\"    \n[4,] \"campaign\"   \"deepfakes\"  \"law\"        \"robert\"  \"deceptive\" \"comments\" \n[5,] \"misleading\" \"federal\"    \"campaign\"   \"nancy\"   \"provided\"  \"law\"      \n[6,] \"americans\"  \"use\"        \"provided\"   \"richard\" \"depicting\" \"provided\" \n[7,] \"content\"    \"generative\" \"use\"        \"james\"   \"comments\"  \"campaigns\"\n[8,] \"worried\"    \"elections\"  \"misleading\" \"carol\"   \"voters\"    \"depicting\"\n     Topic 7             Topic 8     \n[1,] \"campaign\"          \"campaign\"  \n[2,] \"candidate\"         \"ads\"       \n[3,] \"commission\"        \"fec\"       \n[4,] \"fraudulent\"        \"election\"  \n[5,] \"political\"         \"generative\"\n[6,] \"deepfakes\"         \"federal\"   \n[7,] \"public\"            \"can\"       \n[8,] \"misrepresentation\" \"political\" \n\n\nSo it turns out that adding the names as stop words was not that helpful. It jsut returned another topic filled with names. For now, we will move on.\n\n# Extract the topic for each document for the refined model\ntopic_probabilities_refined &lt;- posterior(lda_model_refined)$topics\ndoc_topics_refined &lt;- apply(topic_probabilities_refined, 1, which.max)\n\n# Create a data frame for the document-topic associations for the refined model\ndoc_topics_df_refined &lt;- data.frame(Document = names(doc_topics_refined), MostLikelyTopic = doc_topics_refined)\n\n# View the first few rows of the document-topic association for the refined model\nhead(doc_topics_df_refined)\n\n  Document MostLikelyTopic\n1        1               2\n2        2               2\n3        3               2\n4        4               2\n5        5               2\n6        6               2\n\n\nIt turns out that topic two is not associated with documents 1-6 now that names were added to the stopword list. More investigation would be needed to uncover the meaning of this. ## Sentiment analysis now let’s take a look at the sentiment for each document. For this we will use the Bing method\n\n# Perform sentiment analysis on the combined text data\nsentiment_scores &lt;- get_sentiment(text_data_combined, method = \"bing\")\n\n# View the sentiment scores\nhead(sentiment_scores)\n\n[1]  -6 -24  -6  30  11  -8\n\n# Create a vector of PDF document names\npdf_document_names &lt;- basename(file_list)\n\n# Create a data frame with document names and sentiment scores\nsentiment_df &lt;- data.frame(DocumentName = pdf_document_names, SentimentScore = sentiment_scores)\n\n# Print the first few rows of the data frame to see the mapping\nhead(sentiment_df)\n\n          DocumentName SentimentScore\n1             aapc.pdf             -6\n2 accountable_tech.pdf            -24\n3              acm.pdf             -6\n4            Adobe.pdf             30\n5          afl_cio.pdf             11\n6         arnetfox.pdf             -8\n\nprint(sentiment_df)\n\n                           DocumentName SentimentScore\n1                              aapc.pdf             -6\n2                  accountable_tech.pdf            -24\n3                               acm.pdf             -6\n4                             Adobe.pdf             30\n5                           afl_cio.pdf             11\n6                          arnetfox.pdf             -8\n7  AsianAmericans_advancing_justice.pdf            -16\n8                       brennan_ctr.pdf             -7\n9                                BS.pdf              2\n10                               bv.pdf             -2\n11                               ca.pdf            -72\n12      campaign_for_accountability.pdf            -13\n13             catholic_social_just.pdf              1\n14                               cb.pdf           -131\n15                     common_cause.pdf            -37\n16                              CPD.pdf             -5\n17                             CREW.pdf             -6\n18                            crew2.pdf             -4\n19               ctr_democracy_tech.pdf             -5\n20            ctr_for_ai_dig_policy.pdf              0\n21                               dc.pdf           -222\n22                       demo_first.pdf             -3\n23                              dnc.pdf            -13\n24              election_protection.pdf             -2\n25                             epic.pdf              4\n26                     future_priva.pdf             -3\n27                              GMU.pdf             -4\n28                       harvardlaw.pdf            -20\n29                         holtzman.pdf            -13\n30 Institute for Strategic Dialogue.pdf             -5\n31                   integrity_inst.pdf              1\n32                        issue_dia.pdf              2\n33                               jm.pdf              3\n34                               lc.pdf           -241\n35                              lwv.pdf              2\n36                               MM.pdf              4\n37                               MR.pdf            -24\n38                        partnerAI.pdf              3\n39              people_power_united.pdf             -4\n40                              ppu.pdf              5\n41                protect_democracy.pdf            -13\n42                         pub_citz.pdf             -1\n43                     she_persists.pdf            -21\n44                      stabilityAI.pdf             21\n45                        StanfordU.pdf              3\n46                          technet.pdf             10\n47                           unidos.pdf            -21\n48                      US_congress.pdf             -1\n49                            wiley.pdf            -28\n50                   workers_circle.pdf             -2\n\n\nFor the text used in this analysis, the sentiment may be a little misleading. These comments were written in support of a second petition for the FEC to allow public comments of rulemaking. Most public comments in these forums begin by thanking the regulatory agency for allowing comments. Those sections tend to be very positive. However, the comments often continue by describing potential problem. Those tend to use negative language. The Bing method results are centered around 0. A zero score indicates completely neutral setiment. The larger negative scores indicate negative sentiment. Large positive scores indicate positive sentiment.\n\nLet’s take a look at a different way to identify sentiment. For this we will use the NRC method which classifies sentiment into categories that may make better sense of the data.\nThese results display word counts for the number of words in each document that fall into NRC’s sentiment categories. The bar graph represents the percent to words that fall into each category. The barchart represents all the text across all 50 documents.\n\n# define the data\nnrc_data &lt;- get_nrc_sentiment(text_data_combined)\n\n# Access the data frame columns for emotions and sentiments\n#anger_items &lt;- which(nrc_data$anger &gt; 0)\n#joy_items &lt;- which(nrc_data$joy &gt; 0)\n\n# Print sentences associated with specific emotions\n#print(text_data_combined[anger_items])\n#print(text_data_combined[joy_items])\n\n# View the entire sentiment data frame\nprint(nrc_data)\n\n   anger anticipation disgust fear joy sadness surprise trust negative positive\n1     10            6       6   13   5       3        4    22       21       37\n2     21           13      11   22   7       6        7    28       42       24\n3     11           15       7   15   8       7        5    34       26       44\n4     14           24       7   20  20      13        9    51       30       92\n5     16           16       7   19  12      12        7    37       29       56\n6     11           11       4   12   8       4        2    27       19       43\n7     17           11       6   24   6      13        4    28       34       44\n8     18           18       8   16   9       7        3    34       30       50\n9      1            4       1    2   2       1        1    11        8       20\n10     2            0       1    3   2       0        0     2        2        4\n11    68           48      39   75  29      52       27    97      133      158\n12    26           19      10   25  13      17        5    53       47       72\n13     6            8       3   11   7       2        5    17       15       24\n14   116           86      77  134  62      97       46   163      251      263\n15    31           21      15   38  15      26        9    58       66       92\n16     7            8       3   13   6       3        4    23       15       30\n17     9            3       6    7   3       4        2    11       16       18\n18     6            5       4    9   3       2        3    19       13       23\n19    18           17      10   21  13      15        7    48       46       79\n20    26           42      16   37  21      22       18    89       62      132\n21   161          139     100  194  93     131       79   245      374      390\n22     2            4       2    3   4       3        2    10       11       19\n23    17            8      12   18   5      10        7    34       35       47\n24     2            2       0    4   2       0        1     3        7       10\n25    11           10       5   13  14       9        6    32       30       69\n26    23           20      10   23  14      12        8    48       39       80\n27    19           23       8   21  22      13       10    58       48       83\n28    34           33      17   36  17      18       11    61       74       94\n29    20           18      13   19  10      13        7    43       51       59\n30     4            2       2    3   3       4        0     9        9       15\n31    24           35      11   35  19      16       11    78       57      124\n32     9           11       5   15  11      12        7    40       25       51\n33     2            1       2    3   5       2        0    11        7       16\n34   188          124     130  213  83     168       81   229      414      357\n35    12           15       5   11  10       6        5    29       20       52\n36     1            1       0    1   1       0        0     4        1        4\n37    17            9       8   23   7      10        2    38       44       53\n38    14           22       8   16  18      10        9    53       33       74\n39     3            3       2    4   3       3        1    11        8       19\n40    28           30      20   28  36      21       14    46       54       96\n41    21           15      12   20  12      17        6    52       49       72\n42    20           21      14   18  20      19       12    65       59       91\n43    16           14       8   21  12       6        5    34       35       48\n44    16           27       9   21  20      10        6    56       37       92\n45    10           10       6   12   6       5        0    28       22       44\n46     6            9       3    8   6       3        3    25       15       42\n47    19           16       8   20   7      12        5    41       35       61\n48     2            2       2    5   3       1        2    13        5       23\n49    15           13       8   22  13       9       11    45       44       56\n50     5            3       3    4   3       3        1    10       10       17\n\n# View only the positive and negative valence columns\nprint(nrc_data[, c(\"negative\", \"positive\")])\n\n   negative positive\n1        21       37\n2        42       24\n3        26       44\n4        30       92\n5        29       56\n6        19       43\n7        34       44\n8        30       50\n9         8       20\n10        2        4\n11      133      158\n12       47       72\n13       15       24\n14      251      263\n15       66       92\n16       15       30\n17       16       18\n18       13       23\n19       46       79\n20       62      132\n21      374      390\n22       11       19\n23       35       47\n24        7       10\n25       30       69\n26       39       80\n27       48       83\n28       74       94\n29       51       59\n30        9       15\n31       57      124\n32       25       51\n33        7       16\n34      414      357\n35       20       52\n36        1        4\n37       44       53\n38       33       74\n39        8       19\n40       54       96\n41       49       72\n42       59       91\n43       35       48\n44       37       92\n45       22       44\n46       15       42\n47       35       61\n48        5       23\n49       44       56\n50       10       17\n\ndocument_sentiment &lt;- data.frame(DocumentName = pdf_document_names, \n                                 Negative = nrc_data$negative, \n                                 Positive = nrc_data$positive)\n\n# Print the data frame with document names and sentiment scores\nprint(document_sentiment)\n\n                           DocumentName Negative Positive\n1                              aapc.pdf       21       37\n2                  accountable_tech.pdf       42       24\n3                               acm.pdf       26       44\n4                             Adobe.pdf       30       92\n5                           afl_cio.pdf       29       56\n6                          arnetfox.pdf       19       43\n7  AsianAmericans_advancing_justice.pdf       34       44\n8                       brennan_ctr.pdf       30       50\n9                                BS.pdf        8       20\n10                               bv.pdf        2        4\n11                               ca.pdf      133      158\n12      campaign_for_accountability.pdf       47       72\n13             catholic_social_just.pdf       15       24\n14                               cb.pdf      251      263\n15                     common_cause.pdf       66       92\n16                              CPD.pdf       15       30\n17                             CREW.pdf       16       18\n18                            crew2.pdf       13       23\n19               ctr_democracy_tech.pdf       46       79\n20            ctr_for_ai_dig_policy.pdf       62      132\n21                               dc.pdf      374      390\n22                       demo_first.pdf       11       19\n23                              dnc.pdf       35       47\n24              election_protection.pdf        7       10\n25                             epic.pdf       30       69\n26                     future_priva.pdf       39       80\n27                              GMU.pdf       48       83\n28                       harvardlaw.pdf       74       94\n29                         holtzman.pdf       51       59\n30 Institute for Strategic Dialogue.pdf        9       15\n31                   integrity_inst.pdf       57      124\n32                        issue_dia.pdf       25       51\n33                               jm.pdf        7       16\n34                               lc.pdf      414      357\n35                              lwv.pdf       20       52\n36                               MM.pdf        1        4\n37                               MR.pdf       44       53\n38                        partnerAI.pdf       33       74\n39              people_power_united.pdf        8       19\n40                              ppu.pdf       54       96\n41                protect_democracy.pdf       49       72\n42                         pub_citz.pdf       59       91\n43                     she_persists.pdf       35       48\n44                      stabilityAI.pdf       37       92\n45                        StanfordU.pdf       22       44\n46                          technet.pdf       15       42\n47                           unidos.pdf       35       61\n48                      US_congress.pdf        5       23\n49                            wiley.pdf       44       56\n50                   workers_circle.pdf       10       17\n\n# Create a bar graph of emotions\nbarplot(\n  sort(colSums(prop.table(nrc_data[, 1:8]))), \n  horiz = TRUE, \n  cex.names = 0.7, \n  las = 1, \n  main = \"Emotions in Text\", \n  xlab = \"Percentage\"\n)"
  },
  {
    "objectID": "coding-exercise/coding-exercise.html",
    "href": "coding-exercise/coding-exercise.html",
    "title": "R Coding Exercise",
    "section": "",
    "text": "#load package\nsuppressPackageStartupMessages(library(dslabs))\nsuppressPackageStartupMessages(library(dplyr))\nsuppressPackageStartupMessages(library(ggplot2))\nsuppressPackageStartupMessages(library(plotly))"
  },
  {
    "objectID": "coding-exercise/coding-exercise.html#when-plotted-there-are-distinct-streaks-in-the-data.-this-is-especially-evident-in-the-life-expectancy-vs-log_10-population-these-streaks-likely-represent-the-trajectory-of-individual-countries-over-time.-in-general-as-levels-of-development-improve-so-do-health-outcomes-like-life-expectancy.",
    "href": "coding-exercise/coding-exercise.html#when-plotted-there-are-distinct-streaks-in-the-data.-this-is-especially-evident-in-the-life-expectancy-vs-log_10-population-these-streaks-likely-represent-the-trajectory-of-individual-countries-over-time.-in-general-as-levels-of-development-improve-so-do-health-outcomes-like-life-expectancy.",
    "title": "R Coding Exercise",
    "section": "When plotted, there are distinct “streaks” in the data. This is especially evident in the Life Expectancy vs log\\(_{10}\\) Population, These streaks likely represent the trajectory of individual countries over time. In general, as levels of development improve, so do health outcomes like life expectancy.",
    "text": "When plotted, there are distinct “streaks” in the data. This is especially evident in the Life Expectancy vs log\\(_{10}\\) Population, These streaks likely represent the trajectory of individual countries over time. In general, as levels of development improve, so do health outcomes like life expectancy.\n\nNote: in both plots there is an outlier showing a visible decrease in life expectancy. Without countries or years in the plots, it is difficult to pin point the exact cause of that decrease, but it is likely due to a single, tranformational event. In this case, I would attribute that to the civil war and genocide in Rwanda in the early 1990s.\n\nlibrary(ggplot2)\n\n# Plot life expectancy as a function of infant mortality\nplot_le_vs_im &lt;- ggplot(africa_mort_expect, aes(x = infant_mortality, y = life_expectancy)) +\n  geom_point() +\n  theme_minimal() +\n  labs(title = \"Life Expectancy vs Infant Mortality\",\n       x = \"Infant Mortality\",\n       y = \"Life Expectancy\")\n\nplot_le_vs_im\n\nWarning: Removed 226 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n#plot life expectancy vs population with population on a log scale\nplot_le_vs_pop_log &lt;- ggplot(africa_pop_expect, aes(x = population, y = life_expectancy)) +\n    geom_point() +\n    theme_minimal() +\n    labs(title = \"Life Expectancy vs Population\",\n         x = \"Population (Log Scale)\",\n         y = \"Life Expectancy\") +\n    scale_x_log10()\n\nplot_le_vs_pop_log\n\nWarning: Removed 51 rows containing missing values (`geom_point()`)."
  },
  {
    "objectID": "coding-exercise/coding-exercise.html#creating-object-from-africadata-for-the-year-2000",
    "href": "coding-exercise/coding-exercise.html#creating-object-from-africadata-for-the-year-2000",
    "title": "R Coding Exercise",
    "section": "creating object from africadata for the year 2000",
    "text": "creating object from africadata for the year 2000\n\n# filter data for year == 2000\nafricadata2000 &lt;- africadata %&gt;%\n  filter(year == 2000)\n\n#examine the structure and summary of africadata2000\nstr(africadata2000)\n\n'data.frame':   51 obs. of  9 variables:\n $ country         : Factor w/ 185 levels \"Albania\",\"Algeria\",..: 2 3 18 22 26 27 29 31 32 33 ...\n $ year            : int  2000 2000 2000 2000 2000 2000 2000 2000 2000 2000 ...\n $ infant_mortality: num  33.9 128.3 89.3 52.4 96.2 ...\n $ life_expectancy : num  73.3 52.3 57.2 47.6 52.6 46.7 54.3 68.4 45.3 51.5 ...\n $ fertility       : num  2.51 6.84 5.98 3.41 6.59 7.06 5.62 3.7 5.45 7.35 ...\n $ population      : num  31183658 15058638 6949366 1736579 11607944 ...\n $ gdp             : num  5.48e+10 9.13e+09 2.25e+09 5.63e+09 2.61e+09 ...\n $ continent       : Factor w/ 5 levels \"Africa\",\"Americas\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ region          : Factor w/ 22 levels \"Australia and New Zealand\",..: 11 10 20 17 20 5 10 20 10 10 ...\n\nsummary(africadata2000)\n\n         country        year      infant_mortality life_expectancy\n Algeria     : 1   Min.   :2000   Min.   : 12.30   Min.   :37.60  \n Angola      : 1   1st Qu.:2000   1st Qu.: 60.80   1st Qu.:51.75  \n Benin       : 1   Median :2000   Median : 80.30   Median :54.30  \n Botswana    : 1   Mean   :2000   Mean   : 78.93   Mean   :56.36  \n Burkina Faso: 1   3rd Qu.:2000   3rd Qu.:103.30   3rd Qu.:60.00  \n Burundi     : 1   Max.   :2000   Max.   :143.30   Max.   :75.00  \n (Other)     :45                                                  \n   fertility       population             gdp               continent \n Min.   :1.990   Min.   :    81154   Min.   :2.019e+08   Africa  :51  \n 1st Qu.:4.150   1st Qu.:  2304687   1st Qu.:1.274e+09   Americas: 0  \n Median :5.550   Median :  8799165   Median :3.238e+09   Asia    : 0  \n Mean   :5.156   Mean   : 15659800   Mean   :1.155e+10   Europe  : 0  \n 3rd Qu.:5.960   3rd Qu.: 17391242   3rd Qu.:8.654e+09   Oceania : 0  \n Max.   :7.730   Max.   :122876723   Max.   :1.329e+11                \n                                                                      \n                       region  \n Eastern Africa           :16  \n Western Africa           :16  \n Middle Africa            : 8  \n Northern Africa          : 6  \n Southern Africa          : 5  \n Australia and New Zealand: 0  \n (Other)                  : 0"
  },
  {
    "objectID": "coding-exercise/coding-exercise.html#new-plots-using-only-data-from-the-year-2000-in-the-africadata-file",
    "href": "coding-exercise/coding-exercise.html#new-plots-using-only-data-from-the-year-2000-in-the-africadata-file",
    "title": "R Coding Exercise",
    "section": "new plots using only data from the year 2000 in the africadata file",
    "text": "new plots using only data from the year 2000 in the africadata file\n\n# plot infant mortality vs life expectancy for year=2000\nplot_le_vs_im_2000 &lt;- ggplot(africadata2000, aes(x = infant_mortality, y = life_expectancy)) +\n  geom_point() +\n  theme_minimal() +\n  labs(title = \"Life Expectancy vs Infant Mortality, year=2000\",\n       x = \"Infant Mortality\",\n       y = \"Life Expectancy\")\nplot(plot_le_vs_im_2000)\n\n\n\n\n\n\n\n# plot life expectancy vs population (log10) for year=2000\nplot_le_vs_pop_log_2000 &lt;- ggplot(africadata2000, aes(x = population, y = life_expectancy)) +\n    geom_point() +\n    theme_minimal() +\n    labs(title = \"Life Expectancy vs Population Year = 2000\",\n         x = \"Population (Log Scale)\",\n         y = \"Life Expectancy\") +\n    scale_x_log10()\n\nplot_le_vs_pop_log\n\nWarning: Removed 51 rows containing missing values (`geom_point()`)."
  },
  {
    "objectID": "coding-exercise/coding-exercise.html#linear-models",
    "href": "coding-exercise/coding-exercise.html#linear-models",
    "title": "R Coding Exercise",
    "section": "linear models",
    "text": "linear models\n\nlife_expectancy~infant_mortality\n\nfit1 &lt;- lm(life_expectancy ~ infant_mortality, data = africadata2000)\n\nsummary(fit1)\n\n\nCall:\nlm(formula = life_expectancy ~ infant_mortality, data = africadata2000)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-22.6651  -3.7087   0.9914   4.0408   8.6817 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      71.29331    2.42611  29.386  &lt; 2e-16 ***\ninfant_mortality -0.18916    0.02869  -6.594 2.83e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.221 on 49 degrees of freedom\nMultiple R-squared:  0.4701,    Adjusted R-squared:  0.4593 \nF-statistic: 43.48 on 1 and 49 DF,  p-value: 2.826e-08"
  },
  {
    "objectID": "coding-exercise/coding-exercise.html#linear-models-1",
    "href": "coding-exercise/coding-exercise.html#linear-models-1",
    "title": "R Coding Exercise",
    "section": "linear models",
    "text": "linear models\n\nlife_expectancy~population\n\nfit2 &lt;- lm(life_expectancy ~ population, data = africadata2000)\n\nsummary(fit2)\n\n\nCall:\nlm(formula = life_expectancy ~ population, data = africadata2000)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-18.429  -4.602  -2.568   3.800  18.802 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 5.593e+01  1.468e+00  38.097   &lt;2e-16 ***\npopulation  2.756e-08  5.459e-08   0.505    0.616    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.524 on 49 degrees of freedom\nMultiple R-squared:  0.005176,  Adjusted R-squared:  -0.01513 \nF-statistic: 0.2549 on 1 and 49 DF,  p-value: 0.6159"
  },
  {
    "objectID": "aboutme.html",
    "href": "aboutme.html",
    "title": "About me",
    "section": "",
    "text": "Doctor of Public Health candidate, board-certified medical entomologist, and health scientist at CDC’s National Center for Environmental Health. My background is in mosquito control and surveillance. My dissertation research involves using AI to predict human cases of eastern equine encephalitis in Bristol County, Massachusetts based on mosquito surveillance, ecological, environmental, and demographic data. I have lived in 10 states (including DC) and 2 other countries (Germany and Ghana). I currently live in the Lenox/Morningside area of Atlanta. Outside of work and school, I like spending time with my pets and family.\n\n\n\n\nKayaking at Stone Mountain"
  },
  {
    "objectID": "aboutme.html#education",
    "href": "aboutme.html#education",
    "title": "About me",
    "section": "Education",
    "text": "Education\n\n\nUniversity of New Mexico Tulane University University of Georgia\n\nBA -Geography/GIS MSPH -Tropical Medicine DrPH Candidate -Health Policy & Management"
  },
  {
    "objectID": "aboutme.html#professional",
    "href": "aboutme.html#professional",
    "title": "About me",
    "section": "Professional",
    "text": "Professional\nCDC hired me during the Zika outbreak in the US. I have been a health scientist there since 2017.\nBefore CDC, I was the operation manager for SW Florida at a private sector mosquito control company. Before that I managed the eastern equine encephalitis field surveillance in Massachusetts. Before that, I was an entomologist for the City of New Orleans’ Mosquito Control Board."
  },
  {
    "objectID": "cdcdata-exercise/cdcdata-exercsie.html",
    "href": "cdcdata-exercise/cdcdata-exercsie.html",
    "title": "cdcdata-exercise",
    "section": "",
    "text": "#Load libraries and read data\nrm(list = ls())\n\nlibrary(here)\n\nhere() starts at /Users/andrewruiz/MADA_course/andrew_ruiz-MADA-portfolio\n\nlibrary(readr)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(tidyr)\nlibrary(ggplot2)\nlibrary(forecast)\n\nRegistered S3 method overwritten by 'quantmod':\n  method            from\n  as.zoo.data.frame zoo \n\n# Read the CSV file using here()\nrabies2020 &lt;- read_csv(here(\"cdcdata-exercise\", \"Rabies2020.csv\"))\n\nRows: 3710 Columns: 23\n\n\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (11): Reporting Area, Rabies, Animal, Current week, flag, Rabies, Animal...\ndbl  (8): MMWR Year, MMWR Week, Rabies, Animal, Current week, Rabies, Animal...\nlgl  (4): Rabies, Human, Current week, Rabies, Human, Previous 52 weeks Max†...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# Now apply your renaming and cleaning\nnames(rabies2020) &lt;- gsub(\"[^[:alnum:] ]\", \"\", names(rabies2020))\nnames(rabies2020) &lt;- gsub(\" \", \"_\", names(rabies2020))\n\nrabies2020_cleaned &lt;- rabies2020\n\n# Check the column names\nprint(names(rabies2020_cleaned))\n\n [1] \"Reporting_Area\"                          \n [2] \"MMWR_Year\"                               \n [3] \"MMWR_Week\"                               \n [4] \"Rabies_Animal_Current_week\"              \n [5] \"Rabies_Animal_Current_week_flag\"         \n [6] \"Rabies_Animal_Previous_52_weeks_Max\"     \n [7] \"Rabies_Animal_Previous_52_weeks_Max_flag\"\n [8] \"Rabies_Animal_Cum_2020\"                  \n [9] \"Rabies_Animal_Cum_2020_flag\"             \n[10] \"Rabies_Animal_Cum_2019\"                  \n[11] \"Rabies_Animal_Cum_2019_flag\"             \n[12] \"Rabies_Human_Current_week\"               \n[13] \"Rabies_Human_Current_week_flag\"          \n[14] \"Rabies_Human_Previous_52_weeks_Max\"      \n[15] \"Rabies_Human_Previous_52_weeks_Max_flag\" \n[16] \"Rabies_Human_Cum_2020\"                   \n[17] \"Rabies_Human_Cum_2020_flag\"              \n[18] \"Rabies_Human_Cum_2019\"                   \n[19] \"Rabies_Human_Cum_2019_flag\"              \n[20] \"Location_1\"                              \n[21] \"Location_2\"                              \n[22] \"Reporting_Area_Sort\"                     \n[23] \"New_Georeferenced_Column\""
  },
  {
    "objectID": "cdcdata-exercise/cdcdata-exercsie.html#rabies-data-from-the-cdc",
    "href": "cdcdata-exercise/cdcdata-exercsie.html#rabies-data-from-the-cdc",
    "title": "cdcdata-exercise",
    "section": "Rabies data from the CDC",
    "text": "Rabies data from the CDC\n\nThis dataset was obtained from the data.cdc.gov site link to data. It contains the count of animal and human rabies cases in the US and territories for 2020 and 2019 by MMWR Week. Since there were no human rabies cases in 2020 or 2019, this will focus on animal cases only.\n\n\nUnlike human cases, which rarely go undiagnosed, animal cases are more prone to surveillance bias. Comparing the counts from 2020 to 2019, may be an important indicator of the effects of limited public health lab testing in the first year of the pandemic when public health staff were diverted to support COVID operations and some labs were closed.\n\nLet’s look at the first few rows\n\nhead(rabies2020)\n\n# A tibble: 6 × 23\n  Reporting_Area MMWR_Year MMWR_Week Rabies_Animal_Current_week\n  &lt;chr&gt;              &lt;dbl&gt;     &lt;dbl&gt;                      &lt;dbl&gt;\n1 MASSACHUSETTS       2020         1                         NA\n2 US RESIDENTS        2020         1                         16\n3 WASHINGTON          2020         1                         NA\n4 HAWAII              2020         1                         NA\n5 WISCONSIN           2020         1                         NA\n6 MARYLAND            2020         1                         NA\n# ℹ 19 more variables: Rabies_Animal_Current_week_flag &lt;chr&gt;,\n#   Rabies_Animal_Previous_52_weeks_Max &lt;dbl&gt;,\n#   Rabies_Animal_Previous_52_weeks_Max_flag &lt;chr&gt;,\n#   Rabies_Animal_Cum_2020 &lt;dbl&gt;, Rabies_Animal_Cum_2020_flag &lt;chr&gt;,\n#   Rabies_Animal_Cum_2019 &lt;dbl&gt;, Rabies_Animal_Cum_2019_flag &lt;chr&gt;,\n#   Rabies_Human_Current_week &lt;lgl&gt;, Rabies_Human_Current_week_flag &lt;chr&gt;,\n#   Rabies_Human_Previous_52_weeks_Max &lt;dbl&gt;, …\n\nprint(names(rabies2020))\n\n [1] \"Reporting_Area\"                          \n [2] \"MMWR_Year\"                               \n [3] \"MMWR_Week\"                               \n [4] \"Rabies_Animal_Current_week\"              \n [5] \"Rabies_Animal_Current_week_flag\"         \n [6] \"Rabies_Animal_Previous_52_weeks_Max\"     \n [7] \"Rabies_Animal_Previous_52_weeks_Max_flag\"\n [8] \"Rabies_Animal_Cum_2020\"                  \n [9] \"Rabies_Animal_Cum_2020_flag\"             \n[10] \"Rabies_Animal_Cum_2019\"                  \n[11] \"Rabies_Animal_Cum_2019_flag\"             \n[12] \"Rabies_Human_Current_week\"               \n[13] \"Rabies_Human_Current_week_flag\"          \n[14] \"Rabies_Human_Previous_52_weeks_Max\"      \n[15] \"Rabies_Human_Previous_52_weeks_Max_flag\" \n[16] \"Rabies_Human_Cum_2020\"                   \n[17] \"Rabies_Human_Cum_2020_flag\"              \n[18] \"Rabies_Human_Cum_2019\"                   \n[19] \"Rabies_Human_Cum_2019_flag\"              \n[20] \"Location_1\"                              \n[21] \"Location_2\"                              \n[22] \"Reporting_Area_Sort\"                     \n[23] \"New_Georeferenced_Column\""
  },
  {
    "objectID": "cdcdata-exercise/cdcdata-exercsie.html#now-that-the-data-is-cleaner-lets-focus-on-the-south-atlantic-region-for-the-rest-of-the-analysis.",
    "href": "cdcdata-exercise/cdcdata-exercsie.html#now-that-the-data-is-cleaner-lets-focus-on-the-south-atlantic-region-for-the-rest-of-the-analysis.",
    "title": "cdcdata-exercise",
    "section": "Now that the data is cleaner, let’s focus on the South Atlantic region for the rest of the analysis.",
    "text": "Now that the data is cleaner, let’s focus on the South Atlantic region for the rest of the analysis.\n\nThe original dataset does not provide the incident case count by MMWR week for 2019. Instead it only has the cumulative cases by week. We will have to create a calculate field for this so that we can make some comparisons between the years.\n\n# Focus on South Atlantic state for the rest of the analysis\nsouth_atlantic_data &lt;- rabies2020_selected %&gt;%\n  filter(Location_2 == \"SOUTH ATLANTIC\") %&gt;%\n\n# Calculate incident cases for 2019\n  arrange(Reporting_Area, MMWR_Week) %&gt;%\n  group_by(Reporting_Area) %&gt;%\n  mutate(Incident_Cases_2019 = Rabies_Animal_Cum_2019 - lag(Rabies_Animal_Cum_2019, default = 0)) %&gt;%\n  ungroup()\nstr(south_atlantic_data)\n\ntibble [53 × 7] (S3: tbl_df/tbl/data.frame)\n $ Reporting_Area            : chr [1:53] \"SOUTH ATLANTIC\" \"SOUTH ATLANTIC\" \"SOUTH ATLANTIC\" \"SOUTH ATLANTIC\" ...\n $ MMWR_Week                 : num [1:53] 1 2 3 4 5 6 7 8 9 10 ...\n $ Rabies_Animal_Current_week: num [1:53] 12 9 4 5 3 4 5 5 7 0 ...\n $ Rabies_Animal_Cum_2019    : num [1:53] 9 77 107 135 154 164 169 182 197 212 ...\n $ Location_1                : chr [1:53] NA NA NA NA ...\n $ Location_2                : chr [1:53] \"SOUTH ATLANTIC\" \"SOUTH ATLANTIC\" \"SOUTH ATLANTIC\" \"SOUTH ATLANTIC\" ...\n $ Incident_Cases_2019       : num [1:53] 9 68 30 28 19 10 5 13 15 15 ..."
  },
  {
    "objectID": "cdcdata-exercise/cdcdata-exercsie.html#lets-create-a-line-graph-with-the-counts-by-mmwr-week-for-both-2020-and-2019.",
    "href": "cdcdata-exercise/cdcdata-exercsie.html#lets-create-a-line-graph-with-the-counts-by-mmwr-week-for-both-2020-and-2019.",
    "title": "cdcdata-exercise",
    "section": "Let’s create a line graph with the counts by MMWR week for both 2020 and 2019.",
    "text": "Let’s create a line graph with the counts by MMWR week for both 2020 and 2019.\n\n# Prepare data for graphing: Pivot to long format for both 2019 and 2020\nsouth_atlantic_long &lt;- south_atlantic_data %&gt;%\n  # Ensure MMWR_Week and Reporting_Area are retained for grouping in the long format\n  pivot_longer(cols = c(Incident_Cases_2019, Rabies_Animal_Current_week), \n               names_to = \"Year\", \n               values_to = \"Cases\") %&gt;%\n  # Correct the Year column to reflect actual years\n  mutate(Year = recode(Year, \n                       Incident_Cases_2019 = \"2019\", \n                       Rabies_Animal_Current_week = \"2020\"))\nhead(south_atlantic_long)\n\n# A tibble: 6 × 7\n  Reporting_Area MMWR_Week Rabies_Animal_Cum_2019 Location_1 Location_2    Year \n  &lt;chr&gt;              &lt;dbl&gt;                  &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;         &lt;chr&gt;\n1 SOUTH ATLANTIC         1                      9 &lt;NA&gt;       SOUTH ATLANT… 2019 \n2 SOUTH ATLANTIC         1                      9 &lt;NA&gt;       SOUTH ATLANT… 2020 \n3 SOUTH ATLANTIC         2                     77 &lt;NA&gt;       SOUTH ATLANT… 2019 \n4 SOUTH ATLANTIC         2                     77 &lt;NA&gt;       SOUTH ATLANT… 2020 \n5 SOUTH ATLANTIC         3                    107 &lt;NA&gt;       SOUTH ATLANT… 2019 \n6 SOUTH ATLANTIC         3                    107 &lt;NA&gt;       SOUTH ATLANT… 2020 \n# ℹ 1 more variable: Cases &lt;dbl&gt;\n\n# Graph the incident animal cases from 2019 and 2020 by MMWR week\nggplot(south_atlantic_long, aes(x = MMWR_Week, y = Cases, color = Year, group = Year)) +\n  geom_line() +\n  geom_point() +\n  theme_minimal() +\n  labs(title = \"Rabies Cases by MMWR Week for 2019 and 2020 in South Atlantic\",\n       x = \"MMWR Week\",\n       y = \"Number of Cases\",\n       color = \"Year\") +\n  scale_color_manual(values = c(\"2019\" = \"blue\", \"2020\" = \"red\"))\n\n\n\n\n\n\n\n\n\n# Lets compare the two years with a box plot\nggplot(south_atlantic_long, aes(x = Year, y = Cases, color = Year)) +\n  geom_boxplot() +\n  theme_minimal() +\n  labs(title = \"Distribution of Weekly Rabies Cases for 2019 and 2020\",\n       x = \"Year\",\n       y = \"Number of Cases\")\n\n\n\n\n\n\n\n\n\nThis analysis aims to understand the trends in animal rabies cases reported in the South Atlantic region during 2019, assess the model’s fit, and forecast future cases into the next year. We employ time series analysis techniques, focusing on ARIMA modeling, to capture the underlying patterns in the weekly reported cases and predict future occurrences. The process encompasses data preparation, visualization, model selection and diagnostics, and forecasting, culminating in a comparison of forecasted cases against actual data from 2020.\n\n# Prepare the time series data\ntime_series_data &lt;- south_atlantic_data %&gt;%\n  select(MMWR_Week, Incident_Cases_2019) %&gt;%\n  mutate(MMWR_Week = as.Date(paste0(\"2020-\", MMWR_Week, \"-1\"), format = \"%Y-%U-%u\"))\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `MMWR_Week = as.Date(paste0(\"2020-\", MMWR_Week, \"-1\"), format =\n  \"%Y-%U-%u\")`.\nCaused by warning in `strptime()`:\n! (0-based) yday 369 in year 2020 is invalid\n\n# Convert to time series object\nts_data &lt;- ts(time_series_data$Incident_Cases_2019, frequency = 53)\n\n# Time Series Visualization\nplot(ts_data, main = \"Time Series of Rabies Animal Cases by MMWR Week for 2019\")\n\n\n\n\n\n\n\n# Modeling (Auto ARIMA)\narima_model &lt;- auto.arima(ts_data)\n\n# Diagnostic Checking\ncheckresiduals(arima_model)\n\n\n\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(2,1,1)\nQ* = 16.92, df = 8, p-value = 0.03096\n\nModel df: 3.   Total lags used: 11\n\n# The Ljung-Box test examined the residuals from an ARIMA(2,1,1) model \n#to see if they are correlated with each other. The test statistic (Q*) \n#was 16.92 with 8 degrees of freedom, resulting in a p-value of 0.03096. \n#This suggests that there is evidence of autocorrelation in the residuals, \n#indicating that the ARIMA model may not fully capture the underlying patterns \n#in the data.\n\n# Forecasting\nforecast_values &lt;- forecast(arima_model, h = 52)\n\n# Plot Forecast\n#plot(forecast_values, main = \"Forecast of Rabies Animal Cases for the Next 52 Weeks\")\n\n# Plot Forecast and Actual 2020 Cases\n# Assuming you have the actual 2020 cases data stored in a variable called actual_2020_cases\n\n# Plot Forecast and Actual 2020 Cases\nplot(forecast_values, main = \"Forecast vs Actual Rabies Animal Cases for 2020\")\nlines(south_atlantic_data$Rabies_Animal_Current_week, col = \"blue\", lty = 2, lwd = 2)  # Add actual 2020 cases to the plot\n\n# Add legend\nlegend(\"topright\", legend = c(\"Forecast\", \"Actual 2020 Cases\"), col = c(\"black\", \"blue\"), lty = c(1, 2), lwd = c(1, 2))\n\n\n\n\n\n\n\n\n\nThe Ljung-Box test examined the residuals from an ARIMA(2,1,1) model to see if they are correlated with each other. The test statistic (Q*) was 16.92 with 8 degrees of freedom, resulting in a p-value of 0.03096. This suggests that there is evidence of autocorrelation in the residuals, indicating that the ARIMA model may not fully capture the underlying patterns in the data."
  },
  {
    "objectID": "cdcdata-exercise/cdcdata-exercsie.html#contributed-by-xueyan-hu",
    "href": "cdcdata-exercise/cdcdata-exercsie.html#contributed-by-xueyan-hu",
    "title": "cdcdata-exercise",
    "section": "Contributed by Xueyan Hu",
    "text": "Contributed by Xueyan Hu\n\nFirst creating a synthetic dataset\n\n# Set seed for reproducibility\nset.seed(123)\n\n# Generate MMWR weeks from 1 to 53\nmmwr_weeks &lt;- 1:53\n\n# Generate synthetic data for 2020 (weekly incident cases)\ncovid_weekly_2020 &lt;- sample(1:100, 53, replace = TRUE)\n\n# Generate synthetic data for 2021 (weekly incident cases)\n# Ensure that 2021 cases are overall higher than 2020\ncovid_weekly_2021 &lt;- covid_weekly_2020 + sample(50:150, 53, replace = TRUE) + 50\n\n# Create reporting area variable\nreporting_area &lt;- rep(\"Hogwarts\", 53 * 2)\n\n# Combine data for 2020 and 2021\ncovid_data &lt;- data.frame(\n  MMWR_Week = rep(mmwr_weeks, 2),\n  Covid_Cum_2020 = c(covid_weekly_2020, rep(NA, 53)),  # Placeholder for 2021 weekly counts\n  Covid_Current_Week_2021 = c(rep(NA, 53), covid_weekly_2021),  # 2021 weekly counts\n  Reporting_Area = reporting_area\n)\n\n# Replace NA values for 2021 with a lower limit\ncovid_data$Covid_Cum_2020[54:106] &lt;- cumsum(pmin(10000, pmax(0, covid_weekly_2021)))\n\n# Add variation to incident cases in 2021\ncovid_data$Covid_Current_Week_2021[54:106] &lt;- pmin(10000, pmax(0, covid_data$Covid_Cum_2020[53] + sample(100:500, 53, replace = TRUE)))\n\n# Remove the NA values from the weekly counts for 2021\ncovid_data &lt;- covid_data[complete.cases(covid_data), ]\n\n# Print the generated dataset\nprint(covid_data)\n\n    MMWR_Week Covid_Cum_2020 Covid_Current_Week_2021 Reporting_Area\n54          1            212                     290       Hogwarts\n55          2            487                     474       Hogwarts\n56          3            728                     348       Hogwarts\n57          4            866                     210       Hogwarts\n58          5           1070                     442       Hogwarts\n59          6           1232                     326       Hogwarts\n60          7           1460                     239       Hogwarts\n61          8           1643                     324       Hogwarts\n62          9           1803                     286       Hogwarts\n63         10           2017                     385       Hogwarts\n64         11           2266                     414       Hogwarts\n65         12           2551                     422       Hogwarts\n66         13           2735                     344       Hogwarts\n67         14           3019                     478       Hogwarts\n68         15           3181                     355       Hogwarts\n69         16           3444                     462       Hogwarts\n70         17           3638                     447       Hogwarts\n71         18           3916                     392       Hogwarts\n72         19           4153                     225       Hogwarts\n73         20           4355                     219       Hogwarts\n74         21           4561                     503       Hogwarts\n75         22           4717                     263       Hogwarts\n76         23           4892                     266       Hogwarts\n77         24           5004                     214       Hogwarts\n78         25           5199                     367       Hogwarts\n79         26           5403                     272       Hogwarts\n80         27           5605                     503       Hogwarts\n81         28           5837                     267       Hogwarts\n82         29           6001                     117       Hogwarts\n83         30           6265                     438       Hogwarts\n84         31           6411                     384       Hogwarts\n85         32           6567                     392       Hogwarts\n86         33           6760                     400       Hogwarts\n87         34           6903                     389       Hogwarts\n88         35           7083                     167       Hogwarts\n89         36           7286                     443       Hogwarts\n90         37           7420                     350       Hogwarts\n91         38           7577                     364       Hogwarts\n92         39           7766                     451       Hogwarts\n93         40           7982                     151       Hogwarts\n94         41           8187                     422       Hogwarts\n95         42           8353                     249       Hogwarts\n96         43           8572                     338       Hogwarts\n97         44           8863                     160       Hogwarts\n98         45           9071                     189       Hogwarts\n99         46           9326                     195       Hogwarts\n100        47           9482                     296       Hogwarts\n101        48           9753                     479       Hogwarts\n102        49          10006                     151       Hogwarts\n103        50          10214                     308       Hogwarts\n104        51          10397                     369       Hogwarts\n105        52          10610                     280       Hogwarts\n106        53          10796                     398       Hogwarts\n\n\n\n\ncalculate weekly incident for 2020\n\nnew_covid_data &lt;- covid_data %&gt;%\n  mutate(Incident_Cases_2020 = Covid_Cum_2020 - lag(Covid_Cum_2020, default = 0))\nstr(new_covid_data)\n\n'data.frame':   53 obs. of  5 variables:\n $ MMWR_Week              : int  1 2 3 4 5 6 7 8 9 10 ...\n $ Covid_Cum_2020         : num  212 487 728 866 1070 ...\n $ Covid_Current_Week_2021: num  290 474 348 210 442 326 239 324 286 385 ...\n $ Reporting_Area         : chr  \"Hogwarts\" \"Hogwarts\" \"Hogwarts\" \"Hogwarts\" ...\n $ Incident_Cases_2020    : num  212 275 241 138 204 162 228 183 160 214 ...\n\nhead(new_covid_data)\n\n   MMWR_Week Covid_Cum_2020 Covid_Current_Week_2021 Reporting_Area\n54         1            212                     290       Hogwarts\n55         2            487                     474       Hogwarts\n56         3            728                     348       Hogwarts\n57         4            866                     210       Hogwarts\n58         5           1070                     442       Hogwarts\n59         6           1232                     326       Hogwarts\n   Incident_Cases_2020\n54                 212\n55                 275\n56                 241\n57                 138\n58                 204\n59                 162\n\n\n\n\nline graph for incident case by MMWR Week\n\n# Prepare data for graphing: Pivot to long format for both 2020 and 2021\ncovid_data_long &lt;- new_covid_data %&gt;%\n  pivot_longer(cols = c(Incident_Cases_2020, Covid_Current_Week_2021), \n               names_to = \"Year\", \n               values_to = \"Cases\") %&gt;%\n  # Correct the Year column to reflect actual years\n  mutate(Year = recode(Year, \n                       Incident_Cases_2020 = \"2020\", \n                       Covid_Current_Week_2021 = \"2021\"))\nhead(covid_data_long)\n\n# A tibble: 6 × 5\n  MMWR_Week Covid_Cum_2020 Reporting_Area Year  Cases\n      &lt;int&gt;          &lt;dbl&gt; &lt;chr&gt;          &lt;chr&gt; &lt;dbl&gt;\n1         1            212 Hogwarts       2020    212\n2         1            212 Hogwarts       2021    290\n3         2            487 Hogwarts       2020    275\n4         2            487 Hogwarts       2021    474\n5         3            728 Hogwarts       2020    241\n6         3            728 Hogwarts       2021    348\n\n# Graph the incident animal cases from 2020 and 2021 by MMWR week\nggplot(covid_data_long, aes(x = MMWR_Week, y = Cases, color = Year, group = Year)) +\n  geom_line() +\n  geom_point() +\n  theme_minimal() +\n  labs(title = \"Covid Cases by MMWR Week for 2020 and 2021 in Hogwarts\",\n       x = \"MMWR Week\",\n       y = \"Number of Cases\",\n       color = \"Year\") +\n  scale_color_manual(values = c(\"2020\" = \"blue\", \"2021\" = \"red\"))\n\n\n\n\n\n\n\n\n\n\nboxplot for incident case by year\n\n# Lets compare the two years with a box plot\nggplot(covid_data_long, aes(x = Year, y = Cases, color = Year)) +\n  geom_boxplot() +\n  theme_minimal() +\n  labs(title = \"Distribution of Weekly covid Cases for 2020 and 2021\",\n       x = \"Year\",\n       y = \"Number of Cases\")\n\n\n\n\n\n\n\n\n??? I don’t really know the model named ARIMA that Andrew use for doing forecasting in the last section of part 1 above. But I will copy and paste his code and run it to see what will happen here for the synthetic dataset.\n\n# Prepare the time series data\ntime_series_covid_data &lt;- new_covid_data %&gt;%\n  mutate(MMWR_Week = as.Date(paste0(\"2021-\", MMWR_Week, \"-1\"), format = \"%Y-%U-%u\")) %&gt;%\n  select(MMWR_Week, Incident_Cases_2020)\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `MMWR_Week = as.Date(paste0(\"2021-\", MMWR_Week, \"-1\"), format =\n  \"%Y-%U-%u\")`.\nCaused by warning in `strptime()`:\n! (0-based) yday 367 in year 2021 is invalid\n\n# Convert to time series object\nts_covid_data &lt;- ts(time_series_covid_data$Incident_Cases_2020, frequency = 53)\n\n# Time Series Visualization\nplot(ts_covid_data, main = \"Time Series of Synthetic Covid Cases by MMWR Week for 2020\")\n\n\n\n\n\n\n\n# Modeling (Auto ARIMA)\ncovid_arima_model &lt;- auto.arima(ts_covid_data)\n\n# Diagnostic Checking\ncheckresiduals(covid_arima_model)\n\n\n\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(0,0,0) with non-zero mean\nQ* = 9.2378, df = 11, p-value = 0.6\n\nModel df: 0.   Total lags used: 11\n\n# The Ljung-Box test examined the residuals from an ARIMA(2,1,1) model \n#to see if they are correlated with each other. The test statistic (Q*) \n#was 16.92 with 8 degrees of freedom, resulting in a p-value of 0.03096. \n#This suggests that there is evidence of autocorrelation in the residuals, \n#indicating that the ARIMA model may not fully capture the underlying patterns \n#in the data.\n\n# Forecasting\nforecast_values_covid &lt;- forecast(covid_arima_model, h = 52)\n\n# Plot Forecast\n#plot(forecast_values, main = \"Forecast of Rabies Animal Cases for the Next 52 Weeks\")\n\n# Plot Forecast and Actual 2020 Cases\n# Assuming you have the actual 2020 cases data stored in a variable called actual_2020_cases\n\n# Plot Forecast and Actual 2020 Cases\nplot(forecast_values_covid, main = \"Forecast vs Synthetic Covid Cases for 2021\")\nlines(new_covid_data$Covid_Current_Week_2021, col = \"blue\", lty = 2, lwd = 2)  # Add actual 2020 cases to the plot\n\n# Add legend\nlegend(\"topright\", legend = c(\"Forecast\", \"Syntheric 2020 Cases\"), col = c(\"black\", \"blue\"), lty = c(1, 2), lwd = c(1, 2))"
  },
  {
    "objectID": "presentation-exercise/presentation-exercise.html",
    "href": "presentation-exercise/presentation-exercise.html",
    "title": "Presentation Exercise",
    "section": "",
    "text": "Original NYT graph\n\n\nThe NYT graph was based on the graph and data from an academic study “Leveraging football accelerometer data to quantify associations between repetitive head impacts and chronic traumatic encephalopathy in males”. Their version is show below."
  },
  {
    "objectID": "presentation-exercise/presentation-exercise.html#refining-the-prompts",
    "href": "presentation-exercise/presentation-exercise.html#refining-the-prompts",
    "title": "Presentation Exercise",
    "section": "Refining the prompts",
    "text": "Refining the prompts\n\nThe next series of prompts provided more specifics:\n\n\nthe x axis should be the number of years played (football_years) from 1 to 33. the y axis is the the percent of athletes for each number of years played. it should be a stacked bar graph by football_years. the bars should all have the same order. the bottom should be stage 4 the top should be 0. also 4 should be dark orange 3 lighter orange, 2 dark yellow, 1 yellow, 0 cream. the bars should be wide enough to touch each other and I want the x axis label just to show every 5 years.\n\n\nThe result was better, but still not the same as the NYT article. However, it was very similar to the orginal graph published in the research paper.\n\n\n\nAttempt 2\n\n\n##Re-examining the NYT graphic #### Upon closer inspection, the NYT graph grouped the number of years of football played into 14 categories. Their process for doing this was not shared in the article. However, it was apparent that they included the final last reported year (33) of the number of years plays in it own category. This is odd because there is only one observation for 33 years of football. I suspect that grouping the years using a standard process would not have the same impact. The one observation for 33 years is Stage 4 CTE. So the final bar in the graph shows 100%. This supports that theory that more years of football participation increases the risk of severe CTE.\n\n\nHowever, I find it somewhat deceptive. Using equal intervals to group the data gives a less dramatic visualization:\n\n\n\nAttempt3"
  },
  {
    "objectID": "presentation-exercise/presentation-exercise.html#final-prompts",
    "href": "presentation-exercise/presentation-exercise.html#final-prompts",
    "title": "Presentation Exercise",
    "section": "Final prompts",
    "text": "Final prompts\n\nIn order to match the colors, I used the color picker tool in Powerpoint. ChatGPT is not able to identify hex codes from an image. I also instructed ChatGPT to create 14 categories with the last observation as its own category. Beyond that, I tried using equal interval, jenks and natural breaks to mimic the rest of the data groupings, but I could not exactly recreate the NYT image.\n\n\nLooking that the data once more, I noticed that the NYT graph does not adequately represent the data. I could recreate the last 2 categories but the 3 to last grouping omits at least 2 records.\n\n\n\nStage 2 CTE is missing from the NYT graph for this grouping.\n\n\nFinally, I provided prompts to remove the numbers on the X axis and preplace them with “Increasing Cumulative Force” and also include an arrow point from left to right."
  },
  {
    "objectID": "presentation-exercise/presentation-exercise.html#final-version",
    "href": "presentation-exercise/presentation-exercise.html#final-version",
    "title": "Presentation Exercise",
    "section": "Final version",
    "text": "Final version\n\nWhile my final version does not match the NYT graphic, earlier iterations matched the original graphic published in the academic journal. Below is the final code used to recreate the graph.\n\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(here)\nlibrary(ggplot2)\nlibrary(classInt)\nlibrary(scales)\n\n# Set the correct path to the Excel file\nfile_path &lt;- here(\"presentation-exercise\", \"EX6_mod.xlsx\")\n\n# Read the data from the Excel file\ndf &lt;- read_excel(file_path)\n\n# Ensure 'football_years' is numeric\ndf$football_years &lt;- as.numeric(df$football_years)\n\n# Define the breaks manually, ensuring the last break is 33 to create its own category\n# Adjust the breaks as necessary to fit the categorization you observed\nmax_years &lt;- max(df$football_years, na.rm = TRUE)\nn_groups &lt;- 13 # One less than before since 33 will be its own group\njenks_breaks &lt;- classIntervals(df$football_years[df$football_years &lt; max_years], n = n_groups, style = \"jenks\")$brks\n\n# Ensure 33 is its own category\nfinal_breaks &lt;- c(jenks_breaks, max_years-1, max_years)\n\n# Group 'football_years' using these breaks\ndf$year_group &lt;- cut(df$football_years, breaks = final_breaks, include.lowest = TRUE, labels = FALSE)\n\n# Convert 'CTEStage' to a factor with correct levels\ndf$CTEStage &lt;- factor(df$CTEStage, levels = c(0, 1, 2, 3, 4))\n\n# Proceed with summarizing and plotting as before\ndf_summary &lt;- df %&gt;%\n  group_by(year_group, CTEStage) %&gt;%\n  summarise(count = n(), .groups = \"drop\") %&gt;%\n  left_join(df %&gt;%\n              group_by(year_group) %&gt;%\n              summarise(total = n(), .groups = \"drop\"), by = \"year_group\") %&gt;%\n  mutate(percentage = count / total)\n\n# Calculate the count for each year group and CTE stage\ndf_summary &lt;- df %&gt;%\n  group_by(year_group, CTEStage) %&gt;%\n  summarise(count = n(), .groups = \"drop\")\n\n# Calculate the percentage for each year group and CTE stage\ntotal_counts &lt;- df_summary %&gt;%\n  group_by(year_group) %&gt;%\n  summarise(total = sum(count), .groups = \"drop\")\n\ndf_summary &lt;- df_summary %&gt;%\n  left_join(total_counts, by = \"year_group\") %&gt;%\n  mutate(percentage = count / total)\n\n# Plot the percentages as a stacked bar graph scaled to the same height\nggplot_object &lt;- ggplot(df_summary, aes(x = as.factor(year_group), y = percentage, fill = as.factor(CTEStage))) +\n  geom_bar(stat = \"identity\", position = \"fill\", width = 1) +\n  scale_fill_manual(values = c(\"0\" = \"#D0D8DA\",\n                               \"1\" = \"#F6D3AA\",\n                               \"2\" = \"#EFB47D\",\n                               \"3\" = \"#DC8445\",\n                               \"4\" = \"#BA4B32\"),\n                    labels = c(\"No CTE\", \"Stage 1\", \"Stage 2\", \"Stage 3\", \"Stage 4\")) +\n  scale_y_continuous(labels = percent) +\n  labs(x = NULL, # Remove default x-axis title\n       y = \"Percentage of Athletes\", \n       fill = \"Stage of CTE\",\n       title = \"Estimated cumulative force of head hits for 631 former football players\") +\n  theme_minimal() +\n  theme(legend.position = \"top\", # Move legend to the top\n        axis.ticks.x = element_blank(), # Remove x-axis ticks\n        axis.text.x = element_blank(), # Remove x-axis text\n        plot.title = element_text(hjust = 0.5), # Center the plot title\n        panel.grid.major = element_blank(), # Remove major grid lines\n        panel.grid.minor = element_blank(), # Remove minor grid lines\n        panel.background = element_blank()) + # Remove panel background\n  annotate(\"text\", x = Inf, y = -0.07, label = \"Increasing Cumulative Force\", hjust = 2.45, vjust = .5, size = 4, fontface = \"italic\") +\n  annotate(\"segment\", x = -Inf, xend = Inf, y = -0.05, yend = -0.05, arrow = arrow(type = \"open\", ends = \"last\", length = unit(0.15, \"inches\"))) # Adjusted length\n\n    #annotate(\"segment\", x = -Inf, xend = Inf y = -0.05, yend = -0.05, arrow = arrow(type = \"open\", ends = \"last\", length = unit(0.5, \"inches\")))\n\n# Plot the graph\nprint(ggplot_object)"
  },
  {
    "objectID": "presentation-exercise/presentation-exercise.html#code-for-table",
    "href": "presentation-exercise/presentation-exercise.html#code-for-table",
    "title": "Presentation Exercise",
    "section": "Code for table",
    "text": "Code for table\nlibrary(classInt)\nlibrary(gt)\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(webshot2)\nlibrary(here)\nlibrary(tidyr)\n\n# Read the data from the Excel file\nfile_path &lt;- here(\"presentation-exercise\", \"EX6_mod.xlsx\")\ndf &lt;- read_excel(file_path)\n\n# Ensure 'football_years' is numeric\ndf$football_years &lt;- as.numeric(df$football_years)\n\n# Define the breaks as per your code snippet\nmax_years &lt;- max(df$football_years, na.rm = TRUE)\nn_groups &lt;- 13 # Adjust based on the specific needs\njenks_breaks &lt;- classIntervals(df$football_years[df$football_years &lt; max_years], n = n_groups, style = \"jenks\")$brks\n\n# Ensure 33 is its own category\nfinal_breaks &lt;- c(jenks_breaks, max_years-1, max_years)\n\n# Stratify football_years using the breaks\ndf$year_strata &lt;- cut(df$football_years, breaks = final_breaks, include.lowest = TRUE,\n                      labels = paste(head(final_breaks, -1), tail(final_breaks, -1), sep = \"-\"))\n\n# Convert 'CTEStage' to a factor with correct levels\ndf$CTEStage &lt;- factor(df$CTEStage, levels = c(0, 1, 2, 3, 4))\n\n# Summarize the data\ndf_summary &lt;- df %&gt;%\n  group_by(year_strata, CTEStage) %&gt;%\n  summarise(count = n(), .groups = \"drop\") %&gt;%\n  pivot_wider(names_from = CTEStage, values_from = count, values_fill = list(count = 0))\n\ngt_table &lt;- df_summary %&gt;%\n  gt() %&gt;%\n  tab_header(\n    title = \"Stratification of CTE Stage by Football Years\"\n  ) %&gt;%\n  cols_label(\n    year_strata = \"Years of Football Played\",\n    `0` = \"No CTE\",\n    `1` = \"Stage 1\",\n    `2` = \"Stage 2\",\n    `3` = \"Stage 3\",\n    `4` = \"Stage 4\"\n  ) %&gt;%\n  tab_options(\n    heading.title.font.size = px(18),\n    heading.subtitle.font.size = px(10)\n  ) %&gt;%\n  tab_style(\n    style = list(\n      cell_text(align = 'center'),\n      cell_fill(color = \"gray95\")\n    ),\n    locations = cells_column_labels(columns = TRUE)\n  )\n# If you intended to add more styling or options, they would continue here\n\n# Display the table\nprint(gt_table)"
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "",
    "text": "The time required to travel to healthcare facilities can affect how often people receive. Longer travel times may mean patients see the doctor less often and may lead to adverse health outcomes, such as higher BMI. It may also change an individual’s perception of their own health status (Kelly, Hulme, Farragher, & Clarke, 2016)."
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#general-background-information",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#general-background-information",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "2.1 General Background Information",
    "text": "2.1 General Background Information\nFourteen people were included in this study. Their height, weight, and gender were recorded during their interview. The participants were asked how long (in minutes) it takes takes to travel to the nearest healthcare facility from their home. The participants were also asked to rate their health from using poor, fair, good, excellent."
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#description-of-data-and-data-source",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#description-of-data-and-data-source",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "2.2 Description of data and data source",
    "text": "2.2 Description of data and data source\nFourteen people were included in this study. Their height, weight, and gender were recorded during their interview. The participants were asked how long (in minutes) it takes takes to travel to the nearest healthcare facility from their home. The participants were also asked to rate their health from using poor, fair, good, excellent."
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#questionshypotheses-to-be-addressed",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#questionshypotheses-to-be-addressed",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "2.3 Questions/Hypotheses to be addressed",
    "text": "2.3 Questions/Hypotheses to be addressed\nDoes travel time to access healthcare affect health outcomes, such as weight, and alter a person’s perception of their own health status?\nAn example of a similar study can he found in (Kelly et al., 2016)."
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#data-aquisition",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#data-aquisition",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "3.1 Data aquisition",
    "text": "3.1 Data aquisition\nData was collected during in-person interviews with 14 people. Interview responses were entered into an Excel spreadsheet by multiple study employees."
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#data-import-and-cleaning",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#data-import-and-cleaning",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "3.2 Data import and cleaning",
    "text": "3.2 Data import and cleaning\nData was cleaned using R code. Records that fell outside of defined parameters were removed. Of the 14 orginal records, 9 remained after cleaning"
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#statistical-analysis",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#statistical-analysis",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "3.3 Statistical analysis",
    "text": "3.3 Statistical analysis\nSimple scatter and box plots were used to plots visualize the data. Descriptive tables were created. Finally, linear models were generated in R using the ggplot2 package."
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#exploratorydescriptive-analysis",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#exploratorydescriptive-analysis",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "4.1 Exploratory/Descriptive analysis",
    "text": "4.1 Exploratory/Descriptive analysis\nView the tables and figures below for a better understanding of the data.\nTable 1 shows a summary of the data.\n\n\n\n\n\nTable 1: Data summary table.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_type\nskim_variable\nn_missing\ncomplete_rate\ncharacter.min\ncharacter.max\ncharacter.empty\ncharacter.n_unique\ncharacter.whitespace\nfactor.ordered\nfactor.n_unique\nfactor.top_counts\nnumeric.mean\nnumeric.sd\nnumeric.p0\nnumeric.p25\nnumeric.p50\nnumeric.p75\nnumeric.p100\nnumeric.hist\n\n\n\n\ncharacter\nSR_health\n0\n1\n4\n7\n0\n4\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\nfactor\nGender\n0\n1\nNA\nNA\nNA\nNA\nNA\nFALSE\n3\nM: 4, F: 3, O: 2\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\nnumeric\nHeight\n0\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n165.66667\n15.97655\n133\n156\n166\n178\n183\n▂▁▃▃▇\n\n\nnumeric\nWeight\n0\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n70.11111\n21.24526\n45\n55\n70\n80\n110\n▇▂▃▂▂\n\n\nnumeric\nHC_time\n0\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n33.33333\n19.68502\n10\n20\n25\n50\n65\n▇▂▂▂▃"
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#basic-statistical-analysis",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#basic-statistical-analysis",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "4.2 Basic statistical analysis",
    "text": "4.2 Basic statistical analysis\n\nFigure 1 shows a scatterplot figure produced by one of the R scripts.\n\n\n\n\n\n\n\n\nFigure 1: Height and weight stratified by gender."
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#full-analysis",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#full-analysis",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "4.3 Full analysis",
    "text": "4.3 Full analysis\n\nExample Table 2 shows a summary of a linear model fit.\n\n\n\n\nTable 2: Linear model fit table.\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n149.2726967\n23.3823360\n6.3839942\n0.0013962\n\n\nWeight\n0.2623972\n0.3512436\n0.7470519\n0.4886517\n\n\nGenderM\n-2.1244913\n15.5488953\n-0.1366329\n0.8966520\n\n\nGenderO\n-4.7644739\n19.0114155\n-0.2506112\n0.8120871"
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#summary-and-interpretation",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#summary-and-interpretation",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "5.1 Summary and Interpretation",
    "text": "5.1 Summary and Interpretation\nIn this study, there were no statistically significant relationships between travel time to the nearest healthcare facility and"
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#strengths-and-limitations",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#strengths-and-limitations",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "5.2 Strengths and Limitations",
    "text": "5.2 Strengths and Limitations\nGiven the small sample size, the results are not generalizable to any population. A larger sample size would be needed for more reliable results. Weight is not a proxy for health and it is the only health outcome included in this study."
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#conclusions",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#conclusions",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "5.3 Conclusions",
    "text": "5.3 Conclusions\nTravel time to access healthcare has been demonstrated in other studies as a factor that can lead to adverse health outcomes. Larger sample sizes and better data collection and input methods could help to illustrate the relationship."
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#scatter-plot-1",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#scatter-plot-1",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "6.1 Scatter plot 1",
    "text": "6.1 Scatter plot 1\n\n\n\n\n\n\n\n\nFigure 2: Travel time to access healthcare by weight -stratified by gender."
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#box-plot-1",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#box-plot-1",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "6.2 Box plot 1",
    "text": "6.2 Box plot 1\n\n\n\n\n\n\n\n\nFigure 3: Weight by self-reported health status.\n\n\n\n\n\n\n\n\n\nTable 3: Linear model fit table 3.\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n174.7346939\n39.3640594\n4.4389399\n0.0113433\n\n\nSR_healthgood\n-7.2925170\n28.6897378\n-0.2541856\n0.8118841\n\n\nSR_healthpoor\n0.6224490\n22.4824685\n0.0276860\n0.9792388\n\n\nSR_healthrefused\n10.6530612\n38.4051156\n0.2773865\n0.7952290\n\n\nHC_time\n-0.2387755\n0.7051065\n-0.3386375\n0.7519124\n\n\n\n\n\n\n\n\nIn this linear model, none of the relationships are statistically significant at alpha = 0.05."
  },
  {
    "objectID": "starter-analysis-exercise/code/readme.html",
    "href": "starter-analysis-exercise/code/readme.html",
    "title": "Andrew's Data Analysis Portfolio",
    "section": "",
    "text": "Place your various R or Quarto files in the appropriate folders.\nYou can either have fewer large scripts, or multiple scripts that do only specific actions. Those can be R or Quarto files. In either case, document the scripts and what goes on in them so well that someone else (including future you) can easily figure out what is happening.\nThe scripts should load the appropriate data (e.g. raw or processed), perform actions, and save results (e.g. processed data, figures, computed values) in the appropriate folders. Document somewhere what inputs each script takes and where output is placed.\nIf scripts need to be run in a specific order, document this. Either as comments in the script, or in a separate text file such as this readme file. Ideally of course in both locations.\nDepending on your specific project, you might want to have further folders/sub-folders."
  },
  {
    "objectID": "starter-analysis-exercise/code/eda-code/eda.html",
    "href": "starter-analysis-exercise/code/eda-code/eda.html",
    "title": "An example exploratory analysis script",
    "section": "",
    "text": "This Quarto file loads the cleaned data and does some exploring.\nI’m only showing it the way where the code is included in the file. As described in the processing_code materials, I currently prefer the approach of having R code in a separate file and pulling it in.\nBut I already had this written and haven’t yet re-done it that way. Feel free to redo and send a pull request on GitHub :)\nAgain, it is largely a matter of preference and what makes the most sense to decide if one wants to have code inside Quarto files, or as separate R files. And sometimes, an R script with enough comments is good enough and one doesn’t need a Quarto file.\nAlso note that while here I split cleaning and exploring, this is iterative. You saw that as part of the processing, we already had to explore the data somewhat to understand how to clean it. In general, as you explore, you’ll find things that need cleaning. As you clean, you can explore more. Therefore, at times it might make more sense to combine the cleaning and exploring code parts into a single R or Quarto file. Or split things in any other logical way.\nAs part of the exploratory analysis, you should produce plots or tables or other summary quantities for the most interesting/important quantities in your data. Depending on the total number of variables in your dataset, explore all or some of the others. Figures produced here might be histograms or density plots, correlation plots, etc. Tables might summarize your data.\nStart by exploring one variable at a time. Then continue by creating plots or tables of the outcome(s) of interest and the predictor/exposure/input variables you are most interested in. If your dataset is small, you can do that for all variables.\nPlots produced here can be scatterplots, boxplots, violinplots, etc. Tables can be simple 2x2 tables or larger ones.\n\nSetup\n\n#load needed packages. make sure they are installed.\nlibrary(here) #for data loading/saving\n\nhere() starts at /Users/andrewruiz/MADA_course/andrew_ruiz-MADA-portfolio\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(skimr)\nlibrary(ggplot2)\n\nLoad the data.\n\n#Path to data. Note the use of the here() package and not absolute paths\ndata_location &lt;- here::here(\"starter-analysis-exercise\",\"data\",\"processed-data\",\"processeddata.rds\")\n#load data\nmydata &lt;- readRDS(data_location)\n\n\n\nData exploration through tables\nShowing a bit of code to produce and save a summary table.\n\nsummary_df = skimr::skim(mydata)\nprint(summary_df)\n\n── Data Summary ────────────────────────\n                           Values\nName                       mydata\nNumber of rows             9     \nNumber of columns          3     \n_______________________          \nColumn type frequency:           \n  factor                   1     \n  numeric                  2     \n________________________         \nGroup variables            None  \n\n── Variable type: factor ───────────────────────────────────────────────────────\n  skim_variable n_missing complete_rate ordered n_unique top_counts      \n1 Gender                0             1 FALSE          3 M: 4, F: 3, O: 2\n\n── Variable type: numeric ──────────────────────────────────────────────────────\n  skim_variable n_missing complete_rate  mean   sd  p0 p25 p50 p75 p100 hist \n1 Height                0             1 166.  16.0 133 156 166 178  183 ▂▁▃▃▇\n2 Weight                0             1  70.1 21.2  45  55  70  80  110 ▇▂▃▂▂\n\n# save to file\nsummarytable_file = here(\"starter-analysis-exercise\",\"results\", \"tables-files\", \"summarytable.rds\")\nsaveRDS(summary_df, file = summarytable_file)\n\nWe are saving the results to the results/tables folder. Structure the folders inside results such that they make sense for your specific analysis. Provide enough documentation that someone can understand what you are doing and what goes where. readme.md files inside each folder are a good idea.\n\n\nData exploration through figures\nHistogram plots for the continuous outcomes.\nHeight first.\n\np1 &lt;- mydata %&gt;% ggplot(aes(x=Height)) + geom_histogram() \nplot(p1)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nfigure_file = here(\"starter-analysis-exercise\",\"results\",\"figures\",\"height-distribution.png\")\nggsave(filename = figure_file, plot=p1) \n\nSaving 7 x 5 in image\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nNow weights.\n\np2 &lt;- mydata %&gt;% ggplot(aes(x=Weight)) + geom_histogram() \nplot(p2)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nfigure_file = here(\"starter-analysis-exercise\",\"results\",\"figures\",\"weight-distribution.png\")\nggsave(filename = figure_file, plot=p2) \n\nSaving 7 x 5 in image\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nNow height as function of weight.\n\np3 &lt;- mydata %&gt;% ggplot(aes(x=Height, y=Weight)) + geom_point() + geom_smooth(method='lm')\nplot(p3)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nfigure_file = here(\"starter-analysis-exercise\",\"results\",\"figures\",\"height-weight.png\")\nggsave(filename = figure_file, plot=p3) \n\nSaving 7 x 5 in image\n`geom_smooth()` using formula = 'y ~ x'\n\n\nOnce more height as function of weight, stratified by gender. Note that there is so little data, it’s a bit silly. But we’ll plot it anyway.\n\np4 &lt;- mydata %&gt;% ggplot(aes(x=Height, y=Weight, color = Gender)) + geom_point() + geom_smooth(method='lm')\nplot(p4)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning in qt((1 - level)/2, df): NaNs produced\n\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\n\n\n\n\n\n\n\nfigure_file = here(\"starter-analysis-exercise\",\"results\",\"figures\",\"height-weight-stratified.png\")\nggsave(filename = figure_file, plot=p4) \n\nSaving 7 x 5 in image\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning in qt((1 - level)/2, df): NaNs produced\n\nWarning in qt((1 - level)/2, df): no non-missing arguments to max; returning\n-Inf\n\n\n\n\nNotes\nFor your own explorations, tables and figures can be “quick and dirty”. As long as you can see what’s going on, there is no need to polish them. That’s in contrast to figures you’ll produce for your final products (paper, report, presentation, website, etc.). Those should look as nice, polished and easy to understand as possible."
  },
  {
    "objectID": "starter-analysis-exercise/code/processing-code/processingfile.html",
    "href": "starter-analysis-exercise/code/processing-code/processingfile.html",
    "title": "An example cleaning script",
    "section": "",
    "text": "Processing script\nThis Quarto file contains a mix of code and explanatory text to illustrate a simple data processing/cleaning setup.\n\n\nSetup\nLoad needed packages. make sure they are installed.\n\nlibrary(readxl) #for loading Excel files\nlibrary(dplyr) #for data processing/cleaning\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(tidyr) #for data processing/cleaning\nlibrary(skimr) #for nice visualization of data \nlibrary(here) #to set paths\n\nhere() starts at /Users/andrewruiz/MADA_course/andrew_ruiz-MADA-portfolio\n\n\n\n\nData loading\nNote that for functions that come from specific packages (instead of base R), I often specify both package and function like so: package::function() that’s not required one could just call the function specifying the package makes it clearer where the function “lives”, but it adds typing. You can do it either way.\n\n# path to data\n# note the use of the here() package and not absolute paths\ndata_location &lt;- here::here(\"starter-analysis-exercise\",\"data\",\"raw-data\",\"exampledata.xlsx\")\nrawdata &lt;- readxl::read_excel(data_location)\n\n\n\nCheck data\nFirst we can look at the codebook\n\ncodebook &lt;- readxl::read_excel(data_location, sheet =\"Codebook\")\nprint(codebook)\n\n# A tibble: 3 × 3\n  `Variable Name` `Variable Definition`                 `Allowed Values`      \n  &lt;chr&gt;           &lt;chr&gt;                                 &lt;chr&gt;                 \n1 Height          height in centimeters                 numeric value &gt;0 or NA\n2 Weight          weight in kilograms                   numeric value &gt;0 or NA\n3 Gender          identified gender (male/female/other) M/F/O/NA              \n\n\nSeveral ways of looking at the data\n\ndplyr::glimpse(rawdata)\n\nRows: 14\nColumns: 3\n$ Height &lt;chr&gt; \"180\", \"175\", \"sixty\", \"178\", \"192\", \"6\", \"156\", \"166\", \"155\", …\n$ Weight &lt;dbl&gt; 80, 70, 60, 76, 90, 55, 90, 110, 54, 7000, NA, 45, 55, 50\n$ Gender &lt;chr&gt; \"M\", \"O\", \"F\", \"F\", \"NA\", \"F\", \"O\", \"M\", \"N\", \"M\", \"F\", \"F\", \"M…\n\nsummary(rawdata)\n\n    Height              Weight          Gender         \n Length:14          Min.   :  45.0   Length:14         \n Class :character   1st Qu.:  55.0   Class :character  \n Mode  :character   Median :  70.0   Mode  :character  \n                    Mean   : 602.7                     \n                    3rd Qu.:  90.0                     \n                    Max.   :7000.0                     \n                    NA's   :1                          \n\nhead(rawdata)\n\n# A tibble: 6 × 3\n  Height Weight Gender\n  &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt; \n1 180        80 M     \n2 175        70 O     \n3 sixty      60 F     \n4 178        76 F     \n5 192        90 NA    \n6 6          55 F     \n\nskimr::skim(rawdata)\n\n\nData summary\n\n\nName\nrawdata\n\n\nNumber of rows\n14\n\n\nNumber of columns\n3\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n2\n\n\nnumeric\n1\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nHeight\n0\n1\n1\n5\n0\n13\n0\n\n\nGender\n0\n1\n1\n2\n0\n5\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nWeight\n1\n0.93\n602.69\n1922.25\n45\n55\n70\n90\n7000\n▇▁▁▁▁\n\n\n\n\n\n\n\nCleaning\nBy inspecting the data as done above, we find some problems that need addressing:\nFirst, there is an entry for height which says “sixty” instead of a number. Does that mean it should be a numeric 60? It somehow doesn’t make sense since the weight is 60kg, which can’t happen for a 60cm person (a baby). Since we don’t know how to fix this, we might decide to remove the person. This “sixty” entry also turned all Height entries into characters instead of numeric. That conversion to character also means that our summary function isn’t very meaningful. So let’s fix that first.\n\nd1 &lt;- rawdata %&gt;% dplyr::filter( Height != \"sixty\" ) %&gt;% \n                  dplyr::mutate(Height = as.numeric(Height))\nskimr::skim(d1)\n\n\nData summary\n\n\nName\nd1\n\n\nNumber of rows\n13\n\n\nNumber of columns\n3\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n1\n\n\nnumeric\n2\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nGender\n0\n1\n1\n2\n0\n5\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nHeight\n0\n1.00\n151.62\n46.46\n6\n154.00\n165\n175\n192\n▁▁▁▂▇\n\n\nWeight\n1\n0.92\n647.92\n2000.48\n45\n54.75\n73\n90\n7000\n▇▁▁▁▁\n\n\n\n\nhist(d1$Height)\n\n\n\n\n\n\n\n\nNow we see that there is one person with a height of 6. That could be a typo, or someone mistakenly entered their height in feet. Since we unfortunately don’t know, we might need to remove this person, which we’ll do here.\n\nd2 &lt;- d1 %&gt;% dplyr::mutate( Height = replace(Height, Height==\"6\",round(6*30.48,0)) )\nskimr::skim(d2)\n\n\nData summary\n\n\nName\nd2\n\n\nNumber of rows\n13\n\n\nNumber of columns\n3\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n1\n\n\nnumeric\n2\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nGender\n0\n1\n1\n2\n0\n5\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nHeight\n0\n1.00\n165.23\n16.52\n133\n155.00\n166\n178\n192\n▂▇▆▆▃\n\n\nWeight\n1\n0.92\n647.92\n2000.48\n45\n54.75\n73\n90\n7000\n▇▁▁▁▁\n\n\n\n\n\nHeight values seem ok now.\nNow let’s look at the Weight variable. There is a person with weight of 7000, which is impossible, and one person with missing weight. To be able to analyze the data, we’ll remove those individuals as well.\n\nd3 &lt;- d2 %&gt;%  dplyr::filter(Weight != 7000) %&gt;% tidyr::drop_na()\nskimr::skim(d3)\n\n\nData summary\n\n\nName\nd3\n\n\nNumber of rows\n11\n\n\nNumber of columns\n3\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n1\n\n\nnumeric\n2\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nGender\n0\n1\n1\n2\n0\n5\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nHeight\n0\n1\n167.09\n16.81\n133\n155.5\n166\n179\n192\n▂▇▅▇▅\n\n\nWeight\n0\n1\n70.45\n20.65\n45\n54.5\n70\n85\n110\n▇▂▃▃▂\n\n\n\n\n\nNow checking the Gender variable. Gender should be a categorical/factor variable but is loaded as character. We can fix that with simple base R code to mix things up.\n\nd3$Gender &lt;- as.factor(d3$Gender)  \nskimr::skim(d3)\n\n\nData summary\n\n\nName\nd3\n\n\nNumber of rows\n11\n\n\nNumber of columns\n3\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n1\n\n\nnumeric\n2\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nGender\n0\n1\nFALSE\n5\nM: 4, F: 3, O: 2, N: 1\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nHeight\n0\n1\n167.09\n16.81\n133\n155.5\n166\n179\n192\n▂▇▅▇▅\n\n\nWeight\n0\n1\n70.45\n20.65\n45\n54.5\n70\n85\n110\n▇▂▃▃▂\n\n\n\n\n\nNow we see that there is another NA, but it’s not NA from R, instead it was loaded as character and is now considered as a category. Well proceed here by removing that individual with that NA entry. Since this keeps an empty category for Gender, I’m also using droplevels() to get rid of it.\n\nd4 &lt;- d3 %&gt;% dplyr::filter( !(Gender %in% c(\"NA\",\"N\")) ) %&gt;% droplevels()\nskimr::skim(d4)\n\n\nData summary\n\n\nName\nd4\n\n\nNumber of rows\n9\n\n\nNumber of columns\n3\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n1\n\n\nnumeric\n2\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nGender\n0\n1\nFALSE\n3\nM: 4, F: 3, O: 2\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nHeight\n0\n1\n165.67\n15.98\n133\n156\n166\n178\n183\n▂▁▃▃▇\n\n\nWeight\n0\n1\n70.11\n21.25\n45\n55\n70\n80\n110\n▇▂▃▂▂\n\n\n\n\n\nAll done, data is clean now.\nLet’s assign at the end to some final variable, this makes it easier to add further cleaning steps above.\n\nprocesseddata &lt;- d4\n\n\n\nSave data\nFinally, we save the clean data as RDS file. I suggest you save your processed and cleaned data as RDS or RDA/Rdata files. This preserves coding like factors, characters, numeric, etc. If you save as CSV, that information would get lost. However, CSV is better for sharing with others since it’s plain text. If you do CSV, you might want to write down somewhere what each variable is.\nSee here for some suggestions on how to store your processed data: http://www.sthda.com/english/wiki/saving-data-into-r-data-format-rds-and-rdata\n\nsave_data_location &lt;- here::here(\"starter-analysis-exercise\",\"data\",\"processed-data\",\"processeddata.rds\")\nsaveRDS(processeddata, file = save_data_location)\n\nNote the use of the here package and here command to specify a path relative to the main project directory, that is the folder that contains the .Rproj file. Always use this approach instead of hard-coding file paths that only exist on your computer.\n\n\nNotes\nRemoving anyone observation with “faulty” or missing data is one approach. It’s often not the best. based on your question and your analysis approach, you might want to do cleaning differently (e.g. keep observations with some missing information)."
  },
  {
    "objectID": "starter-analysis-exercise/code/processing-code/processingfile2.html",
    "href": "starter-analysis-exercise/code/processing-code/processingfile2.html",
    "title": "An example cleaning script",
    "section": "",
    "text": "Processing script\nThis Quarto file contains a mix of code and explanatory text to illustrate a simple data processing/cleaning setup.\n\n\nSetup\nLoad needed packages. make sure they are installed.\n\nlibrary(readxl) #for loading Excel files\nlibrary(dplyr) #for data processing/cleaning\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(tidyr) #for data processing/cleaning\nlibrary(skimr) #for nice visualization of data \nlibrary(here) #to set paths\n\nhere() starts at /Users/andrewruiz/MADA_course/andrew_ruiz-MADA-portfolio\n\n\n\n\nData loading\nNote that for functions that come from specific packages (instead of base R), I often specify both package and function like so: package::function() that’s not required one could just call the function specifying the package makes it clearer where the function “lives”, but it adds typing. You can do it either way.\n\n# path to data\n# note the use of the here() package and not absolute paths\ndata_location &lt;- here::here(\"starter-analysis-exercise\",\"data\",\"raw-data\",\"exampledata2.xlsx\")\nrawdata &lt;- readxl::read_excel(data_location)\n\n\n\nCheck data\nFirst we can look at the codebook\n\ncodebook &lt;- readxl::read_excel(data_location, sheet =\"Codebook\")\nprint(codebook)\n\n# A tibble: 5 × 3\n  `Variable Name` `Variable Definition`                         `Allowed Values`\n  &lt;chr&gt;           &lt;chr&gt;                                         &lt;chr&gt;           \n1 Height          \"height in centimeters\"                       numeric value &gt;…\n2 Weight          \"weight in kilograms\"                         numeric value &gt;…\n3 Gender          \"identified gender (male/female/other)\"       M/F/O/NA        \n4 HC_time         \"travel time to nearest healthcare facility … numeric value &gt;…\n5 SR_health       \"self-reported health state, response to the… poor, fair, goo…\n\n\nSeveral ways of looking at the data\n\ndplyr::glimpse(rawdata)\n\nRows: 14\nColumns: 5\n$ Height    &lt;chr&gt; \"180\", \"175\", \"sixty\", \"178\", \"192\", \"6\", \"156\", \"166\", \"155…\n$ Weight    &lt;dbl&gt; 80, 70, 60, 76, 90, 55, 90, 110, 54, 7000, NA, 45, 55, 50\n$ Gender    &lt;chr&gt; \"M\", \"O\", \"F\", \"F\", \"NA\", \"F\", \"O\", \"M\", \"N\", \"M\", \"F\", \"F\",…\n$ HC_time   &lt;dbl&gt; 15, 25, 30, 20, 45, 10, 50, 65, 5, 10, 15, 20, 55, 40\n$ SR_health &lt;chr&gt; \"good\", \"good\", \"excellent\", \"poor\", \"fair\", \"refused\", \"poo…\n\nsummary(rawdata)\n\n    Height              Weight          Gender             HC_time     \n Length:14          Min.   :  45.0   Length:14          Min.   : 5.00  \n Class :character   1st Qu.:  55.0   Class :character   1st Qu.:15.00  \n Mode  :character   Median :  70.0   Mode  :character   Median :22.50  \n                    Mean   : 602.7                      Mean   :28.93  \n                    3rd Qu.:  90.0                      3rd Qu.:43.75  \n                    Max.   :7000.0                      Max.   :65.00  \n                    NA's   :1                                          \n  SR_health        \n Length:14         \n Class :character  \n Mode  :character  \n                   \n                   \n                   \n                   \n\nhead(rawdata)\n\n# A tibble: 6 × 5\n  Height Weight Gender HC_time SR_health\n  &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt;    \n1 180        80 M           15 good     \n2 175        70 O           25 good     \n3 sixty      60 F           30 excellent\n4 178        76 F           20 poor     \n5 192        90 NA          45 fair     \n6 6          55 F           10 refused  \n\nskimr::skim(rawdata)\n\n\nData summary\n\n\nName\nrawdata\n\n\nNumber of rows\n14\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n3\n\n\nnumeric\n2\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nHeight\n0\n1\n1\n5\n0\n13\n0\n\n\nGender\n0\n1\n1\n2\n0\n5\n0\n\n\nSR_health\n0\n1\n4\n9\n0\n5\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nWeight\n1\n0.93\n602.69\n1922.25\n45\n55\n70.0\n90.00\n7000\n▇▁▁▁▁\n\n\nHC_time\n0\n1.00\n28.93\n18.93\n5\n15\n22.5\n43.75\n65\n▇▅▃▃▃\n\n\n\n\n\n\n\nCleaning\nBy inspecting the data as done above, we find some problems that need addressing:\nFirst, there is an entry for height which says “sixty” instead of a number. Does that mean it should be a numeric 60? It somehow doesn’t make sense since the weight is 60kg, which can’t happen for a 60cm person (a baby). Since we don’t know how to fix this, we might decide to remove the person. This “sixty” entry also turned all Height entries into characters instead of numeric. That conversion to character also means that our summary function isn’t very meaningful. So let’s fix that first.\n\nd1 &lt;- rawdata %&gt;% dplyr::filter( Height != \"sixty\" ) %&gt;% \n                  dplyr::mutate(Height = as.numeric(Height))\nskimr::skim(d1)\n\n\nData summary\n\n\nName\nd1\n\n\nNumber of rows\n13\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n2\n\n\nnumeric\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nGender\n0\n1\n1\n2\n0\n5\n0\n\n\nSR_health\n0\n1\n4\n9\n0\n5\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nHeight\n0\n1.00\n151.62\n46.46\n6\n154.00\n165\n175\n192\n▁▁▁▂▇\n\n\nWeight\n1\n0.92\n647.92\n2000.48\n45\n54.75\n73\n90\n7000\n▇▁▁▁▁\n\n\nHC_time\n0\n1.00\n28.85\n19.70\n5\n15.00\n20\n45\n65\n▇▅▂▃▃\n\n\n\n\nhist(d1$Height)\n\n\n\n\n\n\n\n\nNow we see that there is one person with a height of 6. That could be a typo, or someone mistakenly entered their height in feet. Since we unfortunately don’t know, we might need to remove this person, which we’ll do here.\n\nd2 &lt;- d1 %&gt;% dplyr::mutate( Height = replace(Height, Height==\"6\",round(6*30.48,0)) )\nskimr::skim(d2)\n\n\nData summary\n\n\nName\nd2\n\n\nNumber of rows\n13\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n2\n\n\nnumeric\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nGender\n0\n1\n1\n2\n0\n5\n0\n\n\nSR_health\n0\n1\n4\n9\n0\n5\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nHeight\n0\n1.00\n165.23\n16.52\n133\n155.00\n166\n178\n192\n▂▇▆▆▃\n\n\nWeight\n1\n0.92\n647.92\n2000.48\n45\n54.75\n73\n90\n7000\n▇▁▁▁▁\n\n\nHC_time\n0\n1.00\n28.85\n19.70\n5\n15.00\n20\n45\n65\n▇▅▂▃▃\n\n\n\n\n\nHeight values seem ok now.\nNow let’s look at the Weight variable. There is a person with weight of 7000, which is impossible, and one person with missing weight. To be able to analyze the data, we’ll remove those individuals as well.\n\nd3 &lt;- d2 %&gt;%  dplyr::filter(Weight != 7000) %&gt;% tidyr::drop_na()\nskimr::skim(d3)\n\n\nData summary\n\n\nName\nd3\n\n\nNumber of rows\n11\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n2\n\n\nnumeric\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nGender\n0\n1\n1\n2\n0\n5\n0\n\n\nSR_health\n0\n1\n4\n9\n0\n5\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nHeight\n0\n1\n167.09\n16.81\n133\n155.5\n166\n179.0\n192\n▂▇▅▇▅\n\n\nWeight\n0\n1\n70.45\n20.65\n45\n54.5\n70\n85.0\n110\n▇▂▃▃▂\n\n\nHC_time\n0\n1\n31.82\n20.03\n5\n17.5\n25\n47.5\n65\n▇▇▂▅▅\n\n\n\n\n\nNow checking the Gender variable. Gender should be a categorical/factor variable but is loaded as character. We can fix that with simple base R code to mix things up.\n\nd3$Gender &lt;- as.factor(d3$Gender)  \nskimr::skim(d3)\n\n\nData summary\n\n\nName\nd3\n\n\nNumber of rows\n11\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n1\n\n\nfactor\n1\n\n\nnumeric\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nSR_health\n0\n1\n4\n9\n0\n5\n0\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nGender\n0\n1\nFALSE\n5\nM: 4, F: 3, O: 2, N: 1\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nHeight\n0\n1\n167.09\n16.81\n133\n155.5\n166\n179.0\n192\n▂▇▅▇▅\n\n\nWeight\n0\n1\n70.45\n20.65\n45\n54.5\n70\n85.0\n110\n▇▂▃▃▂\n\n\nHC_time\n0\n1\n31.82\n20.03\n5\n17.5\n25\n47.5\n65\n▇▇▂▅▅\n\n\n\n\n\nNow we see that there is another NA, but it’s not NA from R, instead it was loaded as character and is now considered as a category. Well proceed here by removing that individual with that NA entry. Since this keeps an empty category for Gender, I’m also using droplevels() to get rid of it.\n\nd4 &lt;- d3 %&gt;% dplyr::filter( !(Gender %in% c(\"NA\",\"N\")) ) %&gt;% droplevels()\nskimr::skim(d4)\n\n\nData summary\n\n\nName\nd4\n\n\nNumber of rows\n9\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n1\n\n\nfactor\n1\n\n\nnumeric\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nSR_health\n0\n1\n4\n7\n0\n4\n0\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nGender\n0\n1\nFALSE\n3\nM: 4, F: 3, O: 2\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nHeight\n0\n1\n165.67\n15.98\n133\n156\n166\n178\n183\n▂▁▃▃▇\n\n\nWeight\n0\n1\n70.11\n21.25\n45\n55\n70\n80\n110\n▇▂▃▂▂\n\n\nHC_time\n0\n1\n33.33\n19.69\n10\n20\n25\n50\n65\n▇▂▂▂▃\n\n\n\n\n\nAll done, data is clean now.\nLet’s assign at the end to some final variable, this makes it easier to add further cleaning steps above.\n\nprocesseddata &lt;- d4\n\n\n\nSave data\nFinally, we save the clean data as RDS file. I suggest you save your processed and cleaned data as RDS or RDA/Rdata files. This preserves coding like factors, characters, numeric, etc. If you save as CSV, that information would get lost. However, CSV is better for sharing with others since it’s plain text. If you do CSV, you might want to write down somewhere what each variable is.\nSee here for some suggestions on how to store your processed data: http://www.sthda.com/english/wiki/saving-data-into-r-data-format-rds-and-rdata\n\nsave_data_location &lt;- here::here(\"starter-analysis-exercise\",\"data\",\"processed-data\",\"processeddata2.rds\")\nsaveRDS(processeddata, file = save_data_location)\n\nNote the use of the here package and here command to specify a path relative to the main project directory, that is the folder that contains the .Rproj file. Always use this approach instead of hard-coding file paths that only exist on your computer.\n\n\nNotes\nRemoving anyone observation with “faulty” or missing data is one approach. It’s often not the best. based on your question and your analysis approach, you might want to do cleaning differently (e.g. keep observations with some missing information)."
  },
  {
    "objectID": "starter-analysis-exercise/results/readme.html",
    "href": "starter-analysis-exercise/results/readme.html",
    "title": "Andrew's Data Analysis Portfolio",
    "section": "",
    "text": "This folder contains results produced by the code, such as figures and tables.\nDepending on the size and type of your project, you can either place it all in a single folder or create sub-folders. For instance you could create a folder for figures, another for tables. Or you could create a sub-folder for dataset 1, another for dataset 2. Or you could have a subfolder for exploratory analysis, another for final analysis. The options are endless, choose whatever makes sense for your project. For this template, there is just a a single folder, but having sub-folders is often a good idea."
  },
  {
    "objectID": "starter-analysis-exercise/data/raw-data/readme.html",
    "href": "starter-analysis-exercise/data/raw-data/readme.html",
    "title": "Andrew's Data Analysis Portfolio",
    "section": "",
    "text": "This folder contains a simple made-up data-set in an Excel file.\nIt contains the variables Height, Weight and Gender of a few imaginary individuals.\nThe dataset purposefully contains some faulty entries that need to be cleaned.\nGenerally, any dataset should contain some meta-data explaining what each variable in the dataset is. (This is often called a Codebook.) For this simple example, the codebook is given as a second sheet in the Excel file.\nThis raw data-set should generally not be edited by hand. It should instead be loaded and processed/cleaned using code."
  }
]