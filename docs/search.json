[
  {
    "objectID": "fitting-exercise/fitting-exercise.html",
    "href": "fitting-exercise/fitting-exercise.html",
    "title": "fitting-exercise",
    "section": "",
    "text": "`\nsuppressMessages({\n  library(ggplot2)\n  library(dplyr)\n  library(skimr)\n  library(shiny)\n  library(DT)\n  library(here)\n  library(rsconnect)\n  library(tidymodels)\n  library(yardstick)\n  library(MASS)\n})"
  },
  {
    "objectID": "fitting-exercise/fitting-exercise.html#load-dataset",
    "href": "fitting-exercise/fitting-exercise.html#load-dataset",
    "title": "fitting-exercise",
    "section": "Load dataset",
    "text": "Load dataset\n\ndataset found at https://github.com/metrumresearchgroup/BayesPBPK-tutorial.git\n\nfile_path_mav = here(\"fitting-exercise\", \"data\", \"Mavoglurant_A2121_nmpk.csv\")\nmav = read.csv(file_path_mav)"
  },
  {
    "objectID": "fitting-exercise/fitting-exercise.html#dv-is-the-outcome-variable",
    "href": "fitting-exercise/fitting-exercise.html#dv-is-the-outcome-variable",
    "title": "fitting-exercise",
    "section": "DV is the outcome variable",
    "text": "DV is the outcome variable"
  },
  {
    "objectID": "fitting-exercise/fitting-exercise.html#plot-graph-dv-as-a-function-of-time-by-dose-and-id",
    "href": "fitting-exercise/fitting-exercise.html#plot-graph-dv-as-a-function-of-time-by-dose-and-id",
    "title": "fitting-exercise",
    "section": "Plot graph DV as a function of Time by DOSE and ID",
    "text": "Plot graph DV as a function of Time by DOSE and ID\n\n# Create a ggplot object using the 'mav' data\nggplot(mav, aes(x = TIME, y = DV, group = ID, color = as.factor(DOSE))) + \n  geom_line() + \n  geom_point() +\n  theme_minimal() + \n  labs(title = \"DV as a function of Time by DOSE and ID\", \n       x = \"Time\", \n       y = \"DV\", \n       color = \"Dose\")"
  },
  {
    "objectID": "fitting-exercise/fitting-exercise.html#showing-all-doses-on-one-graph-make-it-difficult-to-read",
    "href": "fitting-exercise/fitting-exercise.html#showing-all-doses-on-one-graph-make-it-difficult-to-read",
    "title": "fitting-exercise",
    "section": "Showing all doses on one graph make it difficult to read",
    "text": "Showing all doses on one graph make it difficult to read"
  },
  {
    "objectID": "fitting-exercise/fitting-exercise.html#try-creating-1-plot-for-each-dose",
    "href": "fitting-exercise/fitting-exercise.html#try-creating-1-plot-for-each-dose",
    "title": "fitting-exercise",
    "section": "Try creating 1 plot for each dose",
    "text": "Try creating 1 plot for each dose\n\nggplot(mav, aes(x = TIME, y = DV, group = ID, color = as.factor(DOSE))) + \n  geom_line() + \n  geom_point() +\n  theme_minimal() + \n  labs(title = \"DV as a function of Time by DOSE and ID\", \n       x = \"Time\", \n       y = \"DV\", \n       color = \"Dose\") + \n  facet_grid(~DOSE, scales = \"fixed\")  # Adjusted scales to \"fixed\" so that they share the same y axis scale."
  },
  {
    "objectID": "fitting-exercise/fitting-exercise.html#keep-only-records-where-occ1",
    "href": "fitting-exercise/fitting-exercise.html#keep-only-records-where-occ1",
    "title": "fitting-exercise",
    "section": "Keep only records where OCC=1",
    "text": "Keep only records where OCC=1\n\nmav_occ_1 = mav %&gt;%\n    filter(OCC == 1)\n\n#check to make sure filter worked as expected\nunique(mav_occ_1$OCC)\n\n[1] 1\n\n\n\nFilter and join the dataset\n\nOne data frame where observations where TIME = 0 are excluded, then sum DV for each ID to create a new variable, Y\n\n\nOne data frame that keeps only records where TIME == 0\n\nRationale: Initial measurements (TIME == 0) often represent baseline or pre-treatment values. Excluding these when summing DV allows for the calculation of total change or exposure post-baseline, which can be critical for assessing the effect or impact of an intervention.\n\n# exclude observations where TIME = 0\n# then sum DV for each ID to create new variable, Y\nmav_dv_sum = mav_occ_1 %&gt;%\n  filter(TIME != 0) %&gt;%\n  group_by(ID) %&gt;%\n  summarize(Y = sum(DV, na.rm = TRUE))\n\n#check dimension\ndim(mav_dv_sum)\n\n[1] 120   2\n\n# Keep only records where TIME == 0\nmav_time0 = mav_occ_1 %&gt;%\n    filter(TIME == 0) %&gt;%\n    distinct(ID, .keep_all = TRUE)\n\n#join the two data frames\nmav_joined = left_join(mav_dv_sum, mav_time0, by = \"ID\")\n\n#Check the dimension to ensure it is 120x18\ndim(mav_joined)\n\n[1] 120  18"
  },
  {
    "objectID": "fitting-exercise/fitting-exercise.html#convert-sex-race-and-dose-to-factor-variables-and-keep-the-variables-y-dose-age-sex-race-wt-ht",
    "href": "fitting-exercise/fitting-exercise.html#convert-sex-race-and-dose-to-factor-variables-and-keep-the-variables-y-dose-age-sex-race-wt-ht",
    "title": "fitting-exercise",
    "section": "Convert SEX, RACE, and DOSE to factor variables and keep the variables Y, DOSE, AGE, SEX, RACE, WT, HT",
    "text": "Convert SEX, RACE, and DOSE to factor variables and keep the variables Y, DOSE, AGE, SEX, RACE, WT, HT\n\n#This code transforms SEX, RACE, and DOSE into categorical variables for analysis and selects a specific set of variables, streamlining the dataset for focused statistical modeling or data exploration involving these key demographic and treatment attributes.\nlibrary(dplyr)\nmav_clean &lt;- mav_joined %&gt;%\n  mutate(SEX = as.factor(SEX), RACE = as.factor(RACE), DOSE = as.factor(DOSE)) %&gt;%\n  dplyr::select(Y, DOSE, AGE, SEX, RACE, WT, HT)\n\n# Checking the dimensions\ndim(mav_clean)\n\n[1] 120   7"
  },
  {
    "objectID": "fitting-exercise/fitting-exercise.html#create-bmi-variable-and-a-categorical-variable-for-age",
    "href": "fitting-exercise/fitting-exercise.html#create-bmi-variable-and-a-categorical-variable-for-age",
    "title": "fitting-exercise",
    "section": "Create BMI variable and a categorical variable for age",
    "text": "Create BMI variable and a categorical variable for age\n\nConvert them to factors\n\nBMI = weight in kilograms / (height in meters)^2\n\n#Calculate BMI and assign categories based on value\nmav_clean &lt;- mav_clean %&gt;%\n  mutate(\n    bmi = WT / (HT^2),\n    BMI_Category = case_when(\n      bmi &lt; 18.5 ~ \"Underweight\",\n      bmi &gt;= 18.5 & bmi &lt; 25 ~ \"Normal\",\n      bmi &gt;= 25 & bmi &lt; 30 ~ \"Overweight\",\n      bmi &gt;= 30 ~ \"Obese\",\n      TRUE ~ \"Unknown\"  # Handles any missing or NA values\n    )\n  ) %&gt;%\n  mutate(BMI_Category = factor(BMI_Category)) #convert to factor\n\n#Create categorical age variable\nmav_clean &lt;- mav_clean %&gt;%\n  mutate(Age_Group = cut(AGE,\n                         breaks = c(-Inf, 18, 30, 40, 50, 60, Inf),\n                         labels = c(\"&lt;=18\", \"19-30\", \"31-40\", \"41-50\", \"51-60\", \"&gt;60\"),\n                         right = FALSE)) %&gt;%\n    mutate(Age_Group = factor(Age_Group)) #convert to factor\n#examine structure\nstr(mav_clean)\n\ntibble [120 × 10] (S3: tbl_df/tbl/data.frame)\n $ Y           : num [1:120] 2691 2639 2150 1789 3126 ...\n $ DOSE        : Factor w/ 3 levels \"25\",\"37.5\",\"50\": 1 1 1 1 1 1 1 1 1 1 ...\n $ AGE         : int [1:120] 42 24 31 46 41 27 23 20 23 28 ...\n $ SEX         : Factor w/ 2 levels \"1\",\"2\": 1 1 1 2 2 1 1 1 1 1 ...\n $ RACE        : Factor w/ 4 levels \"1\",\"2\",\"7\",\"88\": 2 2 1 1 2 2 1 4 2 1 ...\n $ WT          : num [1:120] 94.3 80.4 71.8 77.4 64.3 ...\n $ HT          : num [1:120] 1.77 1.76 1.81 1.65 1.56 ...\n $ bmi         : num [1:120] 30.1 26 21.9 28.4 26.4 ...\n $ BMI_Category: Factor w/ 3 levels \"Normal\",\"Obese\",..: 2 3 1 3 3 1 3 1 1 2 ...\n $ Age_Group   : Factor w/ 4 levels \"19-30\",\"31-40\",..: 3 1 2 3 3 1 1 1 1 1 ..."
  },
  {
    "objectID": "fitting-exercise/fitting-exercise.html#create-tables",
    "href": "fitting-exercise/fitting-exercise.html#create-tables",
    "title": "fitting-exercise",
    "section": "Create tables",
    "text": "Create tables\n\nCalculatec summary statistics (number of observations, mean, median, minimum, and maximum of variable Y) for different groups in the dataset mav_clean, based on SEX, BMI_Category, and Age_Group\n\n\nDisplay these values in sortable tables\n\n# Compute summary statistics for each factor variable\nsummary_sex &lt;- mav_clean %&gt;%\n  group_by(SEX) %&gt;%\n    summarize(\n    N = n(),\n    Mean_Y = mean(Y, na.rm = TRUE),\n    Median_Y = median(Y, na.rm = TRUE),\n    Min_Y = min(Y, na.rm = TRUE),\n    Max_Y = max(Y, na.rm = TRUE),\n    .groups = 'drop'\n  ) %&gt;%\n  mutate(across(c(Mean_Y, Median_Y, Min_Y, Max_Y), round, 2))\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `across(c(Mean_Y, Median_Y, Min_Y, Max_Y), round, 2)`.\nCaused by warning:\n! The `...` argument of `across()` is deprecated as of dplyr 1.1.0.\nSupply arguments directly to `.fns` through an anonymous function instead.\n\n  # Previously\n  across(a:b, mean, na.rm = TRUE)\n\n  # Now\n  across(a:b, \\(x) mean(x, na.rm = TRUE))\n\nsummary_BMI &lt;- mav_clean %&gt;%\n  group_by(BMI_Category) %&gt;%\n    summarize(\n    N = n(),\n    Mean_Y = mean(Y, na.rm = TRUE),\n    Median_Y = median(Y, na.rm = TRUE),\n    Min_Y = min(Y, na.rm = TRUE),\n    Max_Y = max(Y, na.rm = TRUE),\n    .groups = 'drop'\n  ) %&gt;%\n  mutate(across(c(Mean_Y, Median_Y, Min_Y, Max_Y), round, 2))\n\nsummary_age &lt;- mav_clean %&gt;%\n  group_by(Age_Group) %&gt;%\n  summarize(\n    N = n(),\n    Mean_Y = mean(Y, na.rm = TRUE),\n    Median_Y = median(Y, na.rm = TRUE),\n    Min_Y = min(Y, na.rm = TRUE),\n    Max_Y = max(Y, na.rm = TRUE),\n    .groups = 'drop'\n  ) %&gt;%\n  mutate(across(c(Mean_Y, Median_Y, Min_Y, Max_Y), round, 2))\n\n# Display the tables\ndatatable(summary_sex, options = list(pageLength = 5), caption = 'Summary Statistics of Y by SEX')\n\n\n\n\ndatatable(summary_BMI, options = list(pageLength = 5), caption = 'Summary Statistics of Y by BMI')\n\n\n\n\ndatatable(summary_age, options = list(pageLength = 5), caption = 'Summary Statistics of Y by Age')\n\n\n\n\n\n\n\nComputes summary statistics (count, mean, median, minimum, and maximum) for variable Y, grouped by Age_Group and BMI_Category from the mav_clean dataset, and then displays the results in an sortable table\n\n# Compute summary statistics for Y, stratified by both SEX and RACE\nsummary_stats_group &lt;- mav_clean %&gt;%\n  group_by(Age_Group, BMI_Category) %&gt;%\n  summarize(\n    N = n(),\n    Mean_Y = mean(Y, na.rm = TRUE),\n    Median_Y = median(Y, na.rm = TRUE),\n    Min_Y = min(Y, na.rm = TRUE),\n    Max_Y = max(Y, na.rm = TRUE),\n    .groups = 'drop'\n  ) %&gt;%\n  mutate(across(c(Mean_Y, Median_Y, Min_Y, Max_Y), round, 2))\n\n# Display the table with DT::datatable for interactivity\ndatatable(summary_stats_group, options = list(pageLength = 10), \n          caption = 'Summary Statistics of Y by Age and BMI Status')\n\n\n\n\n\n\n\nThis R code reorders the levels of the factor variable BMI_Category in the dataset mav_clean and then creates four different plots: a raincloud plot of Y by BMI_Category, a combines scatter and contour plot of Y by Weight, a raincloud plot of Y by DOSE, and a raincloud plot of Y by age category using the ggplot2 package in R\n\n# Reorder the levels of BMI_Category\nmav_clean$BMI_Category &lt;- factor(mav_clean$BMI_Category, \n                                  levels = c(\"Normal\", \"Overweight\", \"Obese\"))\n\nggplot(mav_clean, aes(x = BMI_Category, y = Y)) +\n  geom_violin(fill = \"skyblue\", alpha = 0.5) +  # Add violin plot with semi-transparent fill\n  geom_boxplot(width = 0.1, fill = \"white\", color = \"black\", outlier.shape = NA) +  # Add transparent boxplot without outliers\n  geom_point(position = position_jitter(width = 0.2), alpha = 0.5, size = 2) +  # Add jittered points for individual data\n  labs(x = \"BMI\", y = \"Y\", title = \"Raincloud Plot of Y by BMI\")  # Add labels and title\n\n\n\n\n\n\n\nggplot(mav_clean, aes(x = WT, y = Y)) +\n  geom_point() +\n  labs(x = \"Weight (kg)\", y = \"Y\", title = \"Scatter Plot of Y by Weight\")\n\n\n\n\n\n\n\n#Combined scatter and contour plot\n#a contour plot displays the density of points\n#in the form of contour lines, providing a two-dimensional representation of the data density.\nggplot(mav_clean, aes(x = WT, y = Y)) +\n  stat_density_2d(aes(fill = after_stat(level)), geom = \"polygon\") +  # Create contour polygons\n  geom_point() +  # Add scatter plot\n  scale_fill_viridis_c() +  # Choose a color scale\n  labs(x = \"Weight (kg)\", y = \"Y\", title = \"Combined Scatter and Contour Plot of Y by Weight\")  # Add labels and title\n\n\n\n\n\n\n\nggplot(mav_clean, aes(x = DOSE, y = Y)) +\n  geom_violin(fill = \"skyblue\", alpha = 0.5) +  # Add violin plot with semi-transparent fill\n  geom_boxplot(width = 0.1, fill = \"white\", color = \"black\", outlier.shape = NA) +  # Add transparent boxplot without outliers\n  geom_point(position = position_jitter(width = 0.2), alpha = 0.5, size = 2) +  # Add jittered points for individual data\n  labs(x = \"DOSE\", y = \"Y\", title = \"Raincloud Plot of Y by Dose\")  # Add labels and title\n\n\n\n\n\n\n\nggplot(mav_clean, aes(x = Age_Group, y = Y)) +\n  geom_violin(fill = \"skyblue\", alpha = 0.5) +  # Add violin plot with semi-transparent fill\n  geom_boxplot(width = 0.1, fill = \"white\", color = \"black\", outlier.shape = NA) +  # Add transparent boxplot without outliers\n  geom_point(position = position_jitter(width = 0.2), alpha = 0.5, size = 2) +  # Add jittered points for individual data\n  labs(x = \"Age_Group\", y = \"Y\", title = \"Raincloud Plot of Y by Age\")  # Add labels and title\n\nWarning: Groups with fewer than two data points have been dropped.\n\n\n\n\n\n\n\n\n\n\n\nCreate a grid of scatterplots for each pair of variables in subset_data (Y, bmi) and (HT, bmi), along with histograms for each variable on the diagonal and correlation coefficients in the upper triangle.\n\n\nWeight and BMI are directly related. Using this as an example to show highly correlated pair\n\n# Load the GGally library for pair plot visualization\nlibrary(GGally)\n\nRegistered S3 method overwritten by 'GGally':\n  method from   \n  +.gg   ggplot2\n\n# Subset the dataset to include only the variables Y and BMI\nsubset_Ybmi&lt;- mav_clean[, c(\"Y\", \"bmi\")]\n\n# Using the pairs() function to create a matrix of scatterplots for Y and BMI\npairs(subset_Ybmi)\n\n\n\n\n\n\n\n# Using the ggpairs() function to create a grid of scatterplots, histograms, and correlation coefficients for Y and BMI\nggpairs(subset_Ybmi)\n\n\n\n\n\n\n\n# Subset the dataset to include only the variables weight and BMI\nsubset_dataWTbmi &lt;- mav_clean[, c(\"WT\", \"bmi\")]\n\n# Using the pairs() function to create a matrix of scatterplots for weight and BMI\npairs(subset_dataWTbmi)\n\n\n\n\n\n\n\n# Using the ggpairs() function to create a grid of scatterplots, histograms, and correlation coefficients for weight and BMI\nggpairs(subset_dataWTbmi)\n\n\n\n\n\n\n\n\n\n\nThe BMI to Y shows a Corr. of -.0153. This suggests that there is weak inverse relationship between the two variables.\n\n\nThe weight to BMI shows a Corr. of 0.762. This suggests that there is a stronger postitive relationship and the two are closely related."
  },
  {
    "objectID": "fitting-exercise/fitting-exercise.html#model-fitting",
    "href": "fitting-exercise/fitting-exercise.html#model-fitting",
    "title": "fitting-exercise",
    "section": "Model fitting",
    "text": "Model fitting\n\nFit a linear model to the continuous outcome (Y) using the main predictor of interest, DOSE\n\n\nFit a linear model to the continuous outcome (Y) using all predictors\n\nPreprocess data\n\n# Preprocess your data: convert 'DOSE' and 'BMI_Category' to factors\nmav_clean &lt;- mav_clean %&gt;%\n  mutate(\n    DOSE = as.factor(DOSE),  # Convert DOSE to a factor\n    BMI_Category = factor(BMI_Category, levels = c(\"Normal\", \"Overweight\", \"Obese\"))  # Ensure BMI_Category has ordered levels\n  )\n\n\n\nThe code defines a linear model specification using the ‘lm’ engine for regression analysis and prepares a 5-fold cross-validation with stratification by ‘Y’ to ensure balanced splits\n\n\nUtilizing a 5-fold cross-validation with stratification by ‘Y’ helps ensure balanced splits within each fold, which is crucial for maintaining the representativeness of each subset during model evaluation, especially in the presence of class imbalance or uneven distribution of the target variable ‘Y’.\n\n# Define the linear model specification using the 'lm' engine\nlinear_spec &lt;- linear_reg() %&gt;% \n  set_engine(\"lm\") %&gt;% \n  set_mode(\"regression\")\n\n# Prepare a 5-fold cross-validation, stratifying by 'Y' to ensure balanced splits\ncv_folds &lt;- vfold_cv(mav_clean, v = 5, strata = Y)\n\n\n\nThe code creates a workflow for a linear regression model using ‘DOSE’ as the predictor variable, fits the model across cross-validation folds, and collects evaluation metrics including Root Mean Squared Error (RMSE) and R-squared\n\n# Create a workflow for the model using only DOSE as the predictor\nworkflow_dose &lt;- workflow() %&gt;%\n  add_formula(Y ~ DOSE) %&gt;%  # Define the model formula with DOSE\n  add_model(linear_spec)  # Add the linear model specification\n\n# Fit the model across the cross-validation folds and collect evaluation metrics (RMSE and R-squared)\nresults_dose &lt;- fit_resamples(\n  workflow_dose,\n  cv_folds,\n  metrics = metric_set(rmse, rsq)\n)\n\n\n\nThis code creates a workflow for a linear regression model including all predictors (DOSE, AGE, and BMI_Category), fits the model across cross-validation folds, and collects evaluation metrics such as Root Mean Squared Error (RMSE) and R-squared.\n\n# Workflow for the model including all predictors (DOSE, AGE, BMI_Category)\nworkflow_all &lt;- workflow() %&gt;%\n  add_formula(Y ~ DOSE + AGE + BMI_Category) %&gt;%  # Include all predictors in the formula\n  add_model(linear_spec)  # Add the same linear model specification\n\n# Fit this comprehensive model across the cross-validation folds and collect metrics\nresults_all &lt;- fit_resamples(\n  workflow_all,\n  cv_folds,\n  metrics = metric_set(rmse, rsq)\n)\n\n\n\nThis series of steps allows for the comparison of evaluation metrics between the model with only ‘DOSE’ as the predictor and the model with all predictors (‘DOSE’, ‘AGE’, and ‘BMI_Category’). Additionally, it provides the range of values for the ‘Y’ variable in the dataset.\n\n# Step 1: Collect metrics for the model with DOSE as the predictor\nmetrics_dose &lt;- collect_metrics(results_dose)\n\n# Step 2: Collect metrics for the model with all predictors\nmetrics_all &lt;- collect_metrics(results_all)\n\n# Step 3: Add a model identifier column to the metrics data frames AFTER collecting metrics\nmetrics_dose$model &lt;- \"DOSE Predictor\"\nmetrics_all$model &lt;- \"All Predictors\"\n\n# Step 4: Combine metrics into a single data frame for comparison\ncombined_metrics &lt;- bind_rows(metrics_dose, metrics_all)\n\n# Step 5: Reorder the columns so that 'model' is the first column\nreordered_metrics &lt;- combined_metrics %&gt;%\n  dplyr::select(model, .metric, .estimator, mean, n, std_err, .config)\n\n# Step 6: Print the reordered metrics\nprint(reordered_metrics)\n\n# A tibble: 4 × 7\n  model          .metric .estimator    mean     n std_err .config             \n  &lt;chr&gt;          &lt;chr&gt;   &lt;chr&gt;        &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 DOSE Predictor rmse    standard   662.        5 73.6    Preprocessor1_Model1\n2 DOSE Predictor rsq     standard     0.547     5  0.0859 Preprocessor1_Model1\n3 All Predictors rmse    standard   650.        5 77.6    Preprocessor1_Model1\n4 All Predictors rsq     standard     0.552     5  0.0872 Preprocessor1_Model1\n\n# Step 7: Print the range of 'Y' from the 'mav_clean' dataset\n# Assuming 'mav_clean' is your dataset and it contains the variable 'Y'\ny_range &lt;- range(mav_clean$Y, na.rm = TRUE)\n\n# Step 8: Print the range\nprint(y_range)\n\n[1]  826.43 5606.58\n\n\n\n\n\nComparative Proportion: The error is a moderate proportion of the range (5606.58 - 826.43 = 4780.15). Specifically, it’s about 14% of the total range (666.90 / 4780.15 ≈ 0.14), suggesting that, on average, the model’s predictions might deviate from the actual values by around 14% of the total variability in Y."
  },
  {
    "objectID": "fitting-exercise/fitting-exercise.html#fit-a-logistic-model-to-the-categoricalbinary-outcome-sex-using-the-main-predictor-of-interest-which-well-again-assume-here-to-be-dose",
    "href": "fitting-exercise/fitting-exercise.html#fit-a-logistic-model-to-the-categoricalbinary-outcome-sex-using-the-main-predictor-of-interest-which-well-again-assume-here-to-be-dose",
    "title": "fitting-exercise",
    "section": "Fit a logistic model to the categorical/binary outcome (SEX) using the main predictor of interest, which we’ll again assume here to be DOSE",
    "text": "Fit a logistic model to the categorical/binary outcome (SEX) using the main predictor of interest, which we’ll again assume here to be DOSE"
  },
  {
    "objectID": "fitting-exercise/fitting-exercise.html#fit-a-logistic-model-to-sex-using-all-predictors.",
    "href": "fitting-exercise/fitting-exercise.html#fit-a-logistic-model-to-sex-using-all-predictors.",
    "title": "fitting-exercise",
    "section": "Fit a logistic model to SEX using all predictors.",
    "text": "Fit a logistic model to SEX using all predictors."
  },
  {
    "objectID": "fitting-exercise/fitting-exercise.html#for-both-models-compute-accuracy-and-roc-auc-and-print-them",
    "href": "fitting-exercise/fitting-exercise.html#for-both-models-compute-accuracy-and-roc-auc-and-print-them",
    "title": "fitting-exercise",
    "section": "For both models, compute accuracy and ROC-AUC and print them",
    "text": "For both models, compute accuracy and ROC-AUC and print them\n\nP(SEX = 1 | DOSE) = 1 / (1 + exp(-(intercept + coefficient * DOSE))\n\n# Ensure SEX is a factor and DOSE is treated as a factor for logistic regression analysis\nmav_clean_prepared &lt;- mav_clean %&gt;%\n  mutate(\n    SEX = as.factor(SEX),  # Convert SEX to a factor if it isn't already\n    DOSE = as.factor(DOSE)  # Ensure DOSE is treated as a factor\n  )\n\n# Specify a logistic regression model using glm (Generalized Linear Model) as the engine\nlogistic_spec_dose &lt;- logistic_reg() %&gt;% \n  set_engine(\"glm\") %&gt;% \n  set_mode(\"classification\")  # Set mode to classification for the binary outcome\n\n# Prepare a 5-fold cross-validation object, stratifying by SEX to ensure balanced folds\ncv_folds_sex &lt;- vfold_cv(mav_clean_prepared, v = 5, strata = SEX)\n\n# Create a workflow combining the logistic model specification with the SEX ~ DOSE formula\nworkflow_sex_dose &lt;- workflow() %&gt;%\n  add_formula(SEX ~ DOSE) %&gt;%  # Predicting SEX based on DOSE\n  add_model(logistic_spec_dose)  # Add the logistic regression specification\n\n# Fit the model across the cross-validation folds and calculate metrics\nresults_sex_dose_cv &lt;- fit_resamples(\n  workflow_sex_dose,\n  cv_folds_sex,\n  metrics = metric_set(roc_auc, accuracy)  # Focus on ROC AUC and accuracy for evaluation\n)\n\n# Collect and summarize the metrics from cross-validation\nmetrics_sex_dose &lt;- collect_metrics(results_sex_dose_cv)\n\n# Print the summarized metrics to assess model performance\nprint(metrics_sex_dose)\n\n# A tibble: 2 × 6\n  .metric  .estimator  mean     n std_err .config             \n  &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy binary     0.867     5 0.00681 Preprocessor1_Model1\n2 roc_auc  binary     0.497     5 0.0843  Preprocessor1_Model1\n\n\n\n\nAccuracy\n\nMetric: Accuracy measures the proportion of true results (both true positives and true negatives) among the total number of cases examined. It’s a straightforward indicator of how often the model predicts the correct category.\n\n\nValue: The mean accuracy across the 5 cross-validation folds is approximately 86.69%.\n\n\nInterpretation: This suggests that, on average, the model correctly predicts the SEX category about 86.69% of the time across the different subsets of your data. A high accuracy indicates the model is generally effective at classifying the instances according to SEX.\n\n\n\nROC AUC (Area Under the Receiver Operating Characteristic Curve)\n\nMetric: ROC AUC evaluates the model’s ability to discriminate between the classes at various threshold settings. The AUC (Area Under the Curve) ranges from 0 to 1, where 1 indicates perfect discrimination and 0.5 indicates no discrimination (equivalent to random guessing). Value: The mean ROC AUC across the 5 folds is approximately 0.553. Interpretation: This value is slightly above 0.5, indicating the model has a very limited ability to distinguish between the SEX categories beyond random chance. The ROC AUC being close to 0.5 suggests that, while the model is accurate in many of its predictions, this might be attributed to the distribution of classes in the dataset rather than the model’s discriminative power.\n\n\n\nP(SEX = 1 | DOSE, AGE, BMI_Category) = 1 / (1 + exp(-(intercept + coefficient_DOSE * DOSE + coefficient_AGE * AGE + coefficient_BMI_Category * BMI_Category)))\n\n# Preprocess the dataset: converting predictors to their appropriate formats\nmav_clean_logistic_all &lt;- mav_clean %&gt;%\n  mutate(\n    BMI_Category = as.factor(BMI_Category),  # Ensure BMI_Category is a factor\n    DOSE = as.factor(DOSE),  # Ensure DOSE is a factor\n    AGE = as.numeric(AGE)  # Ensure AGE is numeric\n  )\n\n# Specify a logistic regression model using glm as the computational engine\nlogistic_spec_all &lt;- logistic_reg() %&gt;% \n  set_engine(\"glm\") %&gt;% \n  set_mode(\"classification\")\n\n# Prepare a 5-fold cross-validation, ensuring a balanced representation of SEX across folds\ncv_folds_sex_all &lt;- vfold_cv(mav_clean_logistic_all, v = 5, strata = SEX)\n\n# Create a workflow that encapsulates the model specification and formula\nworkflow_sex_all &lt;- workflow() %&gt;%\n  add_formula(SEX ~ BMI_Category + AGE + DOSE) %&gt;%  # Use all predictors in the model formula\n  add_model(logistic_spec_all)  # Add the logistic regression model specification\n\n# Fit the model across the cross-validation folds and evaluate\nresults_sex_all_cv &lt;- fit_resamples(\n  workflow_sex_all,\n  cv_folds_sex_all,\n  metrics = metric_set(roc_auc, accuracy)  # Focus on ROC AUC and accuracy for evaluation\n)\n# Collect metrics from the cross-validation results\nmetrics_sex_all &lt;- collect_metrics(results_sex_all_cv)\n\n# Print the summarized metrics to understand model performance\nprint(metrics_sex_all)\n\n# A tibble: 2 × 6\n  .metric  .estimator  mean     n std_err .config             \n  &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy binary     0.834     5  0.0224 Preprocessor1_Model1\n2 roc_auc  binary     0.797     5  0.0267 Preprocessor1_Model1\n\n\n\n\nFirst Model (DOSE as the Predictor)\n\nAccuracy: The mean accuracy is approximately 86.69%, indicating a high overall rate of correctly predicting SEX.\n\n\nROC AUC: The mean ROC AUC is approximately 0.553, suggesting the model’s ability to discriminate between the classes is only slightly better than random guessing.\n\n\n\nSecond Model (All Predictors: BMI_Category, AGE, DOSE)\n\nAccuracy: The mean accuracy slightly decreases to approximately 84.26%. This indicates a slight reduction in the overall rate of correct predictions compared to the first model.\n\n\nROC AUC: The mean ROC AUC improves to approximately 0.627, indicating enhanced discriminative ability between the classes compared to the first model.\n\n\n\nInterpretation\n\nAccuracy vs. ROC AUC: While the first model achieves higher accuracy, its ROC AUC value is lower, suggesting it’s not as effective at distinguishing between the classes across different thresholds. The second model, despite a slight drop in accuracy, shows a notable improvement in ROC AUC, indicating better performance in class discrimination.\n\n\nModel Comparison: The increase in ROC AUC for the second model suggests that including additional predictors (BMI_Category and AGE alongside DOSE) contributes to a more nuanced understanding and prediction of SEX, beyond what is achievable with DOSE alone. This indicates the importance of considering multiple factors in predictive modeling, especially for complex outcomes."
  },
  {
    "objectID": "fitting-exercise/fitting-exercise.html#k-nearest-neighbors-knn-regression-model",
    "href": "fitting-exercise/fitting-exercise.html#k-nearest-neighbors-knn-regression-model",
    "title": "fitting-exercise",
    "section": "k-nearest neighbors (KNN) regression model",
    "text": "k-nearest neighbors (KNN) regression model\n\nThe model is trained and evaluated to predict the outcome variable ‘Y’ based on the predictor variable ‘DOSE’.\n\n\nThis process involves splitting the dataset into training and testing sets, converting the ‘DOSE’ variable to a factor, specifying the KNN model, fitting the model on the training data, making predictions on the testing set, calculating evaluation metrics (Root Mean Squared Error and R-squared), and printing the evaluation metrics for model assessment and comparison.\n\nlibrary(kknn)\n\n# Splitting the data\nset.seed(123)  # Ensure reproducibility\nmav_data_split &lt;- initial_split(mav_clean, prop = 0.75)  # 75% training, 25% testing\nmav_train &lt;- training(mav_data_split)  # Training data\nmav_test &lt;- testing(mav_data_split)  # Testing data\n\nmav_train &lt;- mav_train %&gt;%\n  mutate(DOSE = as.factor(DOSE))\n\nmav_test &lt;- mav_test %&gt;%\n  mutate(DOSE = as.factor(DOSE))\n\n# KNN model specification\nknn_spec &lt;- nearest_neighbor(neighbors = 5) %&gt;%\n  set_engine(\"kknn\") %&gt;%\n  set_mode(\"regression\")\n\n# Creating the workflow\nknn_workflow &lt;- workflow() %&gt;%\n  add_formula(Y ~ DOSE) %&gt;%\n  add_model(knn_spec)\n\n# Fitting the model on training data\nknn_fit &lt;- knn_workflow %&gt;%\n  fit(data = mav_train)\n\n# Making predictions on the testing set\nknn_predictions &lt;- predict(knn_fit, new_data = mav_test) %&gt;%\n  bind_cols(mav_test)\n\n# Calculate RMSE and R-squared\nknn_metrics &lt;- knn_predictions %&gt;%\n  metrics(truth = Y, estimate = .pred) %&gt;%\n  filter(.metric %in% c(\"rmse\", \"rsq\"))\n\n# Print the evaluation metrics\nprint(knn_metrics)\n\n# A tibble: 2 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard     566.   \n2 rsq     standard       0.648"
  },
  {
    "objectID": "fitting-exercise/fitting-exercise.html#model-comparison",
    "href": "fitting-exercise/fitting-exercise.html#model-comparison",
    "title": "fitting-exercise",
    "section": "Model comparison",
    "text": "Model comparison\n\nRMSE (Root Mean Squared Error):\n\n\nKNN model: 565.72\n\n\n“DOSE Predictor” model: 673.09\n\nThe RMSE of the KNN model (565.72) is lower than that of the “DOSE Predictor” model (673.09), indicating that, on average, the KNN model’s predictions are closer to the true values compared to the “DOSE Predictor” model.\n\n\n\nR-squared (rsq):\n\nKNN model: 0.648\n\n\n“DOSE Predictor” model: 0.522\n\nThe R-squared value of the KNN model (0.648) is higher than that of the “DOSE Predictor” model (0.522), suggesting that the KNN model explains a higher proportion of the variance in the outcome variable compared to the “DOSE Predictor” model.\n\n\nOverall, based on these metrics, the KNN model appears to perform better in terms of both accuracy (lower RMSE) and explanatory power (higher R-squared) compared to the “DOSE Predictor” model."
  }
]